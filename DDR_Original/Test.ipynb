{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyepo\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for shortest path\n",
    "grid = (5,5) # grid size\n",
    "optmodel = pyepo.model.grb.shortestPathModel(grid)\n",
    "\n",
    "# generate data\n",
    "num_data = 100 # number of data\n",
    "num_feat = 5 # size of feature\n",
    "deg = 4 # polynomial degree\n",
    "noise_width = 0.5 # noise width\n",
    "x, c = pyepo.data.shortestpath.genData(num_data, num_feat, grid, deg, noise_width, seed=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyepo.data.dataset import optDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcs = []\n",
    "for i in range(grid[0]):\n",
    "    # edges on rows\n",
    "    for j in range(grid[1] - 1):\n",
    "        v = i * grid[1] + j\n",
    "        arcs.append((v, v + 1))\n",
    "    # edges in columns\n",
    "    if i == grid[0] - 1:\n",
    "        continue\n",
    "    for j in range(grid[1]):\n",
    "        v = i * grid[1] + j\n",
    "        arcs.append((v, v + grid[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1610.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# build dataset\n",
    "dataset = optDataset(optmodel, x, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data loader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(5, 40)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "# init\n",
    "predmodel = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of cores: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get data loader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(5, 40)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "# init\n",
    "predmodel = LinearRegression()\n",
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(predmodel.parameters(), lr=1e-3)\n",
    "# init SPO+ loss\n",
    "spo = pyepo.func.SPOPlus(optmodel, processes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyepo import EPO\n",
    "def regret(predmodel, optmodel, dataloader):\n",
    "    \"\"\"\n",
    "    A function to evaluate model performance with normalized true regret\n",
    "\n",
    "    Args:\n",
    "        predmodel (nn): a regression neural network for cost prediction\n",
    "        optmodel (optModel): an PyEPO optimization model\n",
    "        dataloader (DataLoader): Torch dataloader from optDataSet\n",
    "\n",
    "    Returns:\n",
    "        float: true regret loss\n",
    "    \"\"\"\n",
    "    # evaluate\n",
    "    predmodel.eval()\n",
    "    loss = 0\n",
    "    optsum = 0\n",
    "    # load data\n",
    "    for data in dataloader:\n",
    "        x, c, w, z = data\n",
    "        # cuda\n",
    "        if next(predmodel.parameters()).is_cuda:\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # predict\n",
    "        with torch.no_grad(): # no grad\n",
    "            cp = predmodel(x).to(\"cpu\").detach().numpy()\n",
    "        # solve\n",
    "        for j in range(cp.shape[0]):\n",
    "            # accumulate loss\n",
    "            loss += calRegret(optmodel, cp[j], c[j].to(\"cpu\").detach().numpy(),\n",
    "                              z[j].item())\n",
    "        optsum += abs(z).sum().item()\n",
    "    # turn back train mode\n",
    "    predmodel.train()\n",
    "    # normalized\n",
    "    return loss / (optsum + 1e-7)\n",
    "\n",
    "\n",
    "def calRegret(optmodel, pred_cost, true_cost, true_obj):\n",
    "    \"\"\"\n",
    "    A function to calculate normalized true regret for a batch\n",
    "\n",
    "    Args:\n",
    "        optmodel (optModel): optimization model\n",
    "        pred_cost (torch.tensor): predicted costs\n",
    "        true_cost (torch.tensor): true costs\n",
    "        true_obj (torch.tensor): true optimal objective values\n",
    "\n",
    "    Returns:predmodel\n",
    "        float: true regret losses\n",
    "    \"\"\"\n",
    "    # opt sol for pred cost\n",
    "    optmodel.setObj(pred_cost)\n",
    "    sol, _ = optmodel.solve()\n",
    "    # obj with true cost\n",
    "    obj = np.dot(sol, true_cost)\n",
    "    # loss\n",
    "    if optmodel.modelSense == EPO.MINIMIZE:\n",
    "        loss = obj - true_obj\n",
    "    if optmodel.modelSense == EPO.MAXIMIZE:\n",
    "        loss = true_obj - obj\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0\n",
      "x:  tensor([-0.8629, -2.2003, -0.1394,  1.8497,  0.2735])\n",
      "cp:  tensor([-0.8148,  1.1028,  0.7246, -1.8341, -0.5219,  0.6857, -0.4815,  1.1070,\n",
      "         0.7286, -0.2700, -0.5083, -1.1259, -0.4710, -0.9342,  0.1993,  0.8728,\n",
      "        -1.2045, -0.3845,  0.3084,  1.4701,  1.1125,  1.5412, -1.0259, -0.3662,\n",
      "         0.8940, -0.9008, -0.0992, -0.1185,  0.4493,  1.0897,  0.5000,  0.1889,\n",
      "        -0.0701, -0.8649, -0.2057, -0.2844,  1.2203,  1.1408, -0.3450, -0.4339],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "epoch =  1\n",
      "x:  tensor([-0.2271,  0.5185, -0.8914,  1.2301, -1.0326])\n",
      "cp:  tensor([ 0.6273, -0.3287,  0.5408, -0.7008, -0.6884,  0.3619, -0.5723,  1.2862,\n",
      "         0.7763, -0.5891, -0.2004,  0.4121, -0.5781,  0.2079,  0.5674,  0.1987,\n",
      "        -0.0914,  0.3493,  0.9369,  0.1259, -0.2955,  0.4816, -0.0677, -0.0361,\n",
      "         0.9792,  0.1179, -0.0479,  0.3512, -0.3103,  0.1986, -0.3370,  0.6545,\n",
      "        -0.4693,  0.6527, -0.4147, -1.1494, -0.1759, -0.6625,  0.2150, -0.2998],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 20\n",
    "for epoch in range(2):\n",
    "    print(\"epoch = \",epoch)\n",
    "    it = 0\n",
    "    for data in dataloader:\n",
    "        x, c, w, z = data # x: feature, c: cost, w: \n",
    "        # forward pass\n",
    "        cp = predmodel(x)\n",
    "        \n",
    "        # print(\"it: \", it,\"x shape = \",np.shape(x)) \n",
    "        # print(\"w: \", w,\" w shape = \",np.shape(w)) \n",
    "        # print(\"z: \", z,\" z shape = \",np.shape(z)) \n",
    "        # it = it + 1\n",
    "        # SPO+ loss\n",
    "        loss = spo(cp, c, w, z)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"x: \", x[0,:]) \n",
    "    print(\"cp: \", cp[0,:]) \n",
    "        # regret = pyepo.metric.regret(reg, optmodel, loader_test)\n",
    "    #     # print(\"it = \",it,\"x = \",spo.optmodel.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.679788589477539"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
