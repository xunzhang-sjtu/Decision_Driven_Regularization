{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5423203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "from Performance import performance_evaluation\n",
    "perfs = performance_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907d7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump):\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,data_generation_process) \n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    np.random.seed(coef_seed)\n",
    "    np.random.seed(coef_seed)\n",
    "    random.seed(coef_seed)\n",
    "    seed_arr = random.sample(range(1, 10000 + 1), len(iteration_all))\n",
    "    x_test_all = {}; c_test_all = {}; x_train_all = {}; c_train_all = {}; W_star_all = {}; noise_train_all = {}; noise_test_all = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_iter = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_iter).mkdir(parents=True, exist_ok=True)\n",
    "        W_star = data_gen.generate_truth(DataPath_iter,lower, upper, p, d, seed_arr[iter],data_generation_process) \n",
    "        x_test_all[iter], c_test_all[iter], x_train_all[iter], c_train_all[iter], noise_train_all[iter],noise_test_all[iter],W_star_all[iter] \\\n",
    "        = data_gen.generate_samples(iter,DataPath_iter,p, d, num_test, num_train, alpha, W_star, mis, num_test, data_generation_process, x_dist, e_dist, x_low, x_up, x_mean, x_var, bump) \n",
    "    return x_test_all, c_test_all, x_train_all, c_train_all, noise_train_all,noise_test_all,W_star_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbc3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_Oracle(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,iteration_all,num_feat,data_generation_process):\n",
    "    cost_Oracle_Post = {}; cost_Oracle_Ante = {}\n",
    "    for iter in iteration_all:\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            # cost_Oracle_Post[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Post(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "            cost_Oracle_Ante[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_oracle_pred,cost_oracle_pred)\n",
    "            # print(\"Oracle: iter=\",iter,\",cost_Oracle_Post=\",np.nanmean(cost_Oracle_Post[iter]),\",cost_Oracle_Ante=\",np.nanmean(cost_Oracle_Ante[iter]))\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_Oracle_Post[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter],True)\n",
    "            cost_Oracle_Ante[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter],False)\n",
    "            # print(\"Oracle: iter=\",iter,\",cost_Oracle_Post=\",np.nanmean(cost_Oracle_Post[iter]),\",cost_Oracle_Ante=\",np.nanmean(cost_Oracle_Ante[iter]))\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            # print(\"Oracle: iter=\",iter,\",cost_Oracle_Post=\",np.nanmean(cost_Oracle_Post[iter]),\",cost_Oracle_Ante=\",np.nanmean(cost_Oracle_Ante[iter]))\n",
    "            print(\"Oracle: iter=\",iter,\",cost_Oracle_Ante=\",np.nanmean(cost_Oracle_Ante[iter]))\n",
    "    return cost_Oracle_Post,cost_Oracle_Ante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a8c09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_OLS(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process):\n",
    "    from OLS import ols_method\n",
    "    ols_method_obj = ols_method()\n",
    "    W_ols_all = {}; w0_ols_all = {}; t_ols_all = {}; obj_ols_all = {}\n",
    "    cost_OLS_Post = {}; cost_OLS_Ante = {}\n",
    "    for iter in iteration_all:\n",
    "        # compute OLS performance\n",
    "        W_ols_all[iter], w0_ols_all[iter], t_ols_all[iter], obj_ols_all[iter] = ols_method_obj.ols_solver(\"\",x_train_all[iter], c_train_all[iter])\n",
    "        cost_dem = (W_ols_all[iter] @ x_test_all[iter].T).T + w0_ols_all[iter]\n",
    "\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            # cost_OLS_Post[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Post(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "            cost_OLS_Ante[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_dem,cost_oracle_pred)\n",
    "            # print(\"Oracle: iter=\",iter,\",cost_OLS_Post=\",np.nanmean(cost_OLS_Post[iter]),\",cost_OLS_Ante=\",np.nanmean(cost_OLS_Ante[iter]))\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_OLS_Post[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter],True)\n",
    "            cost_OLS_Ante[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter],False)\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            # print(\"OLS: iter=\",iter,\",cost_OLS_Post =\",np.nanmean(cost_OLS_Post[iter]),\",cost_OLS_Ante=\",np.nanmean(cost_OLS_Ante[iter]))\n",
    "            print(\"OLS: iter=\",iter,\",cost_OLS_Ante=\",np.nanmean(cost_OLS_Ante[iter]))\n",
    "    return cost_OLS_Post,cost_OLS_Ante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99787333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_DDR(mu_all,lamb_all,arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process):\n",
    "    from DDR import DDR_method\n",
    "    ddr_object = DDR_method()\n",
    "    num_nodes = grid[0] * grid[0]\n",
    "\n",
    "    w0_ddr_dict = {}; W_ddr_dict = {}\n",
    "    cost_DDR_Post = {}; cost_DDR_Ante = {}\n",
    "    for iter in iteration_all:\n",
    "        for mu in mu_all:\n",
    "            for lamb in lamb_all:\n",
    "                w0_ddr_dict[iter,mu,lamb],W_ddr_dict[iter,mu,lamb],alpha_rst,obj_ddr = ddr_object.solve_DDR(arcs,lamb,mu,num_nodes,x_train_all[iter],c_train_all[iter])\n",
    "                cost_pred = (W_ddr_dict[iter,mu,lamb] @ x_test_all[iter].T).T + w0_ddr_dict[iter,mu,lamb]\n",
    "                if data_generation_process == \"SPO_Data_Generation\":\n",
    "                    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "                    cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "                    # cost_DDR_Post[iter,mu,lamb] = perfs.compute_SPO_out_of_sample_Cost_Ex_Post(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "                    cost_DDR_Ante[iter,mu,lamb] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_pred,cost_oracle_pred)\n",
    "\n",
    "                if data_generation_process == \"DDR_Data_Generation\":\n",
    "                    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "                    cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "                    # cost_DDR_with_noise_all[iter,mu,lamb] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],True)\n",
    "                    cost_DDR_Ante[iter,mu,lamb] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],False)\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            # print(\"DDR: iter=\",iter,\",mu=\",mu,\",lamb=\",lamb,\",cost_DDR_Post =\",np.nanmean(cost_DDR_Post[iter,mu,lamb]),\n",
    "            #       \",cost_DDR_Ante =\",np.nanmean(cost_DDR_Ante[iter,mu,lamb]))\n",
    "            print(\"DDR: iter=\",iter,\",mu=\",mu,\",lamb=\",lamb,\",cost_DDR_Ante =\",np.nanmean(cost_DDR_Ante[iter,mu,lamb]))\n",
    "    return cost_DDR_Post,cost_DDR_Ante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf174bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "                  arcs,grid,epo_runner,perfs,num_feat,mis,data_generation_process):\n",
    "    W_EPO_all = {}; w0_EPO_all = {}\n",
    "    cost_EPO_Post = {}; cost_EPO_Ante = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_seed = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        W_EPO_all[iter],w0_EPO_all[iter] = epo_runner.run(method_names,DataPath_seed,batch_size,num_feat,grid,num_epochs,\\\n",
    "                                        x_train_all[iter],c_train_all[iter],arcs)\n",
    "        \n",
    "        cost_pred = (W_EPO_all[iter] @ x_test_all[iter].T).T + w0_EPO_all[iter]\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            non_negative_cols = (cost_oracle_ori > 0).all(axis=0)\n",
    "            cost_oracle_ori = cost_oracle_ori[:,non_negative_cols]\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            \n",
    "            cost_pred = cost_pred[non_negative_cols,:]\n",
    "            # cost_EPO_Post[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Post(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "            cost_EPO_Ante[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_pred,cost_oracle_pred)\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_EPO_Ante[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],False)\n",
    "            cost_EPO_Post[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],True)\n",
    "\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            # print(method_names,\": iter=\",iter,\",cost_EPO_Post =\",np.nanmean(cost_EPO_Post[iter]),\",cost_EPO_Ante=\",np.nanmean(cost_EPO_Ante[iter]))\n",
    "            print(method_names,\": iter=\",iter,\",cost_EPO_Ante=\",np.nanmean(cost_EPO_Ante[iter]))\n",
    "    return cost_EPO_Post,cost_EPO_Ante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e673a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all):\n",
    "        with open(DataPath+'x_test_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(x_test_all,tf)\n",
    "        with open(DataPath+'c_test_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(c_test_all,tf)\n",
    "        with open(DataPath+'x_train_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(x_train_all,tf)\n",
    "        with open(DataPath+'c_train_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(c_train_all,tf)\n",
    "        with open(DataPath+'noise_train_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(noise_train_all,tf)\n",
    "        with open(DataPath+'noise_test_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(noise_test_all,tf)\n",
    "        with open(DataPath+'W_star_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(W_star_all,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49587a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cost_data(DataPath):\n",
    "    with open(DataPath+'cost_OLS_Post_all.pkl', \"rb\") as tf:\n",
    "        cost_OLS_Post_all = pickle.load(tf)\n",
    "    with open(DataPath+'cost_OLS_Ante_all.pkl', \"rb\") as tf:\n",
    "        cost_OLS_Ante_all = pickle.load(tf)\n",
    "\n",
    "    with open(DataPath+'cost_Oracle_Post_all.pkl', \"rb\") as tf:\n",
    "        cost_Oracle_Post_all = pickle.load(tf)\n",
    "    with open(DataPath+'cost_Oracle_Ante_all.pkl', \"rb\") as tf:\n",
    "        cost_Oracle_Ante_all = pickle.load(tf)\n",
    "\n",
    "    with open(DataPath+'cost_DDR_Post_all.pkl', \"rb\") as tf:\n",
    "        cost_DDR_Post_all = pickle.load(tf)\n",
    "    with open(DataPath+'cost_DDR_Ante_all.pkl', \"rb\") as tf:\n",
    "        cost_DDR_Ante_all = pickle.load(tf)\n",
    "\n",
    "    return cost_Oracle_Post_all,cost_Oracle_Ante_all,cost_OLS_Post_all,cost_OLS_Ante_all,cost_DDR_Post_all,cost_DDR_Ante_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e09dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_approaches(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process):\n",
    "        with open(DataPath+'x_test_all.pkl', \"rb\") as tf:\n",
    "            x_test_all = pickle.load(tf)\n",
    "        with open(DataPath+'c_test_all.pkl', \"rb\") as tf:\n",
    "            c_test_all = pickle.load(tf)\n",
    "        with open(DataPath+'x_train_all.pkl', \"rb\") as tf:\n",
    "            x_train_all = pickle.load(tf)\n",
    "        with open(DataPath+'c_train_all.pkl', \"rb\") as tf:\n",
    "            c_train_all = pickle.load(tf)\n",
    "        with open(DataPath+'noise_train_all.pkl', \"rb\") as tf:\n",
    "            noise_train_all = pickle.load(tf)\n",
    "        with open(DataPath+'noise_test_all.pkl', \"rb\") as tf:\n",
    "            noise_test_all = pickle.load(tf)\n",
    "        with open(DataPath+'W_star_all.pkl', \"rb\") as tf:\n",
    "            W_star_all = pickle.load(tf)\n",
    "\n",
    "        cost_Oracle_Post_all,cost_Oracle_Ante_all = Implement_Oracle(arcs, grid,mis,bump,\\\n",
    "                                                                    W_star_all,x_test_all,noise_test_all,\\\n",
    "                                                                    iteration_all,num_feat,data_generation_process)\n",
    "\n",
    "        cost_OLS_Post_all,cost_OLS_Ante_all = Implement_OLS(arcs, grid,mis,bump,\\\n",
    "                                                            W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,\\\n",
    "                                                            iteration_all,num_feat,data_generation_process)\n",
    "\n",
    "        cost_DDR_Post_all,cost_DDR_Ante_all = Implement_DDR(mu_all,lamb_all,arcs, grid,mis,bump,\\\n",
    "                                                                    W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,\\\n",
    "                                                                        iteration_all,num_feat,data_generation_process)\n",
    "\n",
    "        # batch_size = 20\n",
    "        # num_epochs = 1000\n",
    "        # from PYEPO import PyEPO_Method\n",
    "        # epo_runner = PyEPO_Method()\n",
    "        # method_names = [\"spo+\"]\n",
    "        # cost_SPO_Post_all,cost_SPO_Ante_all = Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,\\\n",
    "        #                                             W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "        #                                             arcs,grid,epo_runner,perfs,num_feat,mis,data_generation_process)\n",
    "\n",
    "        \n",
    "        with open(DataPath+'cost_Oracle_Post_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_Oracle_Post_all,tf)\n",
    "        with open(DataPath+'cost_Oracle_Ante_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_Oracle_Ante_all,tf)\n",
    "\n",
    "        with open(DataPath+'cost_OLS_Post_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_OLS_Post_all,tf)\n",
    "        with open(DataPath+'cost_OLS_Ante_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_OLS_Ante_all,tf)\n",
    "\n",
    "        with open(DataPath+'cost_DDR_Post_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_DDR_Post_all,tf)\n",
    "        with open(DataPath+'cost_DDR_Ante_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_DDR_Ante_all,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f51b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_compare2plus(c_item, c_base, c_oracle):\n",
    "    N = len(c_item)\n",
    "    c_diff = c_base - c_item\n",
    "    lbel = np.zeros((N,1))\n",
    "    \n",
    "    equals = np.sum(c_diff == 0)\n",
    "    wins = np.sum(c_diff > 0) # indicate num of c_item is lower than c_base\n",
    "    lose = np.sum(c_diff < 0)\n",
    "    \n",
    "    lbel[c_diff < 0] = 1\n",
    "    lbel[c_diff > 0] = -1\n",
    "    \n",
    "#     print(N, equals, wins, lose)\n",
    "    if N == equals:\n",
    "        win_ratio = 0.5\n",
    "    else:\n",
    "        win_ratio = wins/(N - equals)\n",
    "    cost_reduction = (np.nanmean(c_diff))/np.abs(np.nanmean(c_base))\n",
    "    if np.nanmean(c_base) - np.nanmean(c_oracle) <= 1e-6:\n",
    "        regret_reduction = 0.0\n",
    "    else:\n",
    "        regret_reduction = (np.nanmean(c_diff))/np.abs(np.nanmean(c_base) - np.nanmean(c_oracle))\n",
    "    return win_ratio, cost_reduction, regret_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16e79d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_h2h_regret(mu,lamb,iteration_all,cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all):\n",
    "    ### Post Result\n",
    "    h2h_ = np.zeros(len(iteration_all)); cost_rd_ = np.zeros(len(iteration_all)); regret_rd_ = np.zeros(len(iteration_all))\n",
    "    # for iter_index in range(len(iteration_all)):\n",
    "    #     iter = iteration_all[iter_index]\n",
    "    #     h2h_[iter_index],cost_rd_[iter_index],regret_rd_[iter_index] = cross_compare2plus(cost_DDR_Post_all[iter,mu,lamb], cost_OLS_Post_all[iter], cost_Oracle_Post_all[iter])\n",
    "    # regret_post = np.round( len(regret_rd_[regret_rd_ > 0.0])/len(regret_rd_),4 )\n",
    "    # h2h_post = np.round( len(h2h_[h2h_ >= 0.5])/len(h2h_),4 )\n",
    "\n",
    "    ### Ante Result\n",
    "    h2h_ = np.zeros(len(iteration_all)); cost_rd_ = np.zeros(len(iteration_all)); regret_rd_ = np.zeros(len(iteration_all))\n",
    "    for iter_index in range(len(iteration_all)):\n",
    "        iter = iteration_all[iter_index]\n",
    "        h2h_[iter_index],cost_rd_[iter_index],regret_rd_[iter_index] = cross_compare2plus(cost_DDR_Ante_all[iter,mu,lamb], cost_OLS_Ante_all[iter], cost_Oracle_Ante_all[iter])\n",
    "    regret_ante = np.round( len(regret_rd_[regret_rd_ > 0.0])/len(regret_rd_),4 )\n",
    "    h2h_ante = np.round( len(h2h_[h2h_ >= 0.5])/len(h2h_),4 )\n",
    "    # return h2h_post,regret_post,h2h_ante,regret_ante\n",
    "    return h2h_ante,regret_ante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e7311",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "782cc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = (2,2) # grid size\n",
    "from Network import network_design\n",
    "Network = network_design()\n",
    "arcs,arc_index_mapping = Network._getArcs(grid)\n",
    "\n",
    "num_test = 1000\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "num_nodes = grid[0]*grid[0]\n",
    "coef_seed = 1\n",
    "\n",
    "x_dist = 'uniform'\n",
    "e_dist = 'normal'\n",
    "x_low = -2\n",
    "x_up = 2\n",
    "x_mean = 2\n",
    "x_var = 2\n",
    "bump = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "554bf254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPath_parent: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/\n"
     ]
    }
   ],
   "source": [
    "data_generation_process = \"SPO_Data_Generation\"\n",
    "# data_generation_process = \"DDR_Data_Generation\"\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "project_directory = os.path.dirname(os.path.dirname(os.path.dirname(parent_directory)))\n",
    "DataPath_Parent = project_directory + f'/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed={coef_seed}/{grid[0]}by{grid[1]}_Network_' + data_generation_process + \"/\"\n",
    "pathlib.Path(DataPath_Parent).mkdir(parents=True, exist_ok=True)\n",
    "print(\"DataPath_parent:\", DataPath_Parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25df629",
   "metadata": {},
   "source": [
    "#### Impact of sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "318667b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=50_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=100_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=200_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=500_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=1000_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n"
     ]
    }
   ],
   "source": [
    "num_feat = 5 # size of feature\n",
    "p = num_feat\n",
    "deg = 1.0 # polynomial degree\n",
    "mis = deg # model misspecification\n",
    "e = 0.5 # scale of normal std or the range of uniform. For the error term\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "iteration_all = np.arange(0,100)\n",
    "batch_size = 20\n",
    "num_epochs = 1000\n",
    "num_train_all = [50,100,200,500,1000]\n",
    "mu_all = np.asarray([0.5])\n",
    "lamb_all = np.asarray([0.3])\n",
    "for num_train in num_train_all:\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "    pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    \n",
    "    x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all \\\n",
    "    = Data_Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)\n",
    "\n",
    "    store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99b3b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=50_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-03-13\n",
      "Oracle: iter= 20 ,cost_Oracle_Ante= 7.570987910337144\n",
      "Oracle: iter= 40 ,cost_Oracle_Ante= 7.633024984495525\n",
      "Oracle: iter= 60 ,cost_Oracle_Ante= 7.681466558473392\n",
      "Oracle: iter= 80 ,cost_Oracle_Ante= 7.5372654068001035\n",
      "OLS: iter= 20 ,cost_OLS_Ante= 7.712084158320866\n",
      "OLS: iter= 40 ,cost_OLS_Ante= 7.810012085386832\n",
      "OLS: iter= 60 ,cost_OLS_Ante= 7.694011667498538\n",
      "OLS: iter= 80 ,cost_OLS_Ante= 7.608629547109129\n",
      "DDR: iter= 20 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.713483682866974\n",
      "DDR: iter= 40 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.816434870700436\n",
      "DDR: iter= 60 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.69396847606451\n",
      "DDR: iter= 80 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.607971655059612\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=100_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "Oracle: iter= 20 ,cost_Oracle_Ante= 7.5795514288635575\n",
      "Oracle: iter= 40 ,cost_Oracle_Ante= 7.649737913496897\n",
      "Oracle: iter= 60 ,cost_Oracle_Ante= 7.687142534129683\n",
      "Oracle: iter= 80 ,cost_Oracle_Ante= 7.538072362481895\n",
      "OLS: iter= 20 ,cost_OLS_Ante= 7.616366491839338\n",
      "OLS: iter= 40 ,cost_OLS_Ante= 7.678577120489166\n",
      "OLS: iter= 60 ,cost_OLS_Ante= 7.724739603992886\n",
      "OLS: iter= 80 ,cost_OLS_Ante= 7.606127315236759\n",
      "DDR: iter= 20 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.615784699852257\n",
      "DDR: iter= 40 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.681061039577715\n",
      "DDR: iter= 60 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.728682900997908\n",
      "DDR: iter= 80 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.606552049350755\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=200_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "Oracle: iter= 20 ,cost_Oracle_Ante= 7.568595576154227\n",
      "Oracle: iter= 40 ,cost_Oracle_Ante= 7.6402415066648315\n",
      "Oracle: iter= 60 ,cost_Oracle_Ante= 7.685338939108604\n",
      "Oracle: iter= 80 ,cost_Oracle_Ante= 7.5394784360829075\n",
      "OLS: iter= 20 ,cost_OLS_Ante= 7.598285070875216\n",
      "OLS: iter= 40 ,cost_OLS_Ante= 7.665806009780974\n",
      "OLS: iter= 60 ,cost_OLS_Ante= 7.737731346810959\n",
      "OLS: iter= 80 ,cost_OLS_Ante= 7.556213683241631\n",
      "DDR: iter= 20 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.596774972957682\n",
      "DDR: iter= 40 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.6685338811919515\n",
      "DDR: iter= 60 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.738240757936326\n",
      "DDR: iter= 80 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.559019366615944\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=500_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "Oracle: iter= 20 ,cost_Oracle_Ante= 7.600547959775147\n",
      "Oracle: iter= 40 ,cost_Oracle_Ante= 7.621295415561454\n",
      "Oracle: iter= 60 ,cost_Oracle_Ante= 7.707593313989229\n",
      "Oracle: iter= 80 ,cost_Oracle_Ante= 7.527173976237703\n",
      "OLS: iter= 20 ,cost_OLS_Ante= 7.605356154159865\n",
      "OLS: iter= 40 ,cost_OLS_Ante= 7.631553640010719\n",
      "OLS: iter= 60 ,cost_OLS_Ante= 7.728519366653399\n",
      "OLS: iter= 80 ,cost_OLS_Ante= 7.546627488440326\n",
      "DDR: iter= 20 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.605356154159865\n",
      "DDR: iter= 40 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.631669594030116\n",
      "DDR: iter= 60 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.728345589032474\n",
      "DDR: iter= 80 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.546813627045379\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=1000_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "Oracle: iter= 20 ,cost_Oracle_Ante= 7.631876440274778\n",
      "Oracle: iter= 40 ,cost_Oracle_Ante= 7.597470938355042\n",
      "Oracle: iter= 60 ,cost_Oracle_Ante= 7.685270106809065\n",
      "Oracle: iter= 80 ,cost_Oracle_Ante= 7.562727244228381\n",
      "OLS: iter= 20 ,cost_OLS_Ante= 7.63315256734854\n",
      "OLS: iter= 40 ,cost_OLS_Ante= 7.602931255184767\n",
      "OLS: iter= 60 ,cost_OLS_Ante= 7.689431962971248\n",
      "OLS: iter= 80 ,cost_OLS_Ante= 7.571206456395033\n",
      "DDR: iter= 20 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.63315256734854\n",
      "DDR: iter= 40 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.603255947168193\n",
      "DDR: iter= 60 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.689569790066867\n",
      "DDR: iter= 80 ,mu= 0.5 ,lamb= 0.3 ,cost_DDR_Ante = 7.571414877907889\n"
     ]
    }
   ],
   "source": [
    "for num_train in num_train_all:\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    run_all_approaches(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15b7aff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=50_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "/Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=100_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "/Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=200_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "/Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=500_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "/Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data_JOC_R1/Shortest_Path/Various_Settings_coef_seed=1/2by2_Network_SPO_Data_Generation/data_size=1000_deg=1.0_e=0.5_d=4_p=5_x_dist=uniform_num_test=1000_diff_W/\n"
     ]
    }
   ],
   "source": [
    "regret_N_post = np.zeros(len(num_train_all)); h2h_N_post = np.zeros(len(num_train_all))\n",
    "regret_N_ante = np.zeros(len(num_train_all)); h2h_N_ante = np.zeros(len(num_train_all))\n",
    "mu = mu_all[0]\n",
    "lamb = lamb_all[0]\n",
    "_index = 0\n",
    "for num_train in num_train_all:\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "    print(DataPath)\n",
    "    \n",
    "    cost_Oracle_Post_all,cost_Oracle_Ante_all,cost_OLS_Post_all,cost_OLS_Ante_all,cost_DDR_Post_all,cost_DDR_Ante_all = load_cost_data(DataPath)\n",
    "    \n",
    "    # h2h_N_post[_index],regret_N_post[_index], h2h_N_ante[_index], regret_N_ante[_index] = calculate_h2h_regret(mu,lamb,iteration_all,\\\n",
    "    #                      cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,\\\n",
    "    #                         cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "    h2h_N_ante[_index], regret_N_ante[_index] = calculate_h2h_regret(mu,lamb,iteration_all,\\\n",
    "                         cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,\\\n",
    "                            cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "    _index = _index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc9e0d",
   "metadata": {},
   "source": [
    "#### Impact of number of feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = 1.0 # polynomial degree\n",
    "mis = deg # model misspecification\n",
    "e = 0.5 # scale of normal std or the range of uniform. For the error term\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "num_train = 100\n",
    "num_feat_all = [1,3,5,7,10,15]\n",
    "for num_feat in num_feat_all:\n",
    "    p = num_feat\n",
    "    if p != 5:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "        pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"DataPath:\", DataPath)\n",
    "\n",
    "        x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all \\\n",
    "        = Data_Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)\n",
    "\n",
    "        store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c52b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_feat in num_feat_all:\n",
    "    p = num_feat\n",
    "    if p != 5:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "        pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"DataPath:\", DataPath)        \n",
    "        run_all_approaches(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5739df",
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_P_post = np.zeros(len(num_feat_all)); h2h_P_post = np.zeros(len(num_feat_all))\n",
    "regret_P_ante = np.zeros(len(num_feat_all)); h2h_P_ante = np.zeros(len(num_feat_all))\n",
    "mu = mu_all[0]\n",
    "lamb = lamb_all[0]\n",
    "_index = 0\n",
    "for num_feat in num_feat_all:\n",
    "    p = num_feat\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "    print(\"DataPath:\", DataPath)        \n",
    "\n",
    "    cost_Oracle_Post_all,cost_Oracle_Ante_all,cost_OLS_Post_all,cost_OLS_Ante_all,cost_DDR_Post_all,cost_DDR_Ante_all = load_cost_data(DataPath)\n",
    "    \n",
    "    h2h_P_post[_index],regret_P_post[_index], h2h_P_ante[_index], regret_P_ante[_index] = calculate_h2h_regret(mu,lamb,iteration_all,\\\n",
    "                         cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,\\\n",
    "                            cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "    _index = _index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f666a3",
   "metadata": {},
   "source": [
    "#### Impact of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = 1.0 # polynomial degree\n",
    "mis = deg # model misspecification\n",
    "num_train = 100\n",
    "num_feat = 5\n",
    "p = num_feat\n",
    "e_all = [0.25,0.5,0.75,1.0]\n",
    "for e in e_all:\n",
    "    alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "    if e != 0.5:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "        pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"DataPath:\", DataPath)\n",
    "        x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all \\\n",
    "        = Data_Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)\n",
    "\n",
    "        store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d73514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in e_all:\n",
    "    alpha = e \n",
    "    if e != 0.5:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "        print(\"DataPath:\", DataPath)\n",
    "        run_all_approaches(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aee674",
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_e_post = np.zeros(len(e_all)); h2h_e_post = np.zeros(len(e_all))\n",
    "regret_e_ante = np.zeros(len(e_all)); h2h_e_ante = np.zeros(len(e_all))\n",
    "mu = mu_all[0]\n",
    "lamb = lamb_all[0]\n",
    "_index = 0\n",
    "for e in e_all:\n",
    "    alpha = e \n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "\n",
    "    cost_Oracle_Post_all,cost_Oracle_Ante_all,cost_OLS_Post_all,cost_OLS_Ante_all,cost_DDR_Post_all,cost_DDR_Ante_all = load_cost_data(DataPath)\n",
    "    \n",
    "    h2h_e_post[_index],regret_e_post[_index], h2h_e_ante[_index], regret_e_ante[_index] = calculate_h2h_regret(mu,lamb,iteration_all,\\\n",
    "                         cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,\\\n",
    "                            cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "    _index = _index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a7c33",
   "metadata": {},
   "source": [
    "#### Impact of model misspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0.5\n",
    "alpha = e\n",
    "num_train = 100\n",
    "num_feat = 5\n",
    "p = num_feat\n",
    "deg_all = [0.4,0.6,0.8,1.0,1.2,1.4,1.6,2.0,3.0]\n",
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    if deg != 1.0:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "        pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"DataPath:\", DataPath)\n",
    "\n",
    "        x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all \\\n",
    "        = Data_Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)\n",
    "\n",
    "        store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    if deg != 1.0:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "        print(\"DataPath:\", DataPath)\n",
    "        run_all_approaches(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_d_post = np.zeros(len(deg_all)); h2h_d_post = np.zeros(len(deg_all))\n",
    "regret_d_ante = np.zeros(len(deg_all)); h2h_d_ante = np.zeros(len(deg_all))\n",
    "mu = mu_all[0]\n",
    "lamb = lamb_all[0]\n",
    "_index = 0\n",
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "\n",
    "    cost_Oracle_Post_all,cost_Oracle_Ante_all,cost_OLS_Post_all,cost_OLS_Ante_all,cost_DDR_Post_all,cost_DDR_Ante_all = load_cost_data(DataPath)\n",
    "    \n",
    "    h2h_d_post[_index],regret_d_post[_index], h2h_d_ante[_index], regret_d_ante[_index] = calculate_h2h_regret(mu,lamb,iteration_all,\\\n",
    "                         cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,\\\n",
    "                            cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "    _index = _index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd40b43",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db9844",
   "metadata": {},
   "source": [
    "### Plot Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9dd2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_dir = DataPath_Parent + \"Result/\"\n",
    "pathlib.Path(Result_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "# p_indices = [0,1,3,4,5]\n",
    "# plt.plot(h2h_P_post[p_indices], regret_P_post[p_indices], color='green', marker = \"*\", label = 'p', linestyle = 'None')\n",
    "# plt.text(h2h_P_post[p_indices[0]] + 0.01, regret_P_post[p_indices[0]] - 0.005, 'p='+str(num_feat_all[p_indices[0]]), color='green')\n",
    "# plt.text(h2h_P_post[p_indices[1]] + 0.01, regret_P_post[p_indices[1]] - 0.005, 'p='+str(num_feat_all[p_indices[1]]), color='green')\n",
    "# plt.text(h2h_P_post[p_indices[2]] - 0.05, regret_P_post[p_indices[2]] - 0.005, 'p='+str(num_feat_all[p_indices[2]]), color='green')\n",
    "# plt.text(h2h_P_post[p_indices[3]] - 0.05, regret_P_post[p_indices[3]] - 0.005, 'p='+str(num_feat_all[p_indices[3]]), color='green')\n",
    "# plt.text(h2h_P_post[p_indices[4]] - 0.065, regret_P_post[p_indices[4]] - 0.005, 'p='+str(num_feat_all[p_indices[4]]), color='green')\n",
    "\n",
    "# plt.plot(h2h_d_post[0], regret_d_post[0], color='#003D7C', marker = \"o\", label = 'd', linestyle = 'None')\n",
    "# # plt.plot(h2h_d[1], mci_d[1], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[1], regret_d_post[1], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[2], regret_d_post[2], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[4], regret_d_post[4], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[5], regret_d_post[5], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[6], regret_d_post[6], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[7], regret_d_post[7], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[8], regret_d_post[8], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "\n",
    "\n",
    "# plt.text(h2h_d_post[0] + 0.01, regret_d_post[0] - 0.005, 'd = '+str(deg_all[0]), color='#003D7C')\n",
    "# # plt.text(h2h_d[1] + 0.007, mci_d[1] - 0.003, 'd = 15', color='#003D7C')\n",
    "# plt.text(h2h_d_post[1] + 0.01, regret_d_post[1] - 0.005, 'd = '+str(deg_all[1]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[2] - 0.065, regret_d_post[2] - 0.005, 'd = '+str(deg_all[2]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[4] + 0.01, regret_d_post[4] - 0.005, 'd = '+str(deg_all[4]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[5] - 0.065, regret_d_post[5] - 0.005, 'd = '+str(deg_all[5]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[6] - 0.065, regret_d_post[6] - 0.005, 'd = '+str(deg_all[6]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[7] - 0.065, regret_d_post[7] - 0.005, 'd = '+str(deg_all[7]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[8] - 0.065, regret_d_post[8] - 0.005, 'd = '+str(deg_all[8]), color='#003D7C')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(h2h_N_post[0], regret_N_post[0], color='#EF7C00', marker = \"^\", label = 'N',linestyle = 'None')\n",
    "plt.text(h2h_N_post[1] + 0.01, regret_N_post[1] - 0.01, 'Baseline', color='red')\n",
    "# plt.plot(h2h_N[1], mci_N[1], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_post[2], regret_N_post[2], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_post[3], regret_N_post[3], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_post[4], regret_N_post[4], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.text(h2h_N_post[0] + 0.01, regret_N_post[0] - 0.01, 'N = 50', color='#EF7C00')\n",
    "# plt.text(h2h_N[1] + 0.005, mci_N[1] - 0.003, 'N = 100', color='#EF7C00')\n",
    "plt.text(h2h_N_post[2] + 0.01, regret_N_post[2] - 0.01, 'N = 200', color='#EF7C00')\n",
    "plt.text(h2h_N_post[3] + 0.01, regret_N_post[3] - 0.01, 'N = 500', color='#EF7C00')\n",
    "plt.text(h2h_N_post[4] + 0.01, regret_N_post[4] - 0.01, 'N = 1000', color='#EF7C00')\n",
    "\n",
    "\n",
    "# plt.plot(h2h_e_post[0], regret_e_post[0], color='grey', marker = \"d\", label = r'$\\alpha$',linestyle = 'None')\n",
    "# # plt.plot(h2h_alpha[1], mci_alpha[1], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.plot(h2h_e_post[2], regret_e_post[2], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.plot(h2h_e_post[3], regret_e_post[3], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.text(h2h_e_post[0] + 0.01, regret_e_post[0] - 0.01, r'$\\alpha$ = 0.25', color='grey')\n",
    "# # plt.text(h2h_alpha[1] + 0.005, mci_alpha[1] - 0.005, r'$\\alpha$ = 1', color='grey')\n",
    "# plt.text(h2h_e_post[2] - 0.075, regret_e_post[2] - 0.01, r'$\\alpha$ = 0.75', color='grey')\n",
    "# plt.text(h2h_e_post[3] + 0.01, regret_e_post[3] - 0.01, r'$\\alpha$ = 1.0', color='grey')\n",
    "\n",
    "plt.vlines(0.5, 0.0, 0.7, linestyle=\"dashed\", alpha = 0.8,color = 'k')\n",
    "plt.hlines(0.0, 0.4, 0.8, linestyle=\"dashed\", alpha = 0.8,color = 'k')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Head-to-head')\n",
    "plt.ylabel('Regret reduction')\n",
    "\n",
    "plt.plot(h2h_N_post[1], regret_N_post[1], color='red', marker = \"o\", linestyle = 'None')\n",
    "# plt.annotate('Ridge vs. DDR', xy = (0.25,0.9), xycoords = 'axes fraction', bbox=dict(boxstyle=\"round\", fc=\"w\"), size = 10)\n",
    "\n",
    "# fig.savefig(DataPath_parent+'DDR_vs_OLS_DPSN.eps', format='eps', bbox_inches=\"tight\")\n",
    "fig.savefig(Result_dir +'DDR_vs_OLS_diff_settings_post.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6e04975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "# p_indices = [0,1,3,4,5]\n",
    "# plt.plot(h2h_P_ante[p_indices], regret_P_ante[p_indices], color='green', marker = \"*\", label = 'p', linestyle = 'None')\n",
    "# plt.text(h2h_P_ante[p_indices[0]] + 0.01, regret_P_ante[p_indices[0]] - 0.005, 'p='+str(num_feat_all[p_indices[0]]), color='green')\n",
    "# plt.text(h2h_P_ante[p_indices[1]] + 0.01, regret_P_ante[p_indices[1]] - 0.005, 'p='+str(num_feat_all[p_indices[1]]), color='green')\n",
    "# plt.text(h2h_P_ante[p_indices[2]] - 0.05, regret_P_ante[p_indices[2]] - 0.005, 'p='+str(num_feat_all[p_indices[2]]), color='green')\n",
    "# plt.text(h2h_P_ante[p_indices[3]] - 0.05, regret_P_ante[p_indices[3]] - 0.005, 'p='+str(num_feat_all[p_indices[3]]), color='green')\n",
    "# plt.text(h2h_P_ante[p_indices[4]] - 0.065, regret_P_ante[p_indices[4]] - 0.005, 'p='+str(num_feat_all[p_indices[4]]), color='green')\n",
    "\n",
    "# plt.plot(h2h_d_ante[0], regret_d_ante[0], color='#003D7C', marker = \"o\", label = 'd', linestyle = 'None')\n",
    "# # plt.plot(h2h_d[1], mci_d[1], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[1], regret_d_ante[1], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[2], regret_d_ante[2], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[4], regret_d_ante[4], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[5], regret_d_ante[5], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[6], regret_d_ante[6], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[7], regret_d_ante[7], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[8], regret_d_ante[8], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "\n",
    "\n",
    "# plt.text(h2h_d_ante[0] + 0.01, regret_d_ante[0] - 0.005, 'd = '+str(deg_all[0]), color='#003D7C')\n",
    "# # plt.text(h2h_d[1] + 0.007, mci_d[1] - 0.003, 'd = 15', color='#003D7C')\n",
    "# plt.text(h2h_d_ante[1] + 0.01, regret_d_ante[1] - 0.005, 'd = '+str(deg_all[1]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[2] - 0.065, regret_d_ante[2] - 0.005, 'd = '+str(deg_all[2]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[4] + 0.01, regret_d_ante[4] - 0.005, 'd = '+str(deg_all[4]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[5] - 0.065, regret_d_ante[5] - 0.005, 'd = '+str(deg_all[5]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[6] - 0.065, regret_d_ante[6] - 0.005, 'd = '+str(deg_all[6]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[7] - 0.065, regret_d_ante[7] - 0.005, 'd = '+str(deg_all[7]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[8] - 0.065, regret_d_ante[8] - 0.005, 'd = '+str(deg_all[8]), color='#003D7C')\n",
    "\n",
    "\n",
    "plt.plot(h2h_N_ante[0], regret_N_ante[0], color='#EF7C00', marker = \"^\", label = 'N',linestyle = 'None')\n",
    "plt.text(h2h_N_ante[1] + 0.01, regret_N_ante[1] - 0.01, 'Baseline', color='red')\n",
    "# plt.plot(h2h_N[1], mci_N[1], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_ante[2], regret_N_ante[2], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_ante[3], regret_N_ante[3], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_ante[4], regret_N_ante[4], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.text(h2h_N_ante[0] + 0.01, regret_N_ante[0] - 0.01, 'N = 50', color='#EF7C00')\n",
    "# plt.text(h2h_N[1] + 0.005, mci_N[1] - 0.003, 'N = 100', color='#EF7C00')\n",
    "plt.text(h2h_N_ante[2] + 0.01, regret_N_ante[2] - 0.01, 'N = 200', color='#EF7C00')\n",
    "plt.text(h2h_N_ante[3] + 0.01, regret_N_ante[3] - 0.01, 'N = 500', color='#EF7C00')\n",
    "plt.text(h2h_N_ante[4] + 0.01, regret_N_ante[4] - 0.01, 'N = 1000', color='#EF7C00')\n",
    "\n",
    "\n",
    "# plt.plot(h2h_e_ante[0], regret_e_ante[0], color='grey', marker = \"d\", label = r'$\\alpha$',linestyle = 'None')\n",
    "# # plt.plot(h2h_alpha[1], mci_alpha[1], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.plot(h2h_e_ante[2], regret_e_ante[2], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.plot(h2h_e_ante[3], regret_e_ante[3], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.text(h2h_e_ante[0] + 0.01, regret_e_ante[0] - 0.01, r'$\\alpha$ = 0.25', color='grey')\n",
    "# # plt.text(h2h_alpha[1] + 0.005, mci_alpha[1] - 0.005, r'$\\alpha$ = 1', color='grey')\n",
    "# plt.text(h2h_e_ante[2] - 0.075, regret_e_ante[2] - 0.01, r'$\\alpha$ = 0.75', color='grey')\n",
    "# plt.text(h2h_e_ante[3] + 0.01, regret_e_ante[3] - 0.01, r'$\\alpha$ = 1.0', color='grey')\n",
    "\n",
    "plt.vlines(0.5, 0.0, 0.7, linestyle=\"dashed\", alpha = 0.8,color = 'k')\n",
    "plt.hlines(0.0, 0.4, 0.8, linestyle=\"dashed\", alpha = 0.8,color = 'k')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Head-to-head')\n",
    "plt.ylabel('Regret reduction')\n",
    "\n",
    "plt.plot(h2h_N_ante[1], regret_N_ante[1], color='red', marker = \"o\", linestyle = 'None')\n",
    "# plt.annotate('Ridge vs. DDR', xy = (0.25,0.9), xycoords = 'axes fraction', bbox=dict(boxstyle=\"round\", fc=\"w\"), size = 10)\n",
    "\n",
    "# fig.savefig(DataPath_parent+'DDR_vs_OLS_DPSN.eps', format='eps', bbox_inches=\"tight\")\n",
    "fig.savefig(Result_dir +'DDR_vs_OLS_diff_settings_ante.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7dceaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2h_N_ante"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
