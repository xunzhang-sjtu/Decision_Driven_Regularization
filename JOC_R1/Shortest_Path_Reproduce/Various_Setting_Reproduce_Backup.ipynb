{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5423203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "from Performance import performance_evaluation\n",
    "perfs = performance_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907d7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump):\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,data_generation_process) \n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    np.random.seed(coef_seed)\n",
    "    # random.seed(coef_seed)\n",
    "    # seed_arr = random.sample(range(1, 10000 + 1), len(iteration_all))\n",
    "    x_test_all = {}; c_test_all = {}; x_train_all = {}; c_train_all = {}; W_star_all = {}; noise_train_all = {}; noise_test_all = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_iter = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_iter).mkdir(parents=True, exist_ok=True)\n",
    "        W_star = data_gen.generate_truth(DataPath_iter,lower, upper, p, d, iter,data_generation_process) \n",
    "        x_test_all[iter], c_test_all[iter], x_train_all[iter], c_train_all[iter], noise_train_all[iter],noise_test_all[iter],W_star_all[iter] \\\n",
    "        = data_gen.generate_samples(iter,DataPath_iter,p, d, num_test, num_train, alpha, W_star, mis, num_test, data_generation_process, x_dist, e_dist, x_low, x_up, x_mean, x_var, bump) \n",
    "    return x_test_all, c_test_all, x_train_all, c_train_all, noise_train_all,noise_test_all,W_star_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbc3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_Oracle(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,iteration_all,num_feat,data_generation_process):\n",
    "    cost_Oracle_Post = {}; cost_Oracle_Ante = {}\n",
    "    for iter in iteration_all:\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            # cost_Oracle_Post[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Post(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "            cost_Oracle_Ante[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_oracle_pred,cost_oracle_pred)\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_Oracle_Ante[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_oracle_pred,cost_oracle_pred)\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            # print(\"Oracle: iter=\",iter,\",cost_Oracle_Post=\",np.nanmean(cost_Oracle_Post[iter]),\",cost_Oracle_Ante=\",np.nanmean(cost_Oracle_Ante[iter]))\n",
    "            print(\"Oracle: iter=\",iter,\",cost_Oracle_Ante=\",np.nanmean(cost_Oracle_Ante[iter]))\n",
    "    return cost_Oracle_Post,cost_Oracle_Ante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a8c09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_OLS(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process):\n",
    "    from OLS import ols_method\n",
    "    ols_method_obj = ols_method()\n",
    "    W_ols_all = {}; w0_ols_all = {}; t_ols_all = {}; obj_ols_all = {}\n",
    "    cost_OLS_Post = {}; cost_OLS_Ante = {}\n",
    "    for iter in iteration_all:\n",
    "        # compute OLS performance\n",
    "        W_ols_all[iter], w0_ols_all[iter], t_ols_all[iter], obj_ols_all[iter] = ols_method_obj.ols_solver(\"\",x_train_all[iter], c_train_all[iter])\n",
    "        cost_dem = (W_ols_all[iter] @ x_test_all[iter].T).T + w0_ols_all[iter]\n",
    "\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            # cost_OLS_Post[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Post(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "            cost_OLS_Ante[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_dem,cost_oracle_pred)\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_OLS_Ante[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_dem,cost_oracle_pred)\n",
    "\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            # print(\"OLS: iter=\",iter,\",cost_OLS_Post =\",np.nanmean(cost_OLS_Post[iter]),\",cost_OLS_Ante=\",np.nanmean(cost_OLS_Ante[iter]))\n",
    "            print(\"OLS: iter=\",iter,\",cost_OLS_Ante=\",np.nanmean(cost_OLS_Ante[iter]))\n",
    "    return cost_OLS_Post,cost_OLS_Ante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99787333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_DDR(mu_all,lamb_all,arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process):\n",
    "    from DDR import DDR_method\n",
    "    ddr_object = DDR_method()\n",
    "    num_nodes = grid[0] * grid[0]\n",
    "\n",
    "    w0_ddr_dict = {}; W_ddr_dict = {}\n",
    "    cost_DDR_Post = {}; cost_DDR_Ante = {}\n",
    "    for iter in iteration_all:\n",
    "        for mu in mu_all:\n",
    "            for lamb in lamb_all:\n",
    "                w0_ddr_dict[iter,mu,lamb],W_ddr_dict[iter,mu,lamb],alpha_rst,obj_ddr = ddr_object.solve_DDR(arcs,lamb,mu,num_nodes,x_train_all[iter],c_train_all[iter])\n",
    "                cost_pred = (W_ddr_dict[iter,mu,lamb] @ x_test_all[iter].T).T + w0_ddr_dict[iter,mu,lamb]\n",
    "                if data_generation_process == \"SPO_Data_Generation\":\n",
    "                    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "                    cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "                    # cost_DDR_Post[iter,mu,lamb] = perfs.compute_SPO_out_of_sample_Cost_Ex_Post(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "                    cost_DDR_Ante[iter,mu,lamb] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_pred,cost_oracle_pred)\n",
    "\n",
    "                if data_generation_process == \"DDR_Data_Generation\":\n",
    "                    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "                    cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "                    cost_DDR_Ante[iter,mu,lamb] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_pred,cost_oracle_pred)\n",
    "\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            # print(\"DDR: iter=\",iter,\",mu=\",mu,\",lamb=\",lamb,\",cost_DDR_Post =\",np.nanmean(cost_DDR_Post[iter,mu,lamb]),\n",
    "            #       \",cost_DDR_Ante =\",np.nanmean(cost_DDR_Ante[iter,mu,lamb]))\n",
    "            print(\"DDR: iter=\",iter,\",mu=\",mu,\",lamb=\",lamb,\",cost_DDR_Ante =\",np.nanmean(cost_DDR_Ante[iter,mu,lamb]))\n",
    "    return cost_DDR_Post,cost_DDR_Ante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf174bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "                  arcs,grid,epo_runner,perfs,num_feat,mis,data_generation_process):\n",
    "    W_EPO_all = {}; w0_EPO_all = {}\n",
    "    cost_EPO_Post = {}; cost_EPO_Ante = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_seed = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        W_EPO_all[iter],w0_EPO_all[iter] = epo_runner.run(method_names,DataPath_seed,batch_size,num_feat,grid,num_epochs,\\\n",
    "                                        x_train_all[iter],c_train_all[iter],arcs)\n",
    "        \n",
    "        cost_pred = (W_EPO_all[iter] @ x_test_all[iter].T).T + w0_EPO_all[iter]\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            non_negative_cols = (cost_oracle_ori > 0).all(axis=0)\n",
    "            cost_oracle_ori = cost_oracle_ori[:,non_negative_cols]\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            \n",
    "            cost_pred = cost_pred[non_negative_cols,:]\n",
    "            # cost_EPO_Post[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Post(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "            cost_EPO_Ante[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_pred,cost_oracle_pred)\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_EPO_Ante[iter] = perfs.compute_SPO_out_of_sample_Cost_Ex_Ante(arcs, grid,cost_pred,cost_oracle_pred)\n",
    "\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            # print(method_names,\": iter=\",iter,\",cost_EPO_Post =\",np.nanmean(cost_EPO_Post[iter]),\",cost_EPO_Ante=\",np.nanmean(cost_EPO_Ante[iter]))\n",
    "            print(method_names,\": iter=\",iter,\",cost_EPO_Ante=\",np.nanmean(cost_EPO_Ante[iter]))\n",
    "    return cost_EPO_Post,cost_EPO_Ante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e673a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all):\n",
    "        with open(DataPath+'x_test_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(x_test_all,tf)\n",
    "        with open(DataPath+'c_test_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(c_test_all,tf)\n",
    "        with open(DataPath+'x_train_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(x_train_all,tf)\n",
    "        with open(DataPath+'c_train_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(c_train_all,tf)\n",
    "        with open(DataPath+'noise_train_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(noise_train_all,tf)\n",
    "        with open(DataPath+'noise_test_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(noise_test_all,tf)\n",
    "        with open(DataPath+'W_star_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(W_star_all,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49587a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cost_data(DataPath):\n",
    "    with open(DataPath+'cost_OLS_Post_all.pkl', \"rb\") as tf:\n",
    "        cost_OLS_Post_all = pickle.load(tf)\n",
    "    with open(DataPath+'cost_OLS_Ante_all.pkl', \"rb\") as tf:\n",
    "        cost_OLS_Ante_all = pickle.load(tf)\n",
    "\n",
    "    with open(DataPath+'cost_Oracle_Post_all.pkl', \"rb\") as tf:\n",
    "        cost_Oracle_Post_all = pickle.load(tf)\n",
    "    with open(DataPath+'cost_Oracle_Ante_all.pkl', \"rb\") as tf:\n",
    "        cost_Oracle_Ante_all = pickle.load(tf)\n",
    "\n",
    "    with open(DataPath+'cost_DDR_Post_all.pkl', \"rb\") as tf:\n",
    "        cost_DDR_Post_all = pickle.load(tf)\n",
    "    with open(DataPath+'cost_DDR_Ante_all.pkl', \"rb\") as tf:\n",
    "        cost_DDR_Ante_all = pickle.load(tf)\n",
    "\n",
    "    return cost_Oracle_Post_all,cost_Oracle_Ante_all,cost_OLS_Post_all,cost_OLS_Ante_all,cost_DDR_Post_all,cost_DDR_Ante_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_approaches(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process):\n",
    "        with open(DataPath+'x_test_all.pkl', \"rb\") as tf:\n",
    "            x_test_all = pickle.load(tf)\n",
    "        with open(DataPath+'c_test_all.pkl', \"rb\") as tf:\n",
    "            c_test_all = pickle.load(tf)\n",
    "        with open(DataPath+'x_train_all.pkl', \"rb\") as tf:\n",
    "            x_train_all = pickle.load(tf)\n",
    "        with open(DataPath+'c_train_all.pkl', \"rb\") as tf:\n",
    "            c_train_all = pickle.load(tf)\n",
    "        with open(DataPath+'noise_train_all.pkl', \"rb\") as tf:\n",
    "            noise_train_all = pickle.load(tf)\n",
    "        with open(DataPath+'noise_test_all.pkl', \"rb\") as tf:\n",
    "            noise_test_all = pickle.load(tf)\n",
    "        with open(DataPath+'W_star_all.pkl', \"rb\") as tf:\n",
    "            W_star_all = pickle.load(tf)\n",
    "\n",
    "        cost_Oracle_Post_all,cost_Oracle_Ante_all = Implement_Oracle(arcs, grid,mis,bump,\\\n",
    "                                                                    W_star_all,x_test_all,noise_test_all,\\\n",
    "                                                                    iteration_all,num_feat,data_generation_process)\n",
    "\n",
    "        cost_OLS_Post_all,cost_OLS_Ante_all = Implement_OLS(arcs, grid,mis,bump,\\\n",
    "                                                            W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,\\\n",
    "                                                            iteration_all,num_feat,data_generation_process)\n",
    "\n",
    "        cost_DDR_Post_all,cost_DDR_Ante_all = Implement_DDR(mu_all,lamb_all,arcs, grid,mis,bump,\\\n",
    "                                                                    W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,\\\n",
    "                                                                        iteration_all,num_feat,data_generation_process)\n",
    "\n",
    "        with open(DataPath+'cost_Oracle_Post_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_Oracle_Post_all,tf)\n",
    "        with open(DataPath+'cost_Oracle_Ante_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_Oracle_Ante_all,tf)\n",
    "\n",
    "        with open(DataPath+'cost_OLS_Post_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_OLS_Post_all,tf)\n",
    "        with open(DataPath+'cost_OLS_Ante_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_OLS_Ante_all,tf)\n",
    "\n",
    "        with open(DataPath+'cost_DDR_Post_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_DDR_Post_all,tf)\n",
    "        with open(DataPath+'cost_DDR_Ante_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_DDR_Ante_all,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd90c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_EPO_approaches(DataPath,method_names,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process):\n",
    "        with open(DataPath+'x_test_all.pkl', \"rb\") as tf:\n",
    "            x_test_all = pickle.load(tf)\n",
    "        with open(DataPath+'c_test_all.pkl', \"rb\") as tf:\n",
    "            c_test_all = pickle.load(tf)\n",
    "        with open(DataPath+'x_train_all.pkl', \"rb\") as tf:\n",
    "            x_train_all = pickle.load(tf)\n",
    "        with open(DataPath+'c_train_all.pkl', \"rb\") as tf:\n",
    "            c_train_all = pickle.load(tf)\n",
    "        with open(DataPath+'noise_train_all.pkl', \"rb\") as tf:\n",
    "            noise_train_all = pickle.load(tf)\n",
    "        with open(DataPath+'noise_test_all.pkl', \"rb\") as tf:\n",
    "            noise_test_all = pickle.load(tf)\n",
    "        with open(DataPath+'W_star_all.pkl', \"rb\") as tf:\n",
    "            W_star_all = pickle.load(tf)\n",
    "\n",
    "        batch_size = 20\n",
    "        num_epochs = 1000\n",
    "        from PYEPO import PyEPO_Method\n",
    "        epo_runner = PyEPO_Method()\n",
    "        method_names = [\"spo+\"]\n",
    "        cost_EPO_Post_all,cost_EPO_Ante_all = Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,\\\n",
    "                                                    W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "                                                    arcs,grid,epo_runner,perfs,num_feat,mis,data_generation_process)\n",
    "\n",
    "        with open(DataPath+'cost_'+method_names[0]+'_Post_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_EPO_Post_all,tf)\n",
    "        with open(DataPath+'cost_'+method_names[0]+'_Ante_all.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_EPO_Ante_all,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_compare2plus(c_item, c_base, c_oracle):\n",
    "    N = len(c_item)\n",
    "    c_diff = c_base - c_item\n",
    "    lbel = np.zeros((N,1))\n",
    "    \n",
    "    equals = np.sum(c_diff == 0)\n",
    "    wins = np.sum(c_diff > 0) # indicate num of c_item is lower than c_base\n",
    "    lose = np.sum(c_diff < 0)\n",
    "    \n",
    "    lbel[c_diff < 0] = 1\n",
    "    lbel[c_diff > 0] = -1\n",
    "    \n",
    "#     print(N, equals, wins, lose)\n",
    "    if N == equals:\n",
    "        win_ratio = 0.5\n",
    "    else:\n",
    "        win_ratio = wins/(N - equals)\n",
    "    cost_reduction = (np.nanmean(c_diff))/np.abs(np.nanmean(c_base))\n",
    "    if np.nanmean(c_base) - np.nanmean(c_oracle) <= 1e-6:\n",
    "        regret_reduction = 0.0\n",
    "    else:\n",
    "        regret_reduction = (np.nanmean(c_diff))/np.abs(np.nanmean(c_base) - np.nanmean(c_oracle))\n",
    "    return win_ratio, cost_reduction, regret_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e79d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_h2h_regret(mu,lamb,iteration_all,cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all):\n",
    "    ### Post Result\n",
    "    h2h_ = np.zeros(len(iteration_all)); cost_rd_ = np.zeros(len(iteration_all)); regret_rd_ = np.zeros(len(iteration_all))\n",
    "    # for iter_index in range(len(iteration_all)):\n",
    "    #     iter = iteration_all[iter_index]\n",
    "    #     h2h_[iter_index],cost_rd_[iter_index],regret_rd_[iter_index] = cross_compare2plus(cost_DDR_Post_all[iter,mu,lamb], cost_OLS_Post_all[iter], cost_Oracle_Post_all[iter])\n",
    "    # regret_post = np.round( len(regret_rd_[regret_rd_ > 0.0])/len(regret_rd_),4 )\n",
    "    # h2h_post = np.round( len(h2h_[h2h_ >= 0.5])/len(h2h_),4 )\n",
    "\n",
    "    ### Ante Result\n",
    "    h2h_ = np.zeros(len(iteration_all)); cost_rd_ = np.zeros(len(iteration_all)); regret_rd_ = np.zeros(len(iteration_all))\n",
    "    for iter_index in range(len(iteration_all)):\n",
    "        iter = iteration_all[iter_index]\n",
    "        h2h_[iter_index],cost_rd_[iter_index],regret_rd_[iter_index] = cross_compare2plus(cost_DDR_Ante_all[iter,mu,lamb], cost_OLS_Ante_all[iter], cost_Oracle_Ante_all[iter])\n",
    "    regret_ante = np.round( len(regret_rd_[regret_rd_ > 0.0])/len(regret_rd_),4 )\n",
    "    h2h_ante = np.round( len(h2h_[h2h_ >= 0.5])/len(h2h_),4 )\n",
    "    # return h2h_post,regret_post,h2h_ante,regret_ante\n",
    "    return h2h_ante,regret_ante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e7311",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782cc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = (2,2) # grid size\n",
    "from Network import network_design\n",
    "Network = network_design()\n",
    "arcs,arc_index_mapping = Network._getArcs(grid)\n",
    "\n",
    "num_test = 1000\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "num_nodes = grid[0]*grid[0]\n",
    "coef_seed = 1\n",
    "\n",
    "x_dist = 'uniform'\n",
    "e_dist = 'normal'\n",
    "x_low = -2\n",
    "x_up = 2\n",
    "x_mean = 2\n",
    "x_var = 2\n",
    "bump = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554bf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generation_process = \"SPO_Data_Generation\"\n",
    "# data_generation_process = \"DDR_Data_Generation\"\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "project_directory = os.path.dirname(os.path.dirname(os.path.dirname(parent_directory)))\n",
    "DataPath_Parent = project_directory + 'Various_Settings_' + data_generation_process + f'_coef_seed={coef_seed}/{grid[0]}by{grid[1]}_Network/'\n",
    "pathlib.Path(DataPath_Parent).mkdir(parents=True, exist_ok=True)\n",
    "print(\"DataPath_parent:\", DataPath_Parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25df629",
   "metadata": {},
   "source": [
    "#### Impact of sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318667b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = 5 # size of feature\n",
    "p = num_feat\n",
    "deg = 1.0 # polynomial degree\n",
    "mis = deg # model misspecification\n",
    "e = 0.5 # scale of normal std or the range of uniform. For the error term\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "iteration_all = np.arange(0,100)\n",
    "batch_size = 20\n",
    "num_epochs = 1000\n",
    "num_train_all = [50,100,200,500,1000]\n",
    "mu_all = np.asarray([0.5])\n",
    "lamb_all = np.asarray([0.3])\n",
    "for num_train in num_train_all:\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "    pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    \n",
    "    x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all \\\n",
    "    = Data_Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)\n",
    "\n",
    "    store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_train in num_train_all:\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    run_all_approaches(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_train in num_train_all:\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    method_names = [\"spo+\"]\n",
    "    run_EPO_approaches(DataPath,method_names,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_N_post = np.zeros(len(num_train_all)); h2h_N_post = np.zeros(len(num_train_all))\n",
    "regret_N_ante = np.zeros(len(num_train_all)); h2h_N_ante = np.zeros(len(num_train_all))\n",
    "mu = mu_all[0]\n",
    "lamb = lamb_all[0]\n",
    "_index = 0\n",
    "for num_train in num_train_all:\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "    print(DataPath)\n",
    "    \n",
    "    cost_Oracle_Post_all,cost_Oracle_Ante_all,cost_OLS_Post_all,cost_OLS_Ante_all,cost_DDR_Post_all,cost_DDR_Ante_all = load_cost_data(DataPath)\n",
    "    \n",
    "    # h2h_N_post[_index],regret_N_post[_index], h2h_N_ante[_index], regret_N_ante[_index] = calculate_h2h_regret(mu,lamb,iteration_all,\\\n",
    "    #                      cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,\\\n",
    "    #                         cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "    h2h_N_ante[_index], regret_N_ante[_index] = calculate_h2h_regret(mu,lamb,iteration_all,\\\n",
    "                         cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,\\\n",
    "                            cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "    _index = _index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc9e0d",
   "metadata": {},
   "source": [
    "#### Impact of number of feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = 1.0 # polynomial degree\n",
    "mis = deg # model misspecification\n",
    "e = 0.5 # scale of normal std or the range of uniform. For the error term\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "num_train = 100\n",
    "num_feat_all = [1,3,5,7,10,15]\n",
    "for num_feat in num_feat_all:\n",
    "    p = num_feat\n",
    "    if p != 5:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "        pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"DataPath:\", DataPath)\n",
    "\n",
    "        x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all \\\n",
    "        = Data_Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)\n",
    "\n",
    "        store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c52b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_feat in num_feat_all:\n",
    "    p = num_feat\n",
    "    if p != 5:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "        pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"DataPath:\", DataPath)        \n",
    "        run_all_approaches(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e41ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_feat in num_feat_all:\n",
    "    p = num_feat\n",
    "    if p != 5:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "        pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"DataPath:\", DataPath)    \n",
    "        run_EPO_approaches(DataPath,[\"spo+\"],arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5739df",
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_P_post = np.zeros(len(num_feat_all)); h2h_P_post = np.zeros(len(num_feat_all))\n",
    "regret_P_ante = np.zeros(len(num_feat_all)); h2h_P_ante = np.zeros(len(num_feat_all))\n",
    "mu = mu_all[0]\n",
    "lamb = lamb_all[0]\n",
    "_index = 0\n",
    "for num_feat in num_feat_all:\n",
    "    p = num_feat\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "    print(\"DataPath:\", DataPath)        \n",
    "\n",
    "    cost_Oracle_Post_all,cost_Oracle_Ante_all,cost_OLS_Post_all,cost_OLS_Ante_all,cost_DDR_Post_all,cost_DDR_Ante_all = load_cost_data(DataPath)\n",
    "    \n",
    "    h2h_P_post[_index],regret_P_post[_index], h2h_P_ante[_index], regret_P_ante[_index] = calculate_h2h_regret(mu,lamb,iteration_all,\\\n",
    "                         cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,\\\n",
    "                            cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "    _index = _index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f666a3",
   "metadata": {},
   "source": [
    "#### Impact of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = 1.0 # polynomial degree\n",
    "mis = deg # model misspecification\n",
    "num_train = 100\n",
    "num_feat = 5\n",
    "p = num_feat\n",
    "e_all = [0.25,0.5,0.75,1.0]\n",
    "for e in e_all:\n",
    "    alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "    if e != 0.5:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "        pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"DataPath:\", DataPath)\n",
    "        x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all \\\n",
    "        = Data_Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)\n",
    "\n",
    "        store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d73514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in e_all:\n",
    "    alpha = e \n",
    "    if e != 0.5:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "        print(\"DataPath:\", DataPath)\n",
    "        run_all_approaches(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15547b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in e_all:\n",
    "    alpha = e \n",
    "    if e != 0.5:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "        print(\"DataPath:\", DataPath)\n",
    "        run_EPO_approaches(DataPath,[\"spo+\"],arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aee674",
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_e_post = np.zeros(len(e_all)); h2h_e_post = np.zeros(len(e_all))\n",
    "regret_e_ante = np.zeros(len(e_all)); h2h_e_ante = np.zeros(len(e_all))\n",
    "mu = mu_all[0]\n",
    "lamb = lamb_all[0]\n",
    "_index = 0\n",
    "for e in e_all:\n",
    "    alpha = e \n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "\n",
    "    cost_Oracle_Post_all,cost_Oracle_Ante_all,cost_OLS_Post_all,cost_OLS_Ante_all,cost_DDR_Post_all,cost_DDR_Ante_all = load_cost_data(DataPath)\n",
    "    \n",
    "    h2h_e_post[_index],regret_e_post[_index], h2h_e_ante[_index], regret_e_ante[_index] = calculate_h2h_regret(mu,lamb,iteration_all,\\\n",
    "                         cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,\\\n",
    "                            cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "    _index = _index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a7c33",
   "metadata": {},
   "source": [
    "#### Impact of model misspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0.5\n",
    "alpha = e\n",
    "num_train = 100\n",
    "num_feat = 5\n",
    "p = num_feat\n",
    "deg_all = [0.4,0.6,0.8,1.0,1.2,1.4,1.6,2.0,3.0]\n",
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    if deg != 1.0:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "        pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"DataPath:\", DataPath)\n",
    "\n",
    "        x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all \\\n",
    "        = Data_Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)\n",
    "\n",
    "        store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    if deg != 1.0:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "        print(\"DataPath:\", DataPath)\n",
    "        run_all_approaches(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eaf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    if deg != 1.0:\n",
    "        DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "        print(\"DataPath:\", DataPath)\n",
    "        run_EPO_approaches(DataPath,[\"spo+\"],arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_d_post = np.zeros(len(deg_all)); h2h_d_post = np.zeros(len(deg_all))\n",
    "regret_d_ante = np.zeros(len(deg_all)); h2h_d_ante = np.zeros(len(deg_all))\n",
    "mu = mu_all[0]\n",
    "lamb = lamb_all[0]\n",
    "_index = 0\n",
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    DataPath = DataPath_Parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "\n",
    "    cost_Oracle_Post_all,cost_Oracle_Ante_all,cost_OLS_Post_all,cost_OLS_Ante_all,cost_DDR_Post_all,cost_DDR_Ante_all = load_cost_data(DataPath)\n",
    "    \n",
    "    h2h_d_post[_index],regret_d_post[_index], h2h_d_ante[_index], regret_d_ante[_index] = calculate_h2h_regret(mu,lamb,iteration_all,\\\n",
    "                         cost_DDR_Post_all,cost_OLS_Post_all,cost_Oracle_Post_all,\\\n",
    "                            cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "    _index = _index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd40b43",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db9844",
   "metadata": {},
   "source": [
    "### Plot Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dd2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_dir = DataPath_Parent + \"Result/\"\n",
    "pathlib.Path(Result_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "# p_indices = [0,1,3,4,5]\n",
    "# plt.plot(h2h_P_post[p_indices], regret_P_post[p_indices], color='green', marker = \"*\", label = 'p', linestyle = 'None')\n",
    "# plt.text(h2h_P_post[p_indices[0]] + 0.01, regret_P_post[p_indices[0]] - 0.005, 'p='+str(num_feat_all[p_indices[0]]), color='green')\n",
    "# plt.text(h2h_P_post[p_indices[1]] + 0.01, regret_P_post[p_indices[1]] - 0.005, 'p='+str(num_feat_all[p_indices[1]]), color='green')\n",
    "# plt.text(h2h_P_post[p_indices[2]] - 0.05, regret_P_post[p_indices[2]] - 0.005, 'p='+str(num_feat_all[p_indices[2]]), color='green')\n",
    "# plt.text(h2h_P_post[p_indices[3]] - 0.05, regret_P_post[p_indices[3]] - 0.005, 'p='+str(num_feat_all[p_indices[3]]), color='green')\n",
    "# plt.text(h2h_P_post[p_indices[4]] - 0.065, regret_P_post[p_indices[4]] - 0.005, 'p='+str(num_feat_all[p_indices[4]]), color='green')\n",
    "\n",
    "# plt.plot(h2h_d_post[0], regret_d_post[0], color='#003D7C', marker = \"o\", label = 'd', linestyle = 'None')\n",
    "# # plt.plot(h2h_d[1], mci_d[1], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[1], regret_d_post[1], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[2], regret_d_post[2], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[4], regret_d_post[4], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[5], regret_d_post[5], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[6], regret_d_post[6], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[7], regret_d_post[7], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_post[8], regret_d_post[8], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "\n",
    "\n",
    "# plt.text(h2h_d_post[0] + 0.01, regret_d_post[0] - 0.005, 'd = '+str(deg_all[0]), color='#003D7C')\n",
    "# # plt.text(h2h_d[1] + 0.007, mci_d[1] - 0.003, 'd = 15', color='#003D7C')\n",
    "# plt.text(h2h_d_post[1] + 0.01, regret_d_post[1] - 0.005, 'd = '+str(deg_all[1]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[2] - 0.065, regret_d_post[2] - 0.005, 'd = '+str(deg_all[2]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[4] + 0.01, regret_d_post[4] - 0.005, 'd = '+str(deg_all[4]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[5] - 0.065, regret_d_post[5] - 0.005, 'd = '+str(deg_all[5]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[6] - 0.065, regret_d_post[6] - 0.005, 'd = '+str(deg_all[6]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[7] - 0.065, regret_d_post[7] - 0.005, 'd = '+str(deg_all[7]), color='#003D7C')\n",
    "# plt.text(h2h_d_post[8] - 0.065, regret_d_post[8] - 0.005, 'd = '+str(deg_all[8]), color='#003D7C')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(h2h_N_post[0], regret_N_post[0], color='#EF7C00', marker = \"^\", label = 'N',linestyle = 'None')\n",
    "plt.text(h2h_N_post[1] + 0.01, regret_N_post[1] - 0.01, 'Baseline', color='red')\n",
    "# plt.plot(h2h_N[1], mci_N[1], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_post[2], regret_N_post[2], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_post[3], regret_N_post[3], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_post[4], regret_N_post[4], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.text(h2h_N_post[0] + 0.01, regret_N_post[0] - 0.01, 'N = 50', color='#EF7C00')\n",
    "# plt.text(h2h_N[1] + 0.005, mci_N[1] - 0.003, 'N = 100', color='#EF7C00')\n",
    "plt.text(h2h_N_post[2] + 0.01, regret_N_post[2] - 0.01, 'N = 200', color='#EF7C00')\n",
    "plt.text(h2h_N_post[3] + 0.01, regret_N_post[3] - 0.01, 'N = 500', color='#EF7C00')\n",
    "plt.text(h2h_N_post[4] + 0.01, regret_N_post[4] - 0.01, 'N = 1000', color='#EF7C00')\n",
    "\n",
    "\n",
    "# plt.plot(h2h_e_post[0], regret_e_post[0], color='grey', marker = \"d\", label = r'$\\alpha$',linestyle = 'None')\n",
    "# # plt.plot(h2h_alpha[1], mci_alpha[1], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.plot(h2h_e_post[2], regret_e_post[2], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.plot(h2h_e_post[3], regret_e_post[3], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.text(h2h_e_post[0] + 0.01, regret_e_post[0] - 0.01, r'$\\alpha$ = 0.25', color='grey')\n",
    "# # plt.text(h2h_alpha[1] + 0.005, mci_alpha[1] - 0.005, r'$\\alpha$ = 1', color='grey')\n",
    "# plt.text(h2h_e_post[2] - 0.075, regret_e_post[2] - 0.01, r'$\\alpha$ = 0.75', color='grey')\n",
    "# plt.text(h2h_e_post[3] + 0.01, regret_e_post[3] - 0.01, r'$\\alpha$ = 1.0', color='grey')\n",
    "\n",
    "plt.vlines(0.5, 0.0, 0.7, linestyle=\"dashed\", alpha = 0.8,color = 'k')\n",
    "plt.hlines(0.0, 0.4, 0.8, linestyle=\"dashed\", alpha = 0.8,color = 'k')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Head-to-head')\n",
    "plt.ylabel('Regret reduction')\n",
    "\n",
    "plt.plot(h2h_N_post[1], regret_N_post[1], color='red', marker = \"o\", linestyle = 'None')\n",
    "# plt.annotate('Ridge vs. DDR', xy = (0.25,0.9), xycoords = 'axes fraction', bbox=dict(boxstyle=\"round\", fc=\"w\"), size = 10)\n",
    "\n",
    "# fig.savefig(DataPath_parent+'DDR_vs_OLS_DPSN.eps', format='eps', bbox_inches=\"tight\")\n",
    "fig.savefig(Result_dir +'DDR_vs_OLS_diff_settings_post.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e04975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "# p_indices = [0,1,3,4,5]\n",
    "# plt.plot(h2h_P_ante[p_indices], regret_P_ante[p_indices], color='green', marker = \"*\", label = 'p', linestyle = 'None')\n",
    "# plt.text(h2h_P_ante[p_indices[0]] + 0.01, regret_P_ante[p_indices[0]] - 0.005, 'p='+str(num_feat_all[p_indices[0]]), color='green')\n",
    "# plt.text(h2h_P_ante[p_indices[1]] + 0.01, regret_P_ante[p_indices[1]] - 0.005, 'p='+str(num_feat_all[p_indices[1]]), color='green')\n",
    "# plt.text(h2h_P_ante[p_indices[2]] - 0.05, regret_P_ante[p_indices[2]] - 0.005, 'p='+str(num_feat_all[p_indices[2]]), color='green')\n",
    "# plt.text(h2h_P_ante[p_indices[3]] - 0.05, regret_P_ante[p_indices[3]] - 0.005, 'p='+str(num_feat_all[p_indices[3]]), color='green')\n",
    "# plt.text(h2h_P_ante[p_indices[4]] - 0.065, regret_P_ante[p_indices[4]] - 0.005, 'p='+str(num_feat_all[p_indices[4]]), color='green')\n",
    "\n",
    "# plt.plot(h2h_d_ante[0], regret_d_ante[0], color='#003D7C', marker = \"o\", label = 'd', linestyle = 'None')\n",
    "# # plt.plot(h2h_d[1], mci_d[1], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[1], regret_d_ante[1], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[2], regret_d_ante[2], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[4], regret_d_ante[4], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[5], regret_d_ante[5], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[6], regret_d_ante[6], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[7], regret_d_ante[7], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "# plt.plot(h2h_d_ante[8], regret_d_ante[8], color='#003D7C', marker = \"o\", linestyle = 'None')\n",
    "\n",
    "\n",
    "# plt.text(h2h_d_ante[0] + 0.01, regret_d_ante[0] - 0.005, 'd = '+str(deg_all[0]), color='#003D7C')\n",
    "# # plt.text(h2h_d[1] + 0.007, mci_d[1] - 0.003, 'd = 15', color='#003D7C')\n",
    "# plt.text(h2h_d_ante[1] + 0.01, regret_d_ante[1] - 0.005, 'd = '+str(deg_all[1]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[2] - 0.065, regret_d_ante[2] - 0.005, 'd = '+str(deg_all[2]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[4] + 0.01, regret_d_ante[4] - 0.005, 'd = '+str(deg_all[4]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[5] - 0.065, regret_d_ante[5] - 0.005, 'd = '+str(deg_all[5]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[6] - 0.065, regret_d_ante[6] - 0.005, 'd = '+str(deg_all[6]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[7] - 0.065, regret_d_ante[7] - 0.005, 'd = '+str(deg_all[7]), color='#003D7C')\n",
    "# plt.text(h2h_d_ante[8] - 0.065, regret_d_ante[8] - 0.005, 'd = '+str(deg_all[8]), color='#003D7C')\n",
    "\n",
    "\n",
    "plt.plot(h2h_N_ante[0], regret_N_ante[0], color='#EF7C00', marker = \"^\", label = 'N',linestyle = 'None')\n",
    "plt.text(h2h_N_ante[1] + 0.01, regret_N_ante[1] - 0.01, 'Baseline', color='red')\n",
    "# plt.plot(h2h_N[1], mci_N[1], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_ante[2], regret_N_ante[2], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_ante[3], regret_N_ante[3], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.plot(h2h_N_ante[4], regret_N_ante[4], color='#EF7C00', marker = \"^\",linestyle = 'None')\n",
    "plt.text(h2h_N_ante[0] + 0.01, regret_N_ante[0] - 0.01, 'N = 50', color='#EF7C00')\n",
    "# plt.text(h2h_N[1] + 0.005, mci_N[1] - 0.003, 'N = 100', color='#EF7C00')\n",
    "plt.text(h2h_N_ante[2] + 0.01, regret_N_ante[2] - 0.01, 'N = 200', color='#EF7C00')\n",
    "plt.text(h2h_N_ante[3] + 0.01, regret_N_ante[3] - 0.01, 'N = 500', color='#EF7C00')\n",
    "plt.text(h2h_N_ante[4] + 0.01, regret_N_ante[4] - 0.01, 'N = 1000', color='#EF7C00')\n",
    "\n",
    "\n",
    "# plt.plot(h2h_e_ante[0], regret_e_ante[0], color='grey', marker = \"d\", label = r'$\\alpha$',linestyle = 'None')\n",
    "# # plt.plot(h2h_alpha[1], mci_alpha[1], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.plot(h2h_e_ante[2], regret_e_ante[2], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.plot(h2h_e_ante[3], regret_e_ante[3], color='grey', marker = \"d\",linestyle = 'None')\n",
    "# plt.text(h2h_e_ante[0] + 0.01, regret_e_ante[0] - 0.01, r'$\\alpha$ = 0.25', color='grey')\n",
    "# # plt.text(h2h_alpha[1] + 0.005, mci_alpha[1] - 0.005, r'$\\alpha$ = 1', color='grey')\n",
    "# plt.text(h2h_e_ante[2] - 0.075, regret_e_ante[2] - 0.01, r'$\\alpha$ = 0.75', color='grey')\n",
    "# plt.text(h2h_e_ante[3] + 0.01, regret_e_ante[3] - 0.01, r'$\\alpha$ = 1.0', color='grey')\n",
    "\n",
    "plt.vlines(0.5, 0.0, 0.7, linestyle=\"dashed\", alpha = 0.8,color = 'k')\n",
    "plt.hlines(0.0, 0.4, 0.8, linestyle=\"dashed\", alpha = 0.8,color = 'k')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Head-to-head')\n",
    "plt.ylabel('Regret reduction')\n",
    "\n",
    "plt.plot(h2h_N_ante[1], regret_N_ante[1], color='red', marker = \"o\", linestyle = 'None')\n",
    "# plt.annotate('Ridge vs. DDR', xy = (0.25,0.9), xycoords = 'axes fraction', bbox=dict(boxstyle=\"round\", fc=\"w\"), size = 10)\n",
    "\n",
    "# fig.savefig(DataPath_parent+'DDR_vs_OLS_DPSN.eps', format='eps', bbox_inches=\"tight\")\n",
    "fig.savefig(Result_dir +'DDR_vs_OLS_diff_settings_ante.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dceaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2h_N_ante"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
