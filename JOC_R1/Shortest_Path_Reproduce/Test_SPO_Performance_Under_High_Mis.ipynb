{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5423203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "from Performance import performance_evaluation\n",
    "perfs = performance_evaluation()\n",
    "\n",
    "from Performance import H2h_Regret_Evaluation\n",
    "h2h_regret_eva = H2h_Regret_Evaluation()\n",
    "\n",
    "from Data import Data_Simulator\n",
    "DS_Obj = Data_Simulator()\n",
    "\n",
    "from Oracle import Oracle_Processing\n",
    "Oracle_Proc = Oracle_Processing()\n",
    "\n",
    "from OLS import OLS_Processing\n",
    "OLS_Proc = OLS_Processing()\n",
    "\n",
    "from DDR import DDR_Processing\n",
    "DDR_Proc = DDR_Processing()\n",
    "\n",
    "from PYEPO import EPO_Processing\n",
    "PYEPO_Proc = EPO_Processing()\n",
    "\n",
    "from Data_Load_Store import Load_Store_Methods\n",
    "Data_LSM = Load_Store_Methods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Sequential_Learning_Approaches as SLA\n",
    "import Integrated_Learning_Approaches as ILA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def Upright_Figure(all_x, all_y, figure_name, size = (5, 5), move = [-0.07, 0.07, 0.35, 0.55], \n",
    "                        ymin = 0, ymax=100,xmin = 0,xmax = 100):\n",
    "    \n",
    "    data = np.asarray([all_x,all_y])\n",
    "\n",
    "    ####### Obtain KDE  \n",
    "    #KDE for top marginal\n",
    "    kde_X = gaussian_kde(data[0])\n",
    "    #KDE for right marginal\n",
    "    kde_Y = gaussian_kde(data[1])\n",
    "\n",
    "    x = np.linspace(0, 100, 100)\n",
    "    y = np.linspace(ymin, ymax, 100)\n",
    "\n",
    "    dx = kde_X(x) # X-marginal density\n",
    "    dy = kde_Y(y) # Y-marginal density\n",
    "\n",
    "    #Define grid for subplots\n",
    "    gs = gridspec.GridSpec(2, 2, width_ratios=[3, 1], height_ratios = [1, 3])\n",
    "\n",
    "    ####### Create scatter plot\n",
    "    fig = plt.figure(figsize = size)\n",
    "    ax = plt.subplot(gs[1, 0])\n",
    "    cax = ax.scatter(data[0], data[1], s = 15, color='#003D7C', marker = \"o\", edgecolors = \"#EF7C00\")\n",
    "    plt.xlabel('Head-to-head (%)')\n",
    "\n",
    "    plt.ylabel('Regret reduction (%)') #pio\n",
    "    plt.vlines(50, ymin, ymax, linestyle=\"dashed\", alpha = 0.8,color = 'k')\n",
    "    plt.hlines(0, xmin, xmax, linestyle=\"dashed\", alpha = 0.8,color = 'k')\n",
    "\n",
    "    # ####### Create Y-marginal (right)\n",
    "    axr = plt.subplot(gs[1, 1], xticks = [], yticks = [], frameon = False)\n",
    "    axr.plot(dy, y, color = 'black')\n",
    "\n",
    "    axr.fill_betweenx(y, 0, dy, where = y <= 0.01, alpha = 1, color='#EF7C00')\n",
    "    axr.fill_betweenx(y, 0, dy, where = y >= 0, alpha = 1, color='#003D7C')\n",
    "\n",
    "    leftarea = np.round( sum(n <= 0 for n in all_y)/len(all_y),2 )\n",
    "    rightarea = np.round( sum(n > 0 for n in all_y)/len(all_y),2 )\n",
    "\n",
    "    axr.annotate(leftarea, xy=(0.15, abs(ymin)/(ymax - ymin) + move[0]), xycoords='axes fraction', bbox=dict(boxstyle=\"round\", fc=\"w\"), size = 12)\n",
    "    axr.annotate(rightarea, xy=(0.15, abs(ymin)/(ymax - ymin) + move[1]), xycoords='axes fraction', bbox=dict(boxstyle=\"round\", fc=\"w\"), size = 12)\n",
    "\n",
    "    # ####### Create X-marginal (top)\n",
    "    axt = plt.subplot(gs[0,0], frameon = False, yticks = [], xticks = [])\n",
    "    #base = pyplot.gca().transData\n",
    "    #rot = transforms.Affine2D().rotate_deg(180)\n",
    "    axt.plot(x, dx, color = 'black')\n",
    "    axt.fill_between(x, 0, dx, where = x >= 49.9, alpha= 1, color = '#003D7C')\n",
    "    axt.fill_between(x, 0, dx, where = x <= 50, alpha= 1, color = '#EF7C00')\n",
    "\n",
    "    #     axt.invert_yaxis()\n",
    "    leftarea = np.round( sum(n <= 50 for n in all_x)/len(all_x),2 )\n",
    "    rightarea = np.round( sum(n > 50 for n in all_x)/len(all_x),2 )\n",
    "\n",
    "    axt.annotate(leftarea, xy=(move[2], 0.15), xycoords='axes fraction', bbox=dict(boxstyle=\"round\", fc=\"w\"), size = 12)\n",
    "    axt.annotate(rightarea, xy=(move[3], 0.15), xycoords='axes fraction', bbox=dict(boxstyle=\"round\", fc=\"w\"), size = 12)\n",
    "\n",
    "    # ####### Bring the marginals closer to the scatter plot and save eps file\n",
    "    fig.tight_layout(pad = 1)\n",
    "    # # plt.savefig(figure_name + '.eps', format='eps')\n",
    "    plt.savefig(figure_name + '.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e7311",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782cc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = (3,3) # grid size\n",
    "from Network import network_design\n",
    "Network = network_design()\n",
    "arcs,arc_index_mapping = Network._getArcs(grid)\n",
    "\n",
    "num_test = 1000\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "num_nodes = grid[0]*grid[0]\n",
    "coef_seed = 1\n",
    "\n",
    "x_dist = 'uniform'\n",
    "e_dist = 'normal'\n",
    "x_low = -2\n",
    "x_up = 2\n",
    "x_mean = 2\n",
    "x_var = 2\n",
    "bump = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554bf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generation_process = \"SPO_Data_Generation\"\n",
    "# data_generation_process = \"DDR_Data_Generation\"\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "project_directory = os.path.dirname(os.path.dirname(os.path.dirname(parent_directory)))\n",
    "DataPath_Parent = project_directory + '/Data_JOC_R1/Shortest_Path_0619/SPO_High_Mis_' + data_generation_process + f'/{grid[0]}by{grid[1]}_grid/'\n",
    "pathlib.Path(DataPath_Parent).mkdir(parents=True, exist_ok=True)\n",
    "print(\"DataPath_parent:\", DataPath_Parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82492c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_dir = DataPath_Parent + \"Result/\"\n",
    "pathlib.Path(Result_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25df629",
   "metadata": {},
   "source": [
    "#### Impact of model misspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318667b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = 5 # size of feature\n",
    "p = num_feat\n",
    "e = 0.5 # scale of normal std or the range of uniform. For the error term\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "iteration_all = np.arange(0,100)\n",
    "batch_size = 20\n",
    "num_epochs = 1000\n",
    "num_train = 500\n",
    "mu_all = [0.75]\n",
    "lamb_all = [0.8]\n",
    "deg_all = [1.0,2.0, 4.0, 6.0, 8.0,12.0] # polynomial degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce605d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    DataPath = DataPath_Parent + f\"data_size={num_train}_deg={deg}_e={e}_p={p}_num_test={num_test}\"+\"_x_dist=\"+x_dist+\"_e_dist=\"+e_dist+\"/\"\n",
    "    pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    if os.path.exists(DataPath+\"x_test_all.pkl\"):\n",
    "        print(\"Already Exist\")\n",
    "    else:\n",
    "        x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all = \\\n",
    "        DS_Obj.Simulator(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)\n",
    "        Data_LSM.store_input_data(DataPath,x_test_all,c_test_all,x_train_all,c_train_all,noise_test_all,noise_train_all,W_star_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d09f4d",
   "metadata": {},
   "source": [
    "### Run Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    DataPath = DataPath_Parent + f\"data_size={num_train}_deg={deg}_e={e}_p={p}_num_test={num_test}\"+\"_x_dist=\"+x_dist+\"_e_dist=\"+e_dist+\"/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    if os.path.exists(DataPath+\"cost_Oracle_Ante_all.pkl\"):\n",
    "        print(\"Results already exist\")\n",
    "    else:\n",
    "        SLA.Run_Oracle(DataPath,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a0e9b",
   "metadata": {},
   "source": [
    "### Run OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    DataPath = DataPath_Parent + f\"data_size={num_train}_deg={deg}_e={e}_p={p}_num_test={num_test}\"+\"_x_dist=\"+x_dist+\"_e_dist=\"+e_dist+\"/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    if os.path.exists(DataPath+\"cost_OLS_Ante_all.pkl\"):\n",
    "        print(\"Results already exist\")\n",
    "    else:\n",
    "        SLA.Run_OLS(DataPath,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31321f",
   "metadata": {},
   "source": [
    "### Run DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    DataPath = DataPath_Parent + f\"data_size={num_train}_deg={deg}_e={e}_p={p}_num_test={num_test}\"+\"_x_dist=\"+x_dist+\"_e_dist=\"+e_dist+\"/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    if os.path.exists(DataPath+\"cost_DDR_Ante_all.pkl\"):\n",
    "        print(\"Results already exist\")\n",
    "    else:\n",
    "        ILA.Run_DDR(DataPath,mu_all,lamb_all,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e608d51b",
   "metadata": {},
   "source": [
    "### Run SPO+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ecc51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"spo+\"]\n",
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    DataPath = DataPath_Parent + f\"data_size={num_train}_deg={deg}_e={e}_p={p}_num_test={num_test}\"+\"_x_dist=\"+x_dist+\"_e_dist=\"+e_dist+\"/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    if os.path.exists(DataPath+\"cost_spo+_Ante_all.pkl\"):\n",
    "        print(\"Results already exist\")\n",
    "    else:\n",
    "        ILA.run_EPO_approaches(DataPath,method_names,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a219a9",
   "metadata": {},
   "source": [
    "### Run PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"pg\"]\n",
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    DataPath = DataPath_Parent + f\"data_size={num_train}_deg={deg}_e={e}_p={p}_num_test={num_test}\"+\"_x_dist=\"+x_dist+\"_e_dist=\"+e_dist+\"/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    if os.path.exists(DataPath+\"cost_pg_Ante_all.pkl\"):\n",
    "        print(\"Results already exist\")\n",
    "    else:\n",
    "        ILA.run_EPO_approaches(DataPath,method_names,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbcbdbc",
   "metadata": {},
   "source": [
    "### Run LTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9841ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"ltr\"]\n",
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    DataPath = DataPath_Parent + f\"data_size={num_train}_deg={deg}_e={e}_p={p}_num_test={num_test}\"+\"_x_dist=\"+x_dist+\"_e_dist=\"+e_dist+\"/\"\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    if os.path.exists(DataPath+\"cost_ltr_Ante_all.pkl\"):\n",
    "        print(\"Results already exist\")\n",
    "    else:\n",
    "        ILA.run_EPO_approaches(DataPath,method_names,arcs, grid,mis,bump,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd286d8",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b04ce27",
   "metadata": {},
   "source": [
    "##### DDR vs SPO+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Proportion performance\n",
    "regret_DDR_vs_SPO_d_ante_Dict = {}; h2h_DDR_vs_SPO_d_ante_Dict = {}\n",
    "for mu in mu_all:\n",
    "    for lamb in lamb_all:\n",
    "        regret_d_ante = np.zeros(len(deg_all)); h2h_d_ante = np.zeros(len(deg_all))\n",
    "        _index = 0\n",
    "        for deg in deg_all:\n",
    "            mis = deg # model misspecification\n",
    "            DataPath = DataPath_Parent + f\"data_size={num_train}_deg={deg}_e={e}_p={p}_num_test={num_test}\"+\"_x_dist=\"+x_dist+\"_e_dist=\"+e_dist+\"/\"\n",
    "            print(\"DataPath:\", DataPath)\n",
    "\n",
    "            cost_Oracle_Ante_all,cost_OLS_Ante_all,cost_DDR_Ante_all = Data_LSM.load_cost_data(DataPath)\n",
    "            with open(DataPath+'cost_spo+_Ante_all.pkl', \"rb\") as tf:\n",
    "                cost_SPO_Ante_all = pickle.load(tf)            \n",
    "            h2h_d_ante[_index], regret_d_ante[_index] = h2h_regret_eva.calculate_h2h_regret(mu,lamb,iteration_all,0,0,0,cost_DDR_Ante_all,cost_SPO_Ante_all,cost_Oracle_Ante_all)\n",
    "            _index = _index + 1\n",
    "        regret_DDR_vs_SPO_d_ante_Dict[mu,lamb] = regret_d_ante\n",
    "        h2h_DDR_vs_SPO_d_ante_Dict[mu,lamb] = h2h_d_ante\n",
    "with open(Result_dir+'regret_DDR_vs_SPO_d_ante_Dict.pkl', \"wb\") as tf:\n",
    "    pickle.dump(regret_DDR_vs_SPO_d_ante_Dict,tf)\n",
    "with open(Result_dir+'h2h_DDR_vs_SPO_d_ante_Dict.pkl', \"wb\") as tf:\n",
    "    pickle.dump(h2h_DDR_vs_SPO_d_ante_Dict,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b47937",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Result for ploting H2h and Regret reduction ####\n",
    "h2h_ddr_vs_ols_ante = {}; cost_rd_ddr_vs_ols_ante = {}; regret_rd_ddr_vs_ols_ante = {}\n",
    "h2h_ddr_vs_spo_ante = {}; cost_rd_ddr_vs_spo_ante = {}; regret_rd_ddr_vs_spo_ante = {}\n",
    "for deg in deg_all:\n",
    "    mis = deg # model misspecification\n",
    "    DataPath = DataPath_Parent + f\"data_size={num_train}_deg={deg}_e={e}_p={p}_num_test={num_test}\"+\"_x_dist=\"+x_dist+\"_e_dist=\"+e_dist+\"/\"\n",
    "    print(\"DataPath:\", DataPath)  \n",
    "    cost_Oracle_Ante_all,cost_OLS_Ante_all,cost_DDR_Ante_all = Data_LSM.load_cost_data(DataPath)\n",
    "    with open(DataPath+'cost_spo+_Ante_all.pkl', \"rb\") as tf:\n",
    "        cost_SPO_Ante_all = pickle.load(tf)\n",
    "    for mu in mu_all:\n",
    "        for lamb in lamb_all:\n",
    "            h2h_ddr_vs_ols_ante[deg,mu,lamb],regret_rd_ddr_vs_ols_ante[deg,mu,lamb] \\\n",
    "                = h2h_regret_eva.calculate_DDR_vs_Others_h2h_regret(mu,lamb,iteration_all,\\\n",
    "                                                                    cost_DDR_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "\n",
    "            h2h_ddr_vs_spo_ante[deg,mu,lamb],regret_rd_ddr_vs_spo_ante[deg,mu,lamb] \\\n",
    "                = h2h_regret_eva.calculate_DDR_vs_Others_h2h_regret(mu,lamb,iteration_all,\\\n",
    "                                                                    cost_DDR_Ante_all,cost_SPO_Ante_all,cost_Oracle_Ante_all)\n",
    "    print(\"deg = \",deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0547b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Figure_H2H_Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c57aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deg = deg_all[2]\n",
    "# mu = 0.75\n",
    "# lamb = 0.8\n",
    "# file_name = Result_dir + 'DDR_vs_SPO_mu='+str(mu)+\"_lamb=\"+str(lamb)+\"_ante_N=\"+str(num_train)\n",
    "# all_x = h2h_ddr_vs_spo_ante[deg,mu,lamb] * 100\n",
    "# all_y = regret_rd_ddr_vs_spo_ante[deg,mu,lamb] * 100\n",
    "# Figure_H2H_Regret.figure_plot_upright(all_x, all_y, file_name, size = (5, 5), move = [-0.07, 0.07, 0.35, 0.55], ysame = 0, yrange = [6,6], sublabel = '', ypio = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69959c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deg = deg_all[0]\n",
    "# mu = 0.75\n",
    "# lamb = 0.8\n",
    "# file_name = Result_dir + 'DDR_vs_SPO_mu='+str(mu)+\"_lamb=\"+str(lamb)+\"_ante_N=\"+str(num_train)\n",
    "# all_x = h2h_ddr_vs_spo_ante[deg,mu,lamb] * 100\n",
    "# all_y = regret_rd_ddr_vs_spo_ante[deg,mu,lamb] * 100\n",
    "# Figure_H2H_Regret.figure_plot_upright(all_x, all_y, file_name, size = (5, 5), move = [-0.07, 0.07, 0.35, 0.55], ysame = 0, yrange = [6,6], sublabel = '', ypio = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deg = deg_all[0]\n",
    "# mu = 0.75\n",
    "# lamb = 0.8\n",
    "# file_name = Result_dir + 'DDR_vs_OLS_mu='+str(mu)+\"_lamb=\"+str(lamb)+\"_ante_N=\"+str(num_train)\n",
    "# all_x = h2h_ddr_vs_ols_ante[deg,mu,lamb] * 100\n",
    "# all_y = regret_rd_ddr_vs_ols_ante[deg,mu,lamb] * 100\n",
    "# Figure_H2H_Regret.figure_plot_upright(all_x, all_y, file_name, size = (5, 5), move = [-0.07, 0.07, 0.35, 0.55], ysame = 0, yrange = [6,6], sublabel = '', ypio = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53919454",
   "metadata": {},
   "source": [
    "### SPO+ vs OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41372f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_compare2plus(c_item, c_base, c_oracle):\n",
    "    N = len(c_item)\n",
    "    c_diff = c_base - c_item\n",
    "    lbel = np.zeros((N,1))\n",
    "    \n",
    "    equals = np.sum(c_diff == 0)\n",
    "    wins = np.sum(c_diff > 0) # indicate num of c_item is lower than c_base\n",
    "    lose = np.sum(c_diff < 0)\n",
    "    \n",
    "    lbel[c_diff < 0] = 1\n",
    "    lbel[c_diff > 0] = -1\n",
    "    \n",
    "#     print(N, equals, wins, lose)\n",
    "    if N == equals:\n",
    "        win_ratio = 0.5\n",
    "    else:\n",
    "        win_ratio = wins/(N - equals)\n",
    "    cost_reduction = (np.nanmean(c_diff))/np.abs(np.nanmean(c_base))\n",
    "    if np.nanmean(c_base) - np.nanmean(c_oracle) <= 1e-6:\n",
    "        regret_reduction = 0.0\n",
    "    else:\n",
    "        regret_reduction = (np.nanmean(c_diff))/np.abs(np.nanmean(c_base) - np.nanmean(c_oracle))\n",
    "    return win_ratio, cost_reduction, regret_reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_A_vs_B_h2h_regret(iteration_all,cost_A,cost_other_all,cost_Oracle_Ante_all):\n",
    "    \n",
    "    h2h_ = np.zeros(len(iteration_all)); cost_rd_ = np.zeros(len(iteration_all)); regret_rd_ = np.zeros(len(iteration_all))\n",
    "    for iter_index in range(len(iteration_all)):\n",
    "        iter = iteration_all[iter_index]\n",
    "        h2h_[iter_index],cost_rd_[iter_index],regret_rd_[iter_index] = cross_compare2plus(cost_A[iter], cost_other_all[iter], cost_Oracle_Ante_all[iter])\n",
    "\n",
    "    # return h2h_post,regret_post,h2h_ante,regret_ante\n",
    "    return h2h_,regret_rd_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2h_spo_vs_ols_ante = {}; cost_rd_spo_vs_ols_ante = {}; regret_rd_spo_vs_ols_ante = {}\n",
    "# for deg in deg_all:\n",
    "#     mis = deg # model misspecification\n",
    "#     DataPath = DataPath_Parent + f\"data_size={num_train}_deg={deg}_e={e}_p={p}_num_test={num_test}\"+\"_x_dist=\"+x_dist+\"_e_dist=\"+e_dist+\"/\"\n",
    "#     print(\"DataPath:\", DataPath)  \n",
    "#     cost_Oracle_Ante_all,cost_OLS_Ante_all,cost_DDR_Ante_all = Data_LSM.load_cost_data(DataPath)\n",
    "#     with open(DataPath+'cost_spo+_Ante_all.pkl', \"rb\") as tf:\n",
    "#         cost_SPO_Ante_all = pickle.load(tf)\n",
    "#     h2h_spo_vs_ols_ante[deg],regret_rd_spo_vs_ols_ante[deg] = calculate_A_vs_B_h2h_regret(iteration_all,cost_SPO_Ante_all,cost_OLS_Ante_all,cost_Oracle_Ante_all)\n",
    "#     print(\"deg = \",deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deg = deg_all[2]\n",
    "# mu = 0.75\n",
    "# lamb = 0.8\n",
    "# file_name = Result_dir + 'SPO_vs_OLS_mu='+str(mu)+\"_lamb=\"+str(lamb)+\"_ante_N=\"+str(num_train)\n",
    "# all_x = h2h_spo_vs_ols_ante[deg] * 100\n",
    "# all_y = regret_rd_spo_vs_ols_ante[deg] * 100\n",
    "# Figure_H2H_Regret.figure_plot_upright(all_x, all_y, file_name, size = (5, 5), move = [-0.07, 0.07, 0.35, 0.55], ysame = 0, yrange = [6,6], sublabel = '', ypio = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
