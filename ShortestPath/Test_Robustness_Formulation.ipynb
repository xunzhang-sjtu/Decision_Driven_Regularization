{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "from gurobipy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_generation_process = \"SPO_Data_Generation\"\n",
    "data_generation_process = \"DDR_Data_Generation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyepo\n",
    "# generate data\n",
    "grid = (3,3) # grid size\n",
    "num_train = 50 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "num_test = 1000\n",
    "deg = 1.0 # polynomial degree\n",
    "e = 10 # scale of normal std or the range of uniform. For the error term\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "p = num_feat # num of features\n",
    "d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "mis = deg # model misspecification\n",
    "coef_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grandparent_directory: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Code_MacBook\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data/Test_0324DDR_Data_Generation/\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "grandparent_directory = os.path.dirname(parent_directory)\n",
    "DataPath = os.path.dirname(grandparent_directory) + '/Data/Test_0324' + data_generation_process + \"/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "print(\"grandparent_directory:\", grandparent_directory)\n",
    "print(\"DataPath:\", DataPath)\n",
    "DataPath = DataPath + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_coef_seed=\"+str(coef_seed)+\"/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data(DataPath,lower, upper, p, d, coef_seed,seed_all,num_test, num_train, alpha,mis,data_generation_process):\n",
    "# #  ****** Coef generation *********\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,version = 0) \n",
    "\n",
    "    x_test_all = {}; c_test_all = {}; x_train_all = {}; c_train_all = {}; W_star_all = {}\n",
    "    for seed in seed_all:\n",
    "        DataPath_seed = DataPath +\"Seed=\"+str(seed)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        # #  ****** Data generation *********\n",
    "        x_test_all[seed], c_test_all[seed], x_train_all[seed], c_train_all[seed], W_star_all[seed] = data_gen.generate_samples(seed,DataPath_seed,p, d, num_test, num_train, alpha, W_star, mis, thres = 10, \n",
    "                                version = data_generation_process, x_dist = 'normal', e_dist = 'normal', x_low = 0, x_up = 2, x_mean = 2, x_var = 0.25, bump = 100) \n",
    "        # print()\n",
    "    return x_test_all, c_test_all, x_train_all, c_train_all, W_star_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getArcs(grid):\n",
    "    arcs = []\n",
    "    for i in range(grid[0]):\n",
    "        # edges on rows\n",
    "        for j in range(grid[1] - 1):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + 1))\n",
    "        # edges in columns\n",
    "        if i == grid[0] - 1:\n",
    "            continue\n",
    "        for j in range(grid[1]):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + grid[1]))\n",
    "\n",
    "    arc_index_mapping = {}\n",
    "    for i in range(len(arcs)):\n",
    "        arc = arcs[i]\n",
    "        arc_index_mapping[arc] = i\n",
    "\n",
    "    return arcs,arc_index_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsome import ro\n",
    "from rsome import grb_solver as grb\n",
    "import rsome as rso\n",
    "from rsome import cpt_solver as cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the model with OLS estimation, the objective can be used as target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\min \\frac{1}{N} \\sum_{n \\in [N]}[\\mu y_{n}^{\\top}\\tilde{z}_{n} + (1 - \\mu )y_{n}^\\top f(\\tilde{x}_{n},w^{OLS})]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Solve_DDR_inner(arcs,arc_index_mapping,mu,num_train,num_arcs,c_train,x_train,W_ols,w0_ols,grid):\n",
    "    model = ro.Model()            # create an RSOME model\n",
    "    y = model.dvar((num_train,num_arcs))\n",
    "    t = model.dvar()\n",
    "    weight_sum = model.dvar(num_train)                   \n",
    "\n",
    "    for i in range(num_train):\n",
    "        model.st(weight_sum[i] == mu * (y[i,:] @ c_train[i,:]) + (1 - mu) *  y[i,:] @ (W_ols @ x_train[i,:] + w0_ols))\n",
    "    model.st(t == weight_sum.sum() * (1/num_train))\n",
    "    model.st(y >= 0)\n",
    "\n",
    "    # shortest path constraints\n",
    "    for n in range(num_train):\n",
    "        for i in range(grid[0]):\n",
    "            for j in range(grid[1]):\n",
    "                v = i * grid[1] + j\n",
    "                expr = 0\n",
    "                for arc in arcs:\n",
    "                    # flow in\n",
    "                    if v == arc[1]:\n",
    "                        expr += y[n,arc_index_mapping[arc]]\n",
    "                    # flow out\n",
    "                    elif v == arc[0]:\n",
    "                        expr -= y[n,arc_index_mapping[arc]]\n",
    "                # source\n",
    "                if i == 0 and j == 0:\n",
    "                    model.st(expr == -1)\n",
    "                # sink\n",
    "                elif i == grid[0] - 1 and j == grid[0] - 1:\n",
    "                    model.st(expr == 1)\n",
    "                # transition\n",
    "                else:\n",
    "                    model.st(expr == 0)\n",
    "\n",
    "    model.min(t) \n",
    "\n",
    "    model.solve(grb)\n",
    "    y_sol = y.get()\n",
    "    obj = model.obj()\n",
    "    # print(\"obj = \",obj)\n",
    "\n",
    "    # i = 1\n",
    "    # path = []\n",
    "    # for j in range(num_arcs):\n",
    "    #     if y_sol[i,j] > 0:\n",
    "    #         path.append(arcs[j])\n",
    "    # print(\"The\",i,\"Sample: shortest path = \",path)\n",
    "    return obj,y_sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve Sub-RDDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_sub_rddr(arcs,arc_index_mapping,mu,rho,num_train,num_arcs,c_train,x_train,grid,is_binary):\n",
    "    model = ro.Model()            # create an RSOME model\n",
    "    if is_binary:\n",
    "        y = model.dvar((num_train,num_arcs),vtype='B')\n",
    "    else:\n",
    "        y = model.dvar((num_train,num_arcs))\n",
    "    t = model.dvar()\n",
    "    gamma = model.dvar()\n",
    "    delta = model.dvar((num_train,num_arcs))\n",
    "    delta_vector = model.dvar(num_train * num_arcs)\n",
    "    weight_sum = model.dvar(num_train)                   \n",
    "\n",
    "    for i in range(num_train):\n",
    "        model.st(weight_sum[i] == mu * (y[i,:] @ c_train[i,:]) + (1 - mu) *  delta[i,:] @ c_train[i,:])\n",
    "    model.st(y >= 0)\n",
    "    model.st(t >= weight_sum.sum() * (1/num_train) + ((1-mu)/num_train)*rho*gamma)\n",
    "\n",
    "    for j in range(num_arcs):\n",
    "        model.st(delta[:,j].sum() == y[:,j].sum())\n",
    "        model.st(x_train.T @ delta[:,j] == x_train.T @ y[:,j])\n",
    "\n",
    "    index = 0\n",
    "    for i in range(num_train):\n",
    "        for j in range(num_arcs):\n",
    "            model.st(delta_vector[index] == delta[i,j])\n",
    "            index = index + 1\n",
    "    model.st(rso.norm(delta_vector,2) <= gamma)        # a constraint with 2-norm terms\n",
    "    model.st(gamma >= 0)\n",
    "\n",
    "\n",
    "    # shortest path constraints\n",
    "    for n in range(num_train):\n",
    "        for i in range(grid[0]):\n",
    "            for j in range(grid[1]):\n",
    "                v = i * grid[1] + j\n",
    "                expr = 0\n",
    "                for arc in arcs:\n",
    "                    # flow in\n",
    "                    if v == arc[1]:\n",
    "                        expr += y[n,arc_index_mapping[arc]]\n",
    "                    # flow out\n",
    "                    elif v == arc[0]:\n",
    "                        expr -= y[n,arc_index_mapping[arc]]\n",
    "                # source\n",
    "                if i == 0 and j == 0:\n",
    "                    model.st(expr == -1)\n",
    "                # sink\n",
    "                elif i == grid[0] - 1 and j == grid[0] - 1:\n",
    "                    model.st(expr == 1)\n",
    "                # transition\n",
    "                else:\n",
    "                    model.st(expr == 0)\n",
    "\n",
    "    model.min(t) \n",
    "    model.solve(cpt,display=False,log=False)\n",
    "    y_sol = y.get()\n",
    "    obj = model.obj()\n",
    "    # print(\"obj = \",obj)\n",
    "    return obj,y_sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RobustW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_robustW(mu,rho,num_train,num_arcs,num_feat,c_train,x_train,y_sol):\n",
    "    model = ro.Model()            # create an RSOME model\n",
    "\n",
    "    W_DDR = model.dvar((num_arcs,num_feat))\n",
    "    W0_DDR = model.dvar(num_arcs)\n",
    "    norm_vector = model.dvar(num_train*num_arcs)\n",
    "    t = model.dvar()\n",
    "    weight_sum = model.dvar(num_train)                   \n",
    "\n",
    "    for i in range(num_train):\n",
    "        model.st(weight_sum[i] == mu * (y_sol[i,:] @ c_train[i,:]) + (1 - mu) *  y_sol[i,:] @ (W_DDR @ x_train[i,:] + W0_DDR))\n",
    "    model.st(t == weight_sum.sum() * (1/num_train))\n",
    "\n",
    "    for i in range(num_train):\n",
    "        model.st(norm_vector[i*num_arcs:(i+1)*num_arcs] == c_train[i,:] - W_DDR @ x_train[i,:] - W0_DDR)\n",
    "    model.st(rso.norm(norm_vector,2) <= rho)\n",
    "\n",
    "    model.max(t) \n",
    "\n",
    "    model.solve(cpt,display=False,log=False)\n",
    "    obj = model.obj()\n",
    "    # print(\"obj = \",obj)\n",
    "    W_DDR_val = W_DDR.get()\n",
    "    W0_DDR_val = W0_DDR.get()\n",
    "    return obj,W_DDR_val,W0_DDR_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute out-of-sample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcs,arc_index_mapping = _getArcs(grid)\n",
    "num_arcs = len(arcs)\n",
    "\n",
    "seed_all = np.arange(1,10)\n",
    "# obtain data\n",
    "x_test_all, c_test_all, x_train_all, c_train_all, W_star_all = Prepare_Data(DataPath,lower, upper, p, d, coef_seed,seed_all,num_test, num_train, alpha,mis,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OLS import ols_method\n",
    "ols_method_obj = ols_method()\n",
    "from Peformance import performance_evaluation\n",
    "perfs = performance_evaluation()\n",
    "W_ols_all = {}; w0_ols_all = {}; t_ols_all = {}; obj_ols_all = {}; rho_lb_all = {}\n",
    "cost_OLS_all = {}; cost_Oracle_all = {}\n",
    "\n",
    "for seed in seed_all:\n",
    "    # compute OLS performance\n",
    "    W_ols_all[seed], w0_ols_all[seed], t_ols_all[seed], obj_ols_all[seed] = ols_method_obj.ols_solver(\"\",x_train_all[seed], c_train_all[seed])\n",
    "    cost_OLS_all[seed] = perfs.compute_Cost_with_Prediction(arcs,w0_ols_all[seed],W_ols_all[seed], grid,c_test_all[seed],x_test_all[seed])\n",
    "    cost_Oracle_all[seed] = perfs.compute_Oracel_Cost(arcs, grid,c_test_all[seed])\n",
    "\n",
    "    # obtain the lowest rho\n",
    "    # is_binary = False\n",
    "    rho_lb_all[seed] =  np.sqrt(obj_ols_all[seed] * num_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def obtain_out_of_sample_performance(seed,mu,rho_lb,rho_coef_all,is_binary,arcs,arc_index_mapping,grid,x_train_all,c_train_all,x_test_all,c_test_all,cost_OLS,cost_Oracle,perfs):\n",
    "    x_train = x_train_all[seed]\n",
    "    c_train = c_train_all[seed]\n",
    "    x_test = x_test_all[seed]\n",
    "    c_test = c_test_all[seed]\n",
    "\n",
    "    regret_arr = np.zeros(len(rho_coef_all))\n",
    "    rho_index = 0\n",
    "    for rho_coef in rho_coef_all:\n",
    "        rho = rho_lb + rho_coef * rho_lb\n",
    "    \n",
    "        obj_rddr,y_sol_rddr = solve_sub_rddr(arcs,arc_index_mapping,mu,rho,num_train,num_arcs,c_train,x_train,grid,is_binary)\n",
    "        obj,W_DDR,W0_DDR = solve_robustW(mu,rho,num_train,num_arcs,num_feat,c_train,x_train,y_sol_rddr)\n",
    "        cost_DDR = perfs.compute_Cost_with_Prediction(arcs,W0_DDR,W_DDR, grid,c_test,x_test)\n",
    "        regret = (np.nanmean(cost_OLS) - np.nanmean(cost_DDR) )/(np.nanmean(cost_OLS) - np.nanmean(cost_Oracle)) * 100\n",
    "        # print(\"seed=\",seed,\",mu=\",mu,\"rho=\",rho,\",regret=\",np.round(regret,4))\n",
    "        regret_arr[rho_index] = regret\n",
    "        rho_index = rho_index +1\n",
    "    return regret_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed= 1 ,mu= 0.9 [-0.0019 -0.1743 -0.2913 -0.3863 -0.4903 -0.5778 -0.5942 -0.5977 -0.7287\n",
      " -0.7206]\n",
      "seed= 2 ,mu= 0.9 [ 0.0157 -0.0199  0.1612 -0.0014  0.0427  0.1889  0.3125 -0.1027 -0.312\n",
      " -0.3616]\n",
      "seed= 3 ,mu= 0.9 [ 0.     -0.1973 -0.3986 -0.3983 -0.5831 -0.6918 -0.65   -0.6695 -0.6948\n",
      " -0.6128]\n",
      "seed= 4 ,mu= 0.9 [0.     0.0626 0.1355 0.2046 0.4023 0.6728 0.7917 0.8667 1.0274 1.1376]\n",
      "seed= 5 ,mu= 0.9 [ 0.0081  0.4371  0.5617  0.6825  0.4423  0.4144  0.282  -0.0781 -0.0592\n",
      " -0.1689]\n",
      "seed= 6 ,mu= 0.9 [-0.0014  0.0159 -0.1927 -0.3533 -0.4456 -0.2342 -0.0657 -0.0776  0.1227\n",
      "  0.0705]\n",
      "seed= 7 ,mu= 0.9 [ 0.0174 -0.1483 -0.3735 -0.2396 -0.2997 -0.3003 -0.2603 -0.2294 -0.4788\n",
      " -0.639 ]\n",
      "seed= 8 ,mu= 0.9 [-0.0219  0.8786  0.9337  1.389   1.4608  1.967   2.161   2.1011  1.9713\n",
      "  1.8977]\n",
      "seed= 9 ,mu= 0.9 [-0.0027 -0.1271 -0.1705 -0.103  -0.1774 -0.2314 -0.3167 -0.4135 -0.3666\n",
      " -0.4807]\n"
     ]
    }
   ],
   "source": [
    "mu = 0.9\n",
    "rho_coef_all = np.arange(0.0,0.01,0.001)\n",
    "is_binary = False\n",
    "regret_all = {}\n",
    "for seed in seed_all:\n",
    "    regret_all[seed,mu] = obtain_out_of_sample_performance(seed,mu,rho_lb_all[seed],rho_coef_all,is_binary,arcs,arc_index_mapping,grid,x_train_all,c_train_all,x_test_all,c_test_all,cost_OLS_all[seed],cost_Oracle_all[seed],perfs)\n",
    "    print(\"seed=\",seed,\",mu=\",\"regret reduction=\",mu,np.round(regret_all[seed,mu],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regret_avg= [0.0015 0.0808 0.0406 0.0883 0.0391 0.1342 0.1845 0.0888 0.0535 0.0136]\n"
     ]
    }
   ],
   "source": [
    "regret_avg = np.zeros(len(rho_coef_all))\n",
    "for seed in seed_all:\n",
    "    regret_avg = regret_avg + regret_all[seed,mu]\n",
    "regret_avg = regret_avg/(len(seed_all))\n",
    "print(\"regret_avg=\",np.round(regret_avg,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
