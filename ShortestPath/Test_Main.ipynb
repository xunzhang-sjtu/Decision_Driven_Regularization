{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "from gurobipy import *\n",
    "from rsome import ro\n",
    "from rsome import grb_solver as grb\n",
    "import rsome as rso\n",
    "from rsome import cpt_solver as cpt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_generation_process = \"SPO_Data_Generation\"\n",
    "data_generation_process = \"DDR_Data_Generation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyepo\n",
    "# generate data\n",
    "grid = (2,2) # grid size\n",
    "num_train = 10 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "num_test = 10000\n",
    "deg = 1.0 # polynomial degree\n",
    "e = 1.0 # scale of normal std or the range of uniform. For the error term\n",
    "\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "p = num_feat # num of features\n",
    "d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "num_nodes = grid[0]*grid[0]\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "mis = deg # model misspecification\n",
    "coef_seed = 1\n",
    "\n",
    "x_dist = 'uniform'\n",
    "e_dist = 'normal'\n",
    "x_low = -2\n",
    "x_up = 2\n",
    "x_mean = 2\n",
    "x_var = 2\n",
    "bump = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grandparent_directory: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Code_MacBook\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data/Shortest_Path_2by2_grid_0405_DDR_Data_Generation/\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "grandparent_directory = os.path.dirname(parent_directory)\n",
    "DataPath = os.path.dirname(grandparent_directory) + '/Data/Shortest_Path_'+str(grid[0])+'by'+str(grid[1])+'_grid_0405_' + data_generation_process + \"/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "print(\"grandparent_directory:\", grandparent_directory)\n",
    "print(\"DataPath:\", DataPath)\n",
    "DataPath = DataPath + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_x_dist=\"+x_dist+\"_coef_seed=\"+str(coef_seed)+\"_same_W/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump):\n",
    "# #  ****** Coef generation *********\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,data_generation_process) \n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    np.random.seed(coef_seed)\n",
    "    x_test_all = {}; c_test_all = {}; x_train_all = {}; c_train_all = {}; W_star_all = {}; noise_train_all = {}; noise_test_all = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_iter = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_iter).mkdir(parents=True, exist_ok=True)\n",
    "        W_star = data_gen.generate_truth(DataPath_iter,lower, upper, p, d, iter,data_generation_process) \n",
    "        # #  ****** Data generation *********\n",
    "        x_test_all[iter], c_test_all[iter], x_train_all[iter], c_train_all[iter], noise_train_all[iter],noise_test_all[iter],W_star_all[iter] = data_gen.generate_samples(iter,DataPath_iter,p, d, num_test, num_train, alpha, W_star, mis, num_test, \n",
    "                                data_generation_process, x_dist, e_dist, x_low, x_up, x_mean, x_var, bump) \n",
    "        # print()\n",
    "    return x_test_all, c_test_all, x_train_all, c_train_all, noise_train_all,noise_test_all,W_star_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPO(SPO+,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PYEPO import PyEPO_Method\n",
    "# epo_runner = PyEPO_Method()\n",
    "def Implement_EPO(DataPath,seed_all,batch_size,num_epochs,method_names,x_train_all,c_train_all,x_test_all,c_test_all,arcs,epo_runner):\n",
    "    cost_EPO = {}\n",
    "    for seed in seed_all:\n",
    "        DataPath_seed = DataPath +\"Seed=\"+str(seed)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        # print(\"*** seed = \",seed,\": Run EPO ******\")\n",
    "        cost_EPO[seed] = epo_runner.run(method_names,DataPath_seed,batch_size,num_feat,grid,num_epochs,\\\n",
    "                                        x_train_all[seed],c_train_all[seed],x_test_all[seed],c_test_all[seed],arcs)\n",
    "    return cost_EPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain DDR estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getArcs(grid):\n",
    "    arcs = []\n",
    "    for i in range(grid[0]):\n",
    "        # edges on rows\n",
    "        for j in range(grid[1] - 1):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + 1))\n",
    "        # edges in columns\n",
    "        if i == grid[0] - 1:\n",
    "            continue\n",
    "        for j in range(grid[1]):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + grid[1]))\n",
    "\n",
    "    arc_index_mapping = {}\n",
    "    for i in range(len(arcs)):\n",
    "        arc = arcs[i]\n",
    "        arc_index_mapping[arc] = i\n",
    "\n",
    "    return arcs,arc_index_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_DDR(arcs,lamb,mu_fixed,num_nodes,x_train,c_train):\n",
    "    \n",
    "    N,p = x_train.shape\n",
    "    N,d = c_train.shape\n",
    "\n",
    "    # DDR\n",
    "    m = Model(\"ddr\")\n",
    "    #m.setParam(\"DualReductions\",0)\n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    W_ind = tuplelist( [(i,j) for i in range(d) for j in range(p)] )\n",
    "    w0_ind = tuplelist( [i for i in range(d)])\n",
    "\n",
    "    W_ddr = m.addVars(W_ind, lb=-GRB.INFINITY,name = \"W\" )\n",
    "    w0_ddr = m.addVars(w0_ind, lb=-GRB.INFINITY,name = \"W0\" )\n",
    "    alpha = m.addVars(N,num_nodes,lb=-GRB.INFINITY,name=\"alpha\")\n",
    "    expr_obj = 0\n",
    "    err = []\n",
    "    for n in range(N):\n",
    "        cost_true_tem = c_train[n]\n",
    "        expr_obj = expr_obj + alpha[n,num_nodes-1] - alpha[n,0]\n",
    "        for ind in range(len(arcs)):\n",
    "            cost_pred_tem = quicksum([W_ddr[ind,j] * x_train[n,j] for j in range(p)]) + w0_ddr[ind]\n",
    "            err.append(cost_true_tem[ind] - cost_pred_tem)\n",
    "            e = arcs[ind]\n",
    "            j = e[1]\n",
    "            i = e[0]\n",
    "            # print(\"j = \",j,\", i = \",i, \", e = \",e)\n",
    "            m.addConstr(alpha[n,j] - alpha[n,i] >= -mu_fixed*cost_true_tem[ind] - (1-mu_fixed)*cost_pred_tem)\n",
    "\n",
    "    m.setObjective(quicksum([err[k] * err[k] for k in range(len(err))])/N + lamb*(expr_obj)/N, GRB.MINIMIZE)\n",
    "    m.optimize()\n",
    "    \n",
    "    W_DDR_rst = m.getAttr('x', W_ddr)\n",
    "    w0_DDR_rst = m.getAttr('x', w0_ddr)\n",
    "    W_ddr_val = []\n",
    "    for i in range(d):\n",
    "        W_ddr_val.append([W_DDR_rst[(i,j)] for j in range(p)])\n",
    "    w0_ddr_val = [w0_DDR_rst[i] for i in range(d)]\n",
    "\n",
    "    alpha_rst = m.getAttr('x', alpha)\n",
    "    return w0_ddr_val,W_ddr_val,alpha_rst,m.ObjVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-sample performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcs,arc_index_mapping = _getArcs(grid)\n",
    "num_arcs = len(arcs)\n",
    "iteration_all = np.arange(0,10)\n",
    "# obtain data\n",
    "x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all = Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPO performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EPO, including SPO, PG, LTR\n",
    "# batch_size = 20\n",
    "# num_epochs = 100\n",
    "# method_names = [\"spo+\",\"pg\",\"ltr\"]\n",
    "# method_names = [\"spo+\"]\n",
    "# from PYEPO import PyEPO_Method\n",
    "# epo_runner = PyEPO_Method()\n",
    "\n",
    "# cost_EPO_all = Implement_EPO(DataPath,[1],batch_size,num_epochs,method_names,x_train_all,c_train_all,x_test_all,c_test_all,arcs,epo_runner)\n",
    "# print(\"SPO+Cost = \",np.nanmean(cost_EPO_all[1][\"SPO\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-03-13\n",
      "Oracle: iter= 0 ,cost_avg= 13.301575012386422\n",
      "Oracle: iter= 1 ,cost_avg= 13.339695254892943\n",
      "Oracle: iter= 2 ,cost_avg= 13.662410118891014\n",
      "Oracle: iter= 3 ,cost_avg= 13.235011092999587\n",
      "Oracle: iter= 4 ,cost_avg= 12.921541091507084\n",
      "Oracle: iter= 5 ,cost_avg= 13.591647810901168\n",
      "Oracle: iter= 6 ,cost_avg= 13.455218449953868\n",
      "Oracle: iter= 7 ,cost_avg= 13.316053467439538\n",
      "Oracle: iter= 8 ,cost_avg= 13.302108103743384\n",
      "Oracle: iter= 9 ,cost_avg= 13.531979096520116\n"
     ]
    }
   ],
   "source": [
    "from Peformance import performance_evaluation\n",
    "perfs = performance_evaluation()\n",
    "cost_Oracle_para_all = {}; cost_Oracle_para_avg = {}\n",
    "cost_Oracle_realization_all = {}; cost_Oracle_realization_avg = {}\n",
    "\n",
    "for iter in iteration_all:\n",
    "    if data_generation_process == \"SPO_Data_Generation\":\n",
    "        cost_dem = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "        oracle_cost_pred = (cost_dem ** mis + 1).T\n",
    "    if data_generation_process == \"DDR_Data_Generation\":\n",
    "        cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "        cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "        cost_Oracle_para_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "        # cost_Oracle_para_avg[iter] = np.nanmean(cost_Oracle_para_all[iter])\n",
    "    print(\"Oracle: iter=\",iter,\",cost_avg=\",np.nanmean(cost_Oracle_para_all[iter]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS: iter= 0 ,cost_avg ratio = 1.0372994174398407\n",
      "OLS: iter= 1 ,cost_avg ratio = 1.0219651681745703\n",
      "OLS: iter= 2 ,cost_avg ratio = 1.017993483977978\n",
      "OLS: iter= 3 ,cost_avg ratio = 1.0094050728294979\n",
      "OLS: iter= 4 ,cost_avg ratio = 1.0177366213179972\n",
      "OLS: iter= 5 ,cost_avg ratio = 1.015808001201873\n",
      "OLS: iter= 6 ,cost_avg ratio = 1.0085728091544355\n",
      "OLS: iter= 7 ,cost_avg ratio = 1.0245503100614102\n",
      "OLS: iter= 8 ,cost_avg ratio = 1.0273728886466504\n",
      "OLS: iter= 9 ,cost_avg ratio = 1.0213211204350208\n"
     ]
    }
   ],
   "source": [
    "from OLS import ols_method\n",
    "ols_method_obj = ols_method()\n",
    "W_ols_all = {}; w0_ols_all = {}; t_ols_all = {}; obj_ols_all = {}\n",
    "cost_OLS_all = {}\n",
    "for iter in iteration_all:\n",
    "    # compute OLS performance\n",
    "    W_ols_all[iter], w0_ols_all[iter], t_ols_all[iter], obj_ols_all[iter] = ols_method_obj.ols_solver(\"\",x_train_all[iter], c_train_all[iter])\n",
    "    cost_dem = (W_ols_all[iter] @ x_test_all[iter].T).T + w0_ols_all[iter]\n",
    "    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "    cost_oracel_pred = (cost_oracle_ori ** mis).T\n",
    "    cost_OLS_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracel_pred,noise_test_all[iter])\n",
    "    print(\"OLS: iter=\",iter,\",cost_avg ratio =\",np.nanmean(cost_OLS_all[iter])/np.nanmean(cost_Oracle_para_all[iter]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_DDR_out_of_sample_performance(mu_all,lamb_all,num_nodes,x_train,c_train,x_test,noise_test,perfs,grid,W_star,bump,mis):\n",
    "    lamb_index = 0\n",
    "    cost_DDR = {}; w0_ddr_dict = {}; W_ddr_dict = {}\n",
    "    cost_DDR_avg = np.zeros((len(mu_all),len(lamb_all)))\n",
    "    mu_index = 0\n",
    "    for mu in mu_all:\n",
    "        lamb_index = 0\n",
    "        for lamb in lamb_all:\n",
    "\n",
    "            w0_ddr_dict[mu,lamb],W_ddr_dict[mu,lamb],alpha_rst,obj_ddr = solve_DDR(arcs,lamb,mu,num_nodes,x_train,c_train)\n",
    "            cost_dem = (W_ddr_dict[mu,lamb] @ x_test.T).T + w0_ddr_dict[mu,lamb]\n",
    "\n",
    "            cost_oracle_ori = (W_star @ x_test.T) + bump\n",
    "            cost_oracel_pred = (cost_oracle_ori ** mis).T\n",
    "\n",
    "            cost_DDR[mu,lamb] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracel_pred,noise_test)\n",
    "\n",
    "            cost_DDR_avg[mu_index,lamb_index] = np.nanmean(cost_DDR[mu,lamb])\n",
    "            lamb_index = lamb_index + 1\n",
    "        # print(\"cost_DDR_avg=\",np.round(cost_DDR_avg[0,:],4))\n",
    "        mu_index = mu_index + 1\n",
    "    return cost_DDR,w0_ddr_dict,W_ddr_dict,cost_DDR_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_ddr_rst(iteration_all,mu_all,lamb_all,num_nodes,x_train_all,c_train_all,x_test_all,noise_test_all,perfs,grid,W_star_all,bump,mis):\n",
    "    cost_DDR_all = {}; w0_ddr_all = {}; W_ddr_all = {}\n",
    "    cost_DDR_avg_all = {}\n",
    "    for iter in iteration_all:\n",
    "        cost_DDR_all[iter],w0_ddr_all[iter],W_ddr_all[iter],cost_DDR_avg_all[iter] = obtain_DDR_out_of_sample_performance(mu_all,lamb_all,num_nodes,x_train_all[iter],c_train_all[iter],x_test_all[iter],noise_test_all[iter],perfs,grid,W_star_all[iter],bump,mis)\n",
    "        print(\"DDR iter = \",iter)\n",
    "    return cost_DDR_all,w0_ddr_all,W_ddr_all,cost_DDR_avg_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDR iter =  0\n",
      "DDR iter =  1\n",
      "DDR iter =  2\n",
      "DDR iter =  3\n",
      "DDR iter =  4\n",
      "DDR iter =  5\n"
     ]
    }
   ],
   "source": [
    "mu_all = np.round(np.arange(0.1,1.0,0.1),4)\n",
    "lamb_all = np.round(np.arange(0.0,1.0,0.1),4)\n",
    "cost_DDR_all,w0_ddr_all,W_ddr_all,cost_DDR_avg_all = obtain_ddr_rst(iteration_all,mu_all,lamb_all,num_nodes,x_train_all,c_train_all,x_test_all,noise_test_all,perfs,grid,W_star_all,bump,mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_ddr_vs_ols_para_all = {}; regret_ddr_vs_ols_para_avg = np.zeros((len(mu_all),len(lamb_all)))\n",
    "\n",
    "cost_OLS_avg_all = np.zeros(len(iteration_all))\n",
    "cost_Oracle_para_avg_all = np.zeros(len(iteration_all))\n",
    "cost_Oracle_realization_avg_all = np.zeros(len(iteration_all))\n",
    "\n",
    "for iter_index in range(len(iteration_all)):\n",
    "    iter = iteration_all[iter_index]\n",
    "    cost_OLS_avg_all[iter_index] = np.nanmean(cost_OLS_all[iter])\n",
    "    cost_Oracle_para_avg_all[iter_index] = np.nanmean(cost_Oracle_para_all[iter])\n",
    "\n",
    "    regret_ddr_vs_ols_para_all[iter_index] = (cost_OLS_avg_all[iter_index] - cost_DDR_avg_all[iter])/np.abs(cost_OLS_avg_all[iter_index] - cost_Oracle_para_avg_all[iter_index])\n",
    "    regret_ddr_vs_ols_para_avg = regret_ddr_vs_ols_para_avg + regret_ddr_vs_ols_para_all[iter_index]\n",
    "\n",
    "regret_ddr_vs_ols_para_avg = regret_ddr_vs_ols_para_avg/len(iteration_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_DDR_vs_OLS_para_avg_df = pd.DataFrame(regret_ddr_vs_ols_para_avg)\n",
    "regret_DDR_vs_OLS_para_avg_df.index = mu_all\n",
    "regret_DDR_vs_OLS_para_avg_df.columns = lamb_all\n",
    "regret_DDR_vs_OLS_para_avg_df.to_csv(DataPath+\"regret_DDR_vs_OLS_para_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(DataPath+'cost_OLS_all.pkl', \"wb\") as tf:\n",
    "#     pickle.dump(cost_OLS_all,tf)\n",
    "# with open(DataPath+'cost_Oracle_all.pkl', \"wb\") as tf:\n",
    "#     pickle.dump(cost_Oracle_all,tf)\n",
    "# with open(DataPath+'cost_DDR_all.pkl', \"wb\") as tf:\n",
    "#     pickle.dump(cost_DDR_all,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 1\n",
    "# lamb = 1\n",
    "# cost_OLS_esti = x_test_all[seed] @ np.asarray(W_ols_all[seed]).T + w0_ols_all[seed]\n",
    "# cost_DDR_esti = x_test_all[seed] @ np.asarray(W_ddr_all[seed,mu][lamb]).T + w0_ddr_all[seed,mu][lamb]\n",
    "\n",
    "# S_test_index = 3\n",
    "# print(\"cost_DDR_esti=\",np.round(cost_DDR_esti[S_test_index,],2))\n",
    "# # print(\"cost:(0,1)-->(1,3) = \",cost_DDR_esti[S_test_index,0] + cost_DDR_esti[S_test_index,2])\n",
    "# # print(\"cost:(0,2)-->(2,3) = \",cost_DDR_esti[S_test_index,1] + cost_DDR_esti[S_test_index,3])\n",
    "\n",
    "# print(\"cost_OLS_esti=\",np.round(cost_OLS_esti[S_test_index,],2))\n",
    "# # print(\"cost:(0,1)-->(1,3) = \",cost_OLS_esti[S_test_index,0] + cost_OLS_esti[S_test_index,2])\n",
    "# # print(\"cost:(0,2)-->(2,3) = \",cost_OLS_esti[S_test_index,1] + cost_OLS_esti[S_test_index,3])\n",
    "\n",
    "\n",
    "# print(\"cost_Oracle=\",np.round(c_test_all[seed][S_test_index],2))\n",
    "# # print(\"cost:(0,1)-->(1,3) = \",c_test_all[seed][S_test_index,0] + c_test_all[seed][S_test_index,2])\n",
    "# # print(\"cost:(0,2)-->(2,3) = \",c_test_all[seed][S_test_index,1] + c_test_all[seed][S_test_index,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_compare2plus(c_item, c_base, c_oracle):\n",
    "    c_item = np.asarray(c_item)\n",
    "    c_base = np.asarray(c_base)\n",
    "    c_oracle = np.asarray(c_oracle)\n",
    "\n",
    "    N = len(c_item)\n",
    "    c_diff = c_item - c_base\n",
    "    lbel = np.zeros((N,1))\n",
    "    \n",
    "    equals = np.sum(c_diff == 0)\n",
    "    wins = np.sum(c_diff < 0)\n",
    "    lose = np.sum(c_diff > 0)\n",
    "    \n",
    "    lbel[c_diff < 0] = 1\n",
    "    lbel[c_diff > 0] = -1\n",
    "    \n",
    "    # print(\"Num_train =\",N,\",Num_equals =\",equals,\",Num_wins =\",wins,\",Num_lose =\",lose)\n",
    "    # print(\"base cost = \", np.mean(c_base),\",item cost = \",np.mean(c_item))\n",
    "    if N == equals:\n",
    "        win_ratio = 0.5\n",
    "    else:\n",
    "        win_ratio = wins/(N - equals)\n",
    "    # cost_reduction = (np.mean(c_base) - np.mean(c_item) )/np.abs(np.mean(c_oracle))\n",
    "    regret_reduction = (np.nanmean(c_base) - np.nanmean(c_item))/np.abs(np.nanmean(c_base) - np.nanmean(c_oracle))\n",
    "    return lbel, win_ratio, regret_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2H_DDR_vs_OLS_all = {}; regret_reduction_DDR_vs_OLS_all = {}\n",
    "# for mu in mu_all:\n",
    "#     for lamb in lamb_all:\n",
    "#         H2H_DDR_vs_OLS_arr = np.zeros(len(iteration_all)); regret_reduction_DDR_vs_OLS_arr = np.zeros(len(iteration_all))\n",
    "#         # print(\"lamb = \",lamb)\n",
    "#         for iter in iteration_all:\n",
    "#             lbel, H2H_DDR_vs_OLS_arr[iter-1], regret_reduction_DDR_vs_OLS_arr[iter-1] = cross_compare2plus(cost_DDR_all[iter][mu,lamb],cost_OLS_all[iter], cost_Oracle_all[iter])\n",
    "#         H2H_DDR_vs_OLS_all[mu,lamb] = H2H_DDR_vs_OLS_arr; regret_reduction_DDR_vs_OLS_all[mu,lamb] = regret_reduction_DDR_vs_OLS_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu = mu_all[0]\n",
    "# lamb = lamb_all[7]\n",
    "# import Figures\n",
    "# file_name = DataPath + \"figure_mu=\"+str(mu)+\"_lamb=\"+str(lamb)\n",
    "# Figures.figure_plot_upleft(H2H_DDR_vs_OLS_all[mu,lamb]*100, regret_reduction_DDR_vs_OLS_all[mu,lamb], file_name, size = (5, 5), move = [-0.12, 0.04, 0.35, 0.55], \n",
    "#                     ysame = 0, yrange = [6,6], sublabel = '', ypio = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# ax = plt.subplot()\n",
    "# ax.plot(lamb_all,regret_all[seed,mu])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPO figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2H_SPO_vs_OLS_arr = np.zeros(len(seed_all)); regret_reduction_SPO_vs_OLS_arr = np.zeros(len(seed_all))\n",
    "# seed_index = 0\n",
    "# for seed in seed_all:\n",
    "#     lbel, H2H_SPO_vs_OLS_arr[seed_index], regret_reduction_SPO_vs_OLS_arr[seed_index] = cross_compare2plus(cost_EPO_all[seed][\"SPO\"],cost_OLS_all[seed], cost_Oracle_all[seed])\n",
    "#     seed_index = seed_index + 1\n",
    "# H2H_SPO_vs_OLS_all = H2H_SPO_vs_OLS_arr; regret_reduction_SPO_vs_OLS_all = regret_reduction_SPO_vs_OLS_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figures.figure_plot_upleft(H2H_SPO_vs_OLS_all*100, regret_reduction_SPO_vs_OLS_all, \"\", size = (5, 5), move = [-0.12, 0.04, 0.35, 0.55], \n",
    "#                     ysame = 0, yrange = [6,6], sublabel = '', ypio = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regret_reduction_SPO_vs_OLS_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
