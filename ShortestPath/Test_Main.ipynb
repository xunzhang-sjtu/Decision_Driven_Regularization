{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "from gurobipy import *\n",
    "from rsome import ro\n",
    "from rsome import grb_solver as grb\n",
    "import rsome as rso\n",
    "from rsome import cpt_solver as cpt\n",
    "import pandas as pd\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generation_process = \"SPO_Data_Generation\"\n",
    "# data_generation_process = \"DDR_Data_Generation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = (2,2) # grid size\n",
    "num_train = 100 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "num_test = 1000\n",
    "deg = 1.0 # polynomial degree\n",
    "e = 0.5 # scale of normal std or the range of uniform. For the error term\n",
    "\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "p = num_feat # num of features\n",
    "d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "num_nodes = grid[0]*grid[0]\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "mis = deg # model misspecification\n",
    "coef_seed = 1\n",
    "\n",
    "x_dist = 'uniform'\n",
    "e_dist = 'normal'\n",
    "x_low = -2\n",
    "x_up = 2\n",
    "x_mean = 2\n",
    "x_var = 2\n",
    "bump = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grandparent_directory: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Code_MacBook\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data/Shortest_Path_Macbook_RP/2by2_grid_SPO_Data_Generation_exp=1/\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "grandparent_directory = os.path.dirname(parent_directory)\n",
    "DataPath = os.path.dirname(grandparent_directory) + '/Data/Shortest_Path_Macbook_RP/'+str(grid[0])+'by'+str(grid[1])+'_grid_' + data_generation_process + \"_exp=1/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "print(\"grandparent_directory:\", grandparent_directory)\n",
    "print(\"DataPath:\", DataPath)\n",
    "DataPath = DataPath + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump):\n",
    "# #  ****** Coef generation *********\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,data_generation_process) \n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    np.random.seed(coef_seed)\n",
    "    x_test_all = {}; c_test_all = {}; x_train_all = {}; c_train_all = {}; W_star_all = {}; noise_train_all = {}; noise_test_all = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_iter = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_iter).mkdir(parents=True, exist_ok=True)\n",
    "        W_star = data_gen.generate_truth(DataPath_iter,lower, upper, p, d, iter,data_generation_process) \n",
    "        # #  ****** Data generation *********\n",
    "        x_test_all[iter], c_test_all[iter], x_train_all[iter], c_train_all[iter], noise_train_all[iter],noise_test_all[iter],W_star_all[iter] = data_gen.generate_samples(iter,DataPath_iter,p, d, num_test, num_train, alpha, W_star, mis, num_test, \n",
    "                                data_generation_process, x_dist, e_dist, x_low, x_up, x_mean, x_var, bump) \n",
    "        # print()\n",
    "    return x_test_all, c_test_all, x_train_all, c_train_all, noise_train_all,noise_test_all,W_star_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPO(SPO+,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "                  arcs,grid,epo_runner,perfs):\n",
    "    W_EPO_all = {}; w0_EPO_all = {}\n",
    "    cost_EPO_all = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_seed = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        # print(\"*** seed = \",seed,\": Run EPO ******\")\n",
    "        W_EPO_all[iter],w0_EPO_all[iter] = epo_runner.run(method_names,DataPath_seed,batch_size,num_feat,grid,num_epochs,\\\n",
    "                                        x_train_all[iter],c_train_all[iter],arcs)\n",
    "        \n",
    "        cost_dem = (W_EPO_all[iter] @ x_test_all[iter].T).T + w0_EPO_all[iter]\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            cost_EPO_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_EPO_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "        print(method_names[0],\": iter=\",iter,\",cost=\",np.nanmean(cost_EPO_all[iter]))\n",
    "\n",
    "    return W_EPO_all,w0_EPO_all,cost_EPO_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain DDR estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getArcs(grid):\n",
    "    arcs = []\n",
    "    for i in range(grid[0]):\n",
    "        # edges on rows\n",
    "        for j in range(grid[1] - 1):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + 1))\n",
    "        # edges in columns\n",
    "        if i == grid[0] - 1:\n",
    "            continue\n",
    "        for j in range(grid[1]):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + grid[1]))\n",
    "\n",
    "    arc_index_mapping = {}\n",
    "    for i in range(len(arcs)):\n",
    "        arc = arcs[i]\n",
    "        arc_index_mapping[arc] = i\n",
    "\n",
    "    return arcs,arc_index_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_DDR(arcs,lamb,mu_fixed,num_nodes,x_train,c_train):\n",
    "    \n",
    "    N,p = x_train.shape\n",
    "    N,d = c_train.shape\n",
    "\n",
    "    # DDR\n",
    "    m = Model(\"ddr\")\n",
    "    #m.setParam(\"DualReductions\",0)\n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    W_ind = tuplelist( [(i,j) for i in range(d) for j in range(p)] )\n",
    "    w0_ind = tuplelist( [i for i in range(d)])\n",
    "\n",
    "    W_ddr = m.addVars(W_ind, lb=-GRB.INFINITY,name = \"W\" )\n",
    "    w0_ddr = m.addVars(w0_ind, lb=-GRB.INFINITY,name = \"W0\" )\n",
    "    alpha = m.addVars(N,num_nodes,lb=-GRB.INFINITY,name=\"alpha\")\n",
    "    expr_obj = 0\n",
    "    err = []\n",
    "    for n in range(N):\n",
    "        cost_true_tem = c_train[n]\n",
    "        expr_obj = expr_obj + alpha[n,num_nodes-1] - alpha[n,0]\n",
    "        for ind in range(len(arcs)):\n",
    "            cost_pred_tem = quicksum([W_ddr[ind,j] * x_train[n,j] for j in range(p)]) + w0_ddr[ind]\n",
    "            err.append(cost_true_tem[ind] - cost_pred_tem)\n",
    "            e = arcs[ind]\n",
    "            j = e[1]\n",
    "            i = e[0]\n",
    "            # print(\"j = \",j,\", i = \",i, \", e = \",e)\n",
    "            m.addConstr(alpha[n,j] - alpha[n,i] >= -mu_fixed*cost_true_tem[ind] - (1-mu_fixed)*cost_pred_tem)\n",
    "\n",
    "    m.setObjective(quicksum([err[k] * err[k] for k in range(len(err))])/N + lamb*(expr_obj)/N, GRB.MINIMIZE)\n",
    "    m.optimize()\n",
    "    \n",
    "    W_DDR_rst = m.getAttr('x', W_ddr)\n",
    "    w0_DDR_rst = m.getAttr('x', w0_ddr)\n",
    "    W_ddr_val = []\n",
    "    for i in range(d):\n",
    "        W_ddr_val.append([W_DDR_rst[(i,j)] for j in range(p)])\n",
    "    w0_ddr_val = [w0_DDR_rst[i] for i in range(d)]\n",
    "\n",
    "    alpha_rst = m.getAttr('x', alpha)\n",
    "    return w0_ddr_val,W_ddr_val,alpha_rst,m.ObjVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-sample performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcs,arc_index_mapping = _getArcs(grid)\n",
    "num_arcs = len(arcs)\n",
    "iteration_all = np.arange(0,20)\n",
    "# obtain data\n",
    "x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all = Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_star_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_star_all[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92235509,  1.76345327, -2.10067959,  0.9573124 ,  0.24787527])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all[0][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.00213202,  0.10794482, -0.7383466 ,  1.23227666, -2.1737333 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all[1][0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-03-13\n",
      "Oracle: iter= 0 ,cost_avg= 7.518113970776958\n",
      "Oracle: iter= 1 ,cost_avg= 7.481920364924577\n",
      "Oracle: iter= 2 ,cost_avg= 7.9307440527356485\n",
      "Oracle: iter= 3 ,cost_avg= 7.436325714891586\n",
      "Oracle: iter= 4 ,cost_avg= 7.463773124273877\n",
      "Oracle: iter= 5 ,cost_avg= 7.680059782323815\n",
      "Oracle: iter= 6 ,cost_avg= 7.555471868294173\n",
      "Oracle: iter= 7 ,cost_avg= 7.684026027798313\n",
      "Oracle: iter= 8 ,cost_avg= 7.360416923259242\n",
      "Oracle: iter= 9 ,cost_avg= 7.718062104944936\n",
      "Oracle: iter= 10 ,cost_avg= 7.714351381287567\n",
      "Oracle: iter= 11 ,cost_avg= 7.759257346270374\n",
      "Oracle: iter= 12 ,cost_avg= 7.6327333248231835\n",
      "Oracle: iter= 13 ,cost_avg= 7.846243858004774\n",
      "Oracle: iter= 14 ,cost_avg= 7.451914103499341\n",
      "Oracle: iter= 15 ,cost_avg= 7.684570826443063\n",
      "Oracle: iter= 16 ,cost_avg= 7.545482610331614\n",
      "Oracle: iter= 17 ,cost_avg= 7.58140938588702\n",
      "Oracle: iter= 18 ,cost_avg= 7.785789302347057\n",
      "Oracle: iter= 19 ,cost_avg= 7.536255409861465\n"
     ]
    }
   ],
   "source": [
    "from Peformance import performance_evaluation\n",
    "perfs = performance_evaluation()\n",
    "cost_Oracle_para_all = {}; cost_Oracle_para_avg = {}\n",
    "cost_Oracle_realization_all = {}; cost_Oracle_realization_avg = {}\n",
    "\n",
    "for iter in iteration_all:\n",
    "    if data_generation_process == \"SPO_Data_Generation\":\n",
    "        cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "        cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "        cost_Oracle_para_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "    if data_generation_process == \"DDR_Data_Generation\":\n",
    "        cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "        cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "        cost_Oracle_para_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "        # cost_Oracle_para_avg[iter] = np.nanmean(cost_Oracle_para_all[iter])\n",
    "    print(\"Oracle: iter=\",iter,\",cost_avg=\",np.nanmean(cost_Oracle_para_all[iter]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPO performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EPO, including SPO, PG, LTR\n",
    "# batch_size = 20\n",
    "# num_epochs = 1000\n",
    "# # method_names = [\"spo+\",\"pg\",\"ltr\"]\n",
    "# from PYEPO import PyEPO_Method\n",
    "# epo_runner = PyEPO_Method()\n",
    "# from Peformance import performance_evaluation\n",
    "# perfs = performance_evaluation()\n",
    "\n",
    "# method_names = [\"spo+\"]\n",
    "# W_SPO_all,w0_SPO_all,cost_SPO_all = Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "#                   arcs,grid,epo_runner,perfs)\n",
    "\n",
    "# # method_names = [\"pg\"]\n",
    "# # W_PG_all,w0_PG_all,cost_PG_all = Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "# #                   arcs,grid,epo_runner,perfs)\n",
    "\n",
    "# # method_names = [\"ltr\"]\n",
    "# # W_LTR_all,w0_LTR_all,cost_LTR_all = Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "# #                   arcs,grid,epo_runner,perfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS: iter= 0 ,cost_avg ratio = 7.572913363495361\n",
      "OLS: iter= 1 ,cost_avg ratio = 7.5076801565544535\n",
      "OLS: iter= 2 ,cost_avg ratio = 7.980757784467621\n",
      "OLS: iter= 3 ,cost_avg ratio = 7.506011663053585\n",
      "OLS: iter= 4 ,cost_avg ratio = 7.505030276171892\n",
      "OLS: iter= 5 ,cost_avg ratio = 7.688000870268563\n",
      "OLS: iter= 6 ,cost_avg ratio = 7.562766548239513\n",
      "OLS: iter= 7 ,cost_avg ratio = 7.692732239155091\n",
      "OLS: iter= 8 ,cost_avg ratio = 7.3859699858749535\n",
      "OLS: iter= 9 ,cost_avg ratio = 7.790652775038991\n",
      "OLS: iter= 10 ,cost_avg ratio = 7.73359024637193\n",
      "OLS: iter= 11 ,cost_avg ratio = 7.80618789622475\n",
      "OLS: iter= 12 ,cost_avg ratio = 7.687726135203817\n",
      "OLS: iter= 13 ,cost_avg ratio = 8.026764259328209\n",
      "OLS: iter= 14 ,cost_avg ratio = 7.491666967116219\n",
      "OLS: iter= 15 ,cost_avg ratio = 7.692094285123818\n",
      "OLS: iter= 16 ,cost_avg ratio = 7.575416205576508\n",
      "OLS: iter= 17 ,cost_avg ratio = 7.658775538533817\n",
      "OLS: iter= 18 ,cost_avg ratio = 7.852527487071212\n",
      "OLS: iter= 19 ,cost_avg ratio = 7.548587909750404\n"
     ]
    }
   ],
   "source": [
    "from OLS import ols_method\n",
    "ols_method_obj = ols_method()\n",
    "W_ols_all = {}; w0_ols_all = {}; t_ols_all = {}; obj_ols_all = {}\n",
    "cost_OLS_all = {}\n",
    "for iter in iteration_all:\n",
    "    # compute OLS performance\n",
    "    W_ols_all[iter], w0_ols_all[iter], t_ols_all[iter], obj_ols_all[iter] = ols_method_obj.ols_solver(\"\",x_train_all[iter], c_train_all[iter])\n",
    "    cost_dem = (W_ols_all[iter] @ x_test_all[iter].T).T + w0_ols_all[iter]\n",
    "\n",
    "    if data_generation_process == \"SPO_Data_Generation\":\n",
    "        cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "        cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "        cost_OLS_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "    if data_generation_process == \"DDR_Data_Generation\":\n",
    "        cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "        cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "        cost_OLS_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "    print(\"OLS: iter=\",iter,\",cost_avg ratio =\",np.nanmean(cost_OLS_all[iter]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_DDR_out_of_sample_performance(mu_all,lamb_all,num_nodes,x_train,c_train,x_test,noise_test,perfs,grid,W_star,bump,mis):\n",
    "    lamb_index = 0\n",
    "    cost_DDR = {}; w0_ddr_dict = {}; W_ddr_dict = {}\n",
    "    cost_DDR_avg = np.zeros((len(mu_all),len(lamb_all)))\n",
    "    mu_index = 0\n",
    "    for mu in mu_all:\n",
    "        lamb_index = 0\n",
    "        for lamb in lamb_all:\n",
    "\n",
    "            w0_ddr_dict[mu,lamb],W_ddr_dict[mu,lamb],alpha_rst,obj_ddr = solve_DDR(arcs,lamb,mu,num_nodes,x_train,c_train)\n",
    "            cost_dem = (W_ddr_dict[mu,lamb] @ x_test.T).T + w0_ddr_dict[mu,lamb]\n",
    "\n",
    "            if data_generation_process == \"SPO_Data_Generation\":\n",
    "                cost_oracle_ori = (W_star @ x_test.T)/np.sqrt(num_feat) + 3\n",
    "                cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "                cost_DDR[mu,lamb] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test)\n",
    "\n",
    "            if data_generation_process == \"DDR_Data_Generation\":\n",
    "                cost_oracle_ori = (W_star @ x_test.T) + bump\n",
    "                cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "                cost_DDR[mu,lamb] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test)\n",
    "\n",
    "            cost_DDR_avg[mu_index,lamb_index] = np.nanmean(cost_DDR[mu,lamb])\n",
    "            lamb_index = lamb_index + 1\n",
    "        # print(\"cost_DDR_avg=\",np.round(cost_DDR_avg[0,:],4))\n",
    "        mu_index = mu_index + 1\n",
    "    return cost_DDR,w0_ddr_dict,W_ddr_dict,cost_DDR_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_ddr_rst(iteration_all,mu_all,lamb_all,num_nodes,x_train_all,c_train_all,x_test_all,noise_test_all,perfs,grid,W_star_all,bump,mis):\n",
    "    cost_DDR_all = {}; w0_ddr_all = {}; W_ddr_all = {}\n",
    "    cost_DDR_avg_all = {}\n",
    "    for iter in iteration_all:\n",
    "        cost_DDR_all[iter],w0_ddr_all[iter],W_ddr_all[iter],cost_DDR_avg_all[iter] = obtain_DDR_out_of_sample_performance(mu_all,lamb_all,num_nodes,x_train_all[iter],c_train_all[iter],x_test_all[iter],noise_test_all[iter],perfs,grid,W_star_all[iter],bump,mis)\n",
    "        print(\"DDR iter = \",iter)\n",
    "    return cost_DDR_all,w0_ddr_all,W_ddr_all,cost_DDR_avg_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDR iter =  0\n",
      "DDR iter =  1\n",
      "DDR iter =  2\n",
      "DDR iter =  3\n",
      "DDR iter =  4\n",
      "DDR iter =  5\n",
      "DDR iter =  6\n",
      "DDR iter =  7\n",
      "DDR iter =  8\n",
      "DDR iter =  9\n",
      "DDR iter =  10\n",
      "DDR iter =  11\n",
      "DDR iter =  12\n",
      "DDR iter =  13\n",
      "DDR iter =  14\n",
      "DDR iter =  15\n",
      "DDR iter =  16\n",
      "DDR iter =  17\n",
      "DDR iter =  18\n",
      "DDR iter =  19\n"
     ]
    }
   ],
   "source": [
    "mu_all = np.round(np.arange(0.1,1.0,0.1),4)\n",
    "lamb_all = np.round(np.arange(0.0,1.0,0.1),4)\n",
    "cost_DDR_all,w0_ddr_all,W_ddr_all,cost_DDR_avg_all = obtain_ddr_rst(iteration_all,mu_all,lamb_all,num_nodes,x_train_all,c_train_all,x_test_all,noise_test_all,perfs,grid,W_star_all,bump,mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.572913363495361)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(cost_DDR_all[0][0.1,0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_ddr_vs_ols_para_all = {}; regret_ddr_vs_ols_para_avg = np.zeros((len(mu_all),len(lamb_all)))\n",
    "\n",
    "regret_spo_vs_ols_para_all = {}; regret_spo_vs_ols_para_avg = 0\n",
    "\n",
    "\n",
    "cost_OLS_avg_all = np.zeros(len(iteration_all))\n",
    "cost_Oracle_para_avg_all = np.zeros(len(iteration_all))\n",
    "cost_Oracle_realization_avg_all = np.zeros(len(iteration_all))\n",
    "\n",
    "for iter_index in range(len(iteration_all)):\n",
    "    iter = iteration_all[iter_index]\n",
    "    cost_OLS_avg_all[iter_index] = np.nanmean(cost_OLS_all[iter])\n",
    "    cost_Oracle_para_avg_all[iter_index] = np.nanmean(cost_Oracle_para_all[iter])\n",
    "\n",
    "    regret_ddr_vs_ols_para_all[iter_index] = (cost_OLS_avg_all[iter_index] - cost_DDR_avg_all[iter])/np.abs(cost_OLS_avg_all[iter_index] - cost_Oracle_para_avg_all[iter_index])\n",
    "    regret_ddr_vs_ols_para_avg = regret_ddr_vs_ols_para_avg + regret_ddr_vs_ols_para_all[iter_index]\n",
    "\n",
    "    # regret_spo_vs_ols_para_all[iter] = (cost_OLS_avg_all[iter_index] - np.nanmean(cost_SPO_all[iter]))/np.abs(cost_OLS_avg_all[iter_index] - cost_Oracle_para_avg_all[iter_index])\n",
    "    # regret_spo_vs_ols_para_avg = regret_spo_vs_ols_para_avg + regret_spo_vs_ols_para_all[iter]\n",
    "\n",
    "regret_ddr_vs_ols_para_avg = regret_ddr_vs_ols_para_avg/len(iteration_all)\n",
    "regret_spo_vs_ols_para_avg = regret_spo_vs_ols_para_avg/len(iteration_all)\n",
    "\n",
    "regret_DDR_vs_OLS_para_avg_df = pd.DataFrame(regret_ddr_vs_ols_para_avg)\n",
    "regret_DDR_vs_OLS_para_avg_df.index = [\"$\\mu=\"+str(mu)+\"$\" for mu in mu_all]\n",
    "regret_DDR_vs_OLS_para_avg_df.columns = [\"$\\lambda=\"+str(lamb)+\"$\" for lamb in lamb_all]\n",
    "regret_DDR_vs_OLS_para_avg_df.to_csv(DataPath+\"regret_DDR_vs_OLS_para_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.57291336, 7.50768016, 7.98075778, 7.50601166, 7.50503028,\n",
       "       7.68800087, 7.56276655, 7.69273224, 7.38596999, 7.79065278,\n",
       "       7.73359025, 7.8061879 , 7.68772614, 8.02676426, 7.49166697,\n",
       "       7.69209429, 7.57541621, 7.65877554, 7.85252749, 7.54858791])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_OLS_avg_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DataPath+'cost_OLS_all.pkl', \"wb\") as tf:\n",
    "    pickle.dump(cost_OLS_all,tf)\n",
    "with open(DataPath+'cost_Oracle_para_all.pkl', \"wb\") as tf:\n",
    "    pickle.dump(cost_Oracle_para_all,tf)\n",
    "with open(DataPath+'cost_DDR_all.pkl', \"wb\") as tf:\n",
    "    pickle.dump(cost_DDR_all,tf)\n",
    "# with open(DataPath+'cost_SPO_all.pkl', \"wb\") as tf:\n",
    "#     pickle.dump(cost_SPO_all,tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_compare2plus(c_item, c_base, c_oracle):\n",
    "    c_item = np.asarray(c_item)\n",
    "    c_base = np.asarray(c_base)\n",
    "    c_oracle = np.asarray(c_oracle)\n",
    "\n",
    "    N = len(c_item)\n",
    "    c_diff = c_item - c_base\n",
    "    lbel = np.zeros((N,1))\n",
    "    \n",
    "    equals = np.sum(c_diff == 0)\n",
    "    wins = np.sum(c_diff < 0)\n",
    "    lose = np.sum(c_diff > 0)\n",
    "    \n",
    "    lbel[c_diff < 0] = 1\n",
    "    lbel[c_diff > 0] = -1\n",
    "    \n",
    "    # print(\"Num_train =\",N,\",Num_equals =\",equals,\",Num_wins =\",wins,\",Num_lose =\",lose)\n",
    "    # print(\"base cost = \", np.mean(c_base),\",item cost = \",np.mean(c_item))\n",
    "    if N == equals:\n",
    "        win_ratio = 0.5\n",
    "    else:\n",
    "        win_ratio = wins/(N - equals)\n",
    "    # cost_reduction = (np.mean(c_base) - np.mean(c_item) )/np.abs(np.mean(c_oracle))\n",
    "    regret_reduction = (np.nanmean(c_base) - np.nanmean(c_item))/np.abs(np.nanmean(c_base) - np.nanmean(c_oracle))\n",
    "    return lbel, win_ratio, regret_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2H_DDR_vs_OLS_all = {}; regret_reduction_DDR_vs_OLS_all = {}\n",
    "# for mu in mu_all:\n",
    "#     for lamb in lamb_all:\n",
    "#         H2H_DDR_vs_OLS_arr = np.zeros(len(iteration_all)); regret_reduction_DDR_vs_OLS_arr = np.zeros(len(iteration_all))\n",
    "#         # print(\"lamb = \",lamb)\n",
    "#         iter_index = 0\n",
    "#         for iter in iteration_all:\n",
    "#             lbel, H2H_DDR_vs_OLS_arr[iter_index], regret_reduction_DDR_vs_OLS_arr[iter_index] = cross_compare2plus(cost_DDR_all[iter][mu,lamb],cost_OLS_all[iter], cost_Oracle_para_avg_all[iter])\n",
    "#             iter_index = iter_index + 1\n",
    "#         H2H_DDR_vs_OLS_all[mu,lamb] = H2H_DDR_vs_OLS_arr; regret_reduction_DDR_vs_OLS_all[mu,lamb] = regret_reduction_DDR_vs_OLS_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu = mu_all[4]\n",
    "# lamb = lamb_all[6]\n",
    "# import Figures\n",
    "# file_name = DataPath + \"figure_mu=\"+str(mu)+\"_lamb=\"+str(lamb)\n",
    "# Figures.figure_plot_upleft(H2H_DDR_vs_OLS_all[mu,lamb]*100, regret_reduction_DDR_vs_OLS_all[mu,lamb]*100, file_name, size = (5, 5), move = [-0.12, 0.04, 0.35, 0.55], \n",
    "#                     ysame = 0, yrange = [6,6], sublabel = '', ypio = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPO figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2H_SPO_vs_OLS_all = np.zeros(len(iteration_all)); regret_reduction_SPO_vs_OLS_all = np.zeros(len(iteration_all))\n",
    "# iter_index = 0\n",
    "# for iter in iteration_all:\n",
    "#     # regret_SPO_OLS = (np.nanmean(cost_OLS_all[iter]) - np.nanmean(cost_SPO_all[iter]))/np.abs(np.nanmean(cost_OLS_all[iter_index]) - np.nanmean(cost_Oracle_para_all[iter]))\n",
    "#     # print(\"iter=\",iter,\",SPO cost Ratio = \",np.nanmean(cost_SPO_all[iter])/np.nanmean(cost_Oracle_para_all[iter]),\",regret=\",regret_SPO_OLS)\n",
    "#     lbel, H2H_SPO_vs_OLS_all[iter_index], regret_reduction_SPO_vs_OLS_all[iter_index] = cross_compare2plus(cost_SPO_all[iter],cost_OLS_all[iter], cost_Oracle_para_avg_all[iter])\n",
    "#     iter_index = iter_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Figures\n",
    "# file_name = DataPath+\"regret_SPO_vs_OLS_\"+data_generation_process+\"_grid_\"+str(grid[0])+\"by\"+str(grid[1])\n",
    "# Figures.figure_plot_upleft(H2H_SPO_vs_OLS_all*100, regret_reduction_SPO_vs_OLS_all*100, file_name, size = (5, 5), move = [-0.12, 0.04, 0.35, 0.55], \n",
    "#                     ysame = 0, yrange = [6,6], sublabel = '', ypio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regret_reduction_SPO_vs_OLS_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_avg_ddr_ratio = np.zeros((len(mu_all),len(lamb_all)))\n",
    "for iter in iteration_all:\n",
    "    cost_avg_ddr_ratio += cost_DDR_avg_all[iter]/cost_OLS_avg_all[iter]\n",
    "cost_avg_ddr_ratio = cost_avg_ddr_ratio/len(iteration_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    , -0.0033, -0.0002, -0.0037, -0.0016,  0.0044,  0.0074,\n",
       "         0.0137,  0.0102,  0.0106],\n",
       "       [ 0.    , -0.0028, -0.0046, -0.0071, -0.0073, -0.006 , -0.0101,\n",
       "        -0.0182, -0.0169, -0.0148],\n",
       "       [ 0.    , -0.0059, -0.0094, -0.0104, -0.012 , -0.018 , -0.0176,\n",
       "        -0.0197, -0.0174, -0.0156],\n",
       "       [ 0.    , -0.0054, -0.0089, -0.0151, -0.0186, -0.0222, -0.0243,\n",
       "        -0.0215, -0.0208, -0.0222],\n",
       "       [ 0.    , -0.0039, -0.0064, -0.0147, -0.0143, -0.017 , -0.0221,\n",
       "        -0.0243, -0.0311, -0.032 ],\n",
       "       [ 0.    , -0.0026, -0.0064, -0.0118, -0.0122, -0.0156, -0.0147,\n",
       "        -0.0171, -0.018 , -0.0229],\n",
       "       [ 0.    , -0.0017, -0.0039, -0.0067, -0.0078, -0.0067, -0.0075,\n",
       "        -0.0073, -0.0069, -0.0072],\n",
       "       [ 0.    , -0.0003, -0.001 , -0.0023, -0.004 , -0.0076, -0.0078,\n",
       "        -0.0091, -0.0097, -0.0111],\n",
       "       [ 0.    , -0.    , -0.0002, -0.0013, -0.0013, -0.0011, -0.0012,\n",
       "        -0.0018, -0.0037, -0.0034]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((cost_avg_ddr_ratio -1)*100,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9999172002871553)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(cost_avg_ddr_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.57291336, 7.50768016, 7.98075778, 7.50601166, 7.50503028,\n",
       "       7.68800087, 7.56276655, 7.69273224, 7.38596999, 7.79065278,\n",
       "       7.73359025, 7.8061879 , 7.68772614, 8.02676426, 7.49166697,\n",
       "       7.69209429, 7.57541621, 7.65877554, 7.85252749, 7.54858791])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_OLS_avg_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
