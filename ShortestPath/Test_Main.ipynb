{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "from gurobipy import *\n",
    "from rsome import ro\n",
    "from rsome import grb_solver as grb\n",
    "import rsome as rso\n",
    "from rsome import cpt_solver as cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_generation_process = \"SPO_Data_Generation\"\n",
    "data_generation_process = \"DDR_Data_Generation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyepo\n",
    "# generate data\n",
    "grid = (2,2) # grid size\n",
    "num_train = 100 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "num_test = 10000\n",
    "deg = 1.0 # polynomial degree\n",
    "e = 1 # scale of normal std or the range of uniform. For the error term\n",
    "\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "p = num_feat # num of features\n",
    "d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "num_nodes = grid[0]*grid[0]\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "mis = deg # model misspecification\n",
    "coef_seed = 1\n",
    "\n",
    "x_dist = 'uniform'\n",
    "e_dist = 'normal'\n",
    "x_low = -2\n",
    "x_up = 2\n",
    "x_mean = 2\n",
    "x_var = 2\n",
    "bump = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grandparent_directory: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Code_MacBook\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data/Test0401_DDR_Data_Generation/\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "grandparent_directory = os.path.dirname(parent_directory)\n",
    "DataPath = os.path.dirname(grandparent_directory) + '/Data/Test0401_' + data_generation_process + \"/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "print(\"grandparent_directory:\", grandparent_directory)\n",
    "print(\"DataPath:\", DataPath)\n",
    "DataPath = DataPath + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_coef_seed=\"+str(coef_seed)+\"_diff_W/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump):\n",
    "# #  ****** Coef generation *********\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,version = 0) \n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    np.random.seed(coef_seed)\n",
    "    x_test_all = {}; c_test_all = {}; x_train_all = {}; c_train_all = {}; W_star_all = {}\n",
    "    for iter in iteration_all:\n",
    "        W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, iter,version = 0) \n",
    "        DataPath_seed = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        # #  ****** Data generation *********\n",
    "        x_test_all[iter], c_test_all[iter], x_train_all[iter], c_train_all[iter], W_star_all[iter] = data_gen.generate_samples(iter,DataPath_seed,p, d, num_test, num_train, alpha, W_star, mis, num_test, \n",
    "                                data_generation_process, x_dist, e_dist, x_low, x_up, x_mean, x_var, bump) \n",
    "        # print()\n",
    "    return x_test_all, c_test_all, x_train_all, c_train_all, W_star_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPO(SPO+,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PYEPO import PyEPO_Method\n",
    "# epo_runner = PyEPO_Method()\n",
    "def Implement_EPO(DataPath,seed_all,batch_size,num_epochs,method_names,x_train_all,c_train_all,x_test_all,c_test_all,arcs,epo_runner):\n",
    "    cost_EPO = {}\n",
    "    for seed in seed_all:\n",
    "        DataPath_seed = DataPath +\"Seed=\"+str(seed)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        # print(\"*** seed = \",seed,\": Run EPO ******\")\n",
    "        cost_EPO[seed] = epo_runner.run(method_names,DataPath_seed,batch_size,num_feat,grid,num_epochs,\\\n",
    "                                        x_train_all[seed],c_train_all[seed],x_test_all[seed],c_test_all[seed],arcs)\n",
    "    return cost_EPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain DDR estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getArcs(grid):\n",
    "    arcs = []\n",
    "    for i in range(grid[0]):\n",
    "        # edges on rows\n",
    "        for j in range(grid[1] - 1):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + 1))\n",
    "        # edges in columns\n",
    "        if i == grid[0] - 1:\n",
    "            continue\n",
    "        for j in range(grid[1]):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + grid[1]))\n",
    "\n",
    "    arc_index_mapping = {}\n",
    "    for i in range(len(arcs)):\n",
    "        arc = arcs[i]\n",
    "        arc_index_mapping[arc] = i\n",
    "\n",
    "    return arcs,arc_index_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_DDR(arcs,lamb,mu_fixed,num_nodes,x_train,c_train):\n",
    "    \n",
    "    N,p = x_train.shape\n",
    "    N,d = c_train.shape\n",
    "\n",
    "    # DDR\n",
    "    m = Model(\"ddr\")\n",
    "    #m.setParam(\"DualReductions\",0)\n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    W_ind = tuplelist( [(i,j) for i in range(d) for j in range(p)] )\n",
    "    w0_ind = tuplelist( [i for i in range(d)])\n",
    "\n",
    "    W_ddr = m.addVars(W_ind, lb=-GRB.INFINITY,name = \"W\" )\n",
    "    w0_ddr = m.addVars(w0_ind, lb=-GRB.INFINITY,name = \"W0\" )\n",
    "    alpha = m.addVars(N,num_nodes,lb=-GRB.INFINITY,name=\"alpha\")\n",
    "    expr_obj = 0\n",
    "    err = []\n",
    "    for n in range(N):\n",
    "        cost_true_tem = c_train[n]\n",
    "        expr_obj = expr_obj + alpha[n,num_nodes-1] - alpha[n,0]\n",
    "        for ind in range(len(arcs)):\n",
    "            cost_pred_tem = quicksum([W_ddr[ind,j] * x_train[n,j] for j in range(p)]) + w0_ddr[ind]\n",
    "            err.append(cost_true_tem[ind] - cost_pred_tem)\n",
    "            e = arcs[ind]\n",
    "            j = e[1]\n",
    "            i = e[0]\n",
    "            # print(\"j = \",j,\", i = \",i, \", e = \",e)\n",
    "            m.addConstr(alpha[n,j] - alpha[n,i] >= -mu_fixed*cost_true_tem[ind] - (1-mu_fixed)*cost_pred_tem)\n",
    "\n",
    "    m.setObjective(quicksum([err[k] * err[k] for k in range(len(err))])/N + lamb*(expr_obj)/N, GRB.MINIMIZE)\n",
    "    m.optimize()\n",
    "    \n",
    "    W_DDR_rst = m.getAttr('x', W_ddr)\n",
    "    w0_DDR_rst = m.getAttr('x', w0_ddr)\n",
    "    W_ddr_val = []\n",
    "    for i in range(d):\n",
    "        W_ddr_val.append([W_DDR_rst[(i,j)] for j in range(p)])\n",
    "    w0_ddr_val = [w0_DDR_rst[i] for i in range(d)]\n",
    "\n",
    "    alpha_rst = m.getAttr('x', alpha)\n",
    "    return w0_ddr_val,W_ddr_val,alpha_rst,m.ObjVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-sample performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcs,arc_index_mapping = _getArcs(grid)\n",
    "num_arcs = len(arcs)\n",
    "iteration_all = np.arange(0,10)\n",
    "# obtain data\n",
    "x_test_all, c_test_all, x_train_all, c_train_all, W_star_all = Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8929, 0.332 , 0.8212, 0.0417, 0.1077],\n",
       "       [0.5951, 0.5298, 0.4188, 0.3354, 0.6225],\n",
       "       [0.4381, 0.7359, 0.518 , 0.5789, 0.6454],\n",
       "       [0.9902, 0.8199, 0.4132, 0.8763, 0.8238]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(W_star_all[6],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPO performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EPO, including SPO, PG, LTR\n",
    "# batch_size = 20\n",
    "# num_epochs = 100\n",
    "# method_names = [\"spo+\",\"pg\",\"ltr\"]\n",
    "# method_names = [\"spo+\"]\n",
    "# from PYEPO import PyEPO_Method\n",
    "# epo_runner = PyEPO_Method()\n",
    "\n",
    "# cost_EPO_all = Implement_EPO(DataPath,[1],batch_size,num_epochs,method_names,x_train_all,c_train_all,x_test_all,c_test_all,arcs,epo_runner)\n",
    "# print(\"SPO+Cost = \",np.nanmean(cost_EPO_all[1][\"SPO\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle Cost =  [13.3035 13.3218 13.6684 13.2319 12.9373 13.5863 13.4639 13.3154 13.3031\n",
      " 13.5261]\n"
     ]
    }
   ],
   "source": [
    "from Peformance import performance_evaluation\n",
    "perfs = performance_evaluation()\n",
    "cost_Oracle_all = {}; cost_Oracle_avg = np.zeros(len(iteration_all))\n",
    "for iter in iteration_all:\n",
    "    cost_Oracle_all[iter] = perfs.compute_Cost_with_Prediction(arcs,np.ones(num_arcs)*bump, W_star_all[iter],grid,c_test_all[iter],x_test_all[iter])\n",
    "    cost_Oracle_avg[iter] = np.nanmean(cost_Oracle_all[iter])\n",
    "print(\"Oracle Cost = \",np.round(cost_Oracle_avg,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS cost =  [13.3374 13.3344 13.6979 13.24   12.9433 13.5946 13.4978 13.3584 13.3254\n",
      " 13.5729]\n"
     ]
    }
   ],
   "source": [
    "from OLS import ols_method\n",
    "ols_method_obj = ols_method()\n",
    "W_ols_all = {}; w0_ols_all = {}; t_ols_all = {}; obj_ols_all = {}\n",
    "cost_OLS_all = {};cost_OLS_avg = np.zeros(len(iteration_all))\n",
    "for iter in iteration_all:\n",
    "    # compute OLS performance\n",
    "    W_ols_all[iter], w0_ols_all[iter], t_ols_all[iter], obj_ols_all[iter] = ols_method_obj.ols_solver(\"\",x_train_all[iter], c_train_all[iter])\n",
    "    cost_OLS_all[iter] = perfs.compute_Cost_with_Prediction(arcs,w0_ols_all[iter],W_ols_all[iter], grid,c_test_all[iter],x_test_all[iter])\n",
    "    cost_OLS_avg[iter] = np.nanmean(cost_OLS_all[iter])\n",
    "print(\"OLS cost = \",np.round(cost_OLS_avg,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_DDR_out_of_sample_performance(mu_all,lamb_all,num_nodes,x_train,c_train,x_test,c_test,perfs):\n",
    "    lamb_index = 0\n",
    "    cost_DDR = {}; w0_ddr_dict = {}; W_ddr_dict = {}\n",
    "    cost_DDR_avg = np.zeros((len(mu_all),len(lamb_all)))\n",
    "    mu_index = 0\n",
    "    for mu in mu_all:\n",
    "        lamb_index = 0\n",
    "        for lamb in lamb_all:\n",
    "            w0_ddr_dict[mu,lamb],W_ddr_dict[mu,lamb],alpha_rst,obj_ddr = solve_DDR(arcs,lamb,mu,num_nodes,x_train,c_train)\n",
    "            cost_DDR[mu,lamb] = perfs.compute_Cost_with_Prediction(arcs,w0_ddr_dict[mu,lamb],W_ddr_dict[mu,lamb], grid,c_test,x_test)\n",
    "            cost_DDR_avg[mu_index,lamb_index] = np.nanmean(cost_DDR[mu,lamb])\n",
    "            lamb_index = lamb_index + 1\n",
    "        # print(\"cost_DDR_avg=\",np.round(cost_DDR_avg[0,:],4))\n",
    "        mu_index = mu_index + 1\n",
    "    return cost_DDR,w0_ddr_dict,W_ddr_dict,cost_DDR_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter= 0 ,DDR_vs_OLS =  [[-1.900e+00 -2.740e+00 -3.170e+00 -8.600e-01  2.600e+00  2.800e-01\n",
      "   2.720e+00  2.650e+00  2.920e+00  3.940e+00]\n",
      " [-5.900e-01 -2.920e+00 -4.490e+00 -5.690e+00 -1.254e+01 -1.225e+01\n",
      "  -1.379e+01 -1.525e+01 -1.894e+01 -2.331e+01]\n",
      " [-2.700e-01  1.000e-02  2.420e+00  4.670e+00 -9.100e+00 -2.600e+00\n",
      "  -6.450e+00 -1.251e+01 -2.371e+01 -1.619e+01]\n",
      " [ 1.300e-01  5.300e-01  2.100e-01 -9.000e-02  2.800e-01  3.000e-02\n",
      "  -6.330e+00 -1.570e+00  8.680e+00  2.850e+00]\n",
      " [ 0.000e+00 -1.400e-01  2.640e+00  1.230e+00  2.250e+00  3.900e-01\n",
      "   2.600e-01  4.460e+00  3.690e+00  8.200e-01]\n",
      " [ 0.000e+00 -7.400e-01  2.320e+00  4.450e+00  2.690e+00  2.520e+00\n",
      "   8.100e-01  2.830e+00  5.000e-02  1.400e-01]\n",
      " [ 0.000e+00 -1.150e+00 -1.090e+00 -2.500e-01 -3.800e-01  1.110e+00\n",
      "   1.870e+00 -2.070e+00 -2.160e+00 -4.600e+00]\n",
      " [ 4.100e-01 -2.840e+00 -1.590e+00  2.000e-01 -5.800e-01 -4.300e-01\n",
      "  -1.480e+00 -3.850e+00 -3.910e+00 -3.480e+00]\n",
      " [ 0.000e+00 -3.080e+00 -2.800e+00 -1.560e+00 -1.120e+00 -1.700e+00\n",
      "  -1.510e+00 -4.100e-01 -1.450e+00 -3.370e+00]\n",
      " [ 0.000e+00 -1.440e+00 -3.080e+00 -4.380e+00 -4.130e+00 -3.060e+00\n",
      "  -3.090e+00 -8.200e-01 -1.250e+00 -1.700e+00]]\n",
      "iter= 1 ,DDR_vs_OLS =  [[-3.700e-01 -8.600e+00 -3.950e+00 -2.216e+01 -2.587e+01 -2.560e+01\n",
      "  -4.441e+01 -5.851e+01 -7.332e+01 -6.857e+01]\n",
      " [ 2.120e+00 -9.000e-01 -9.230e+00 -2.790e+00 -1.072e+01 -1.497e+01\n",
      "  -1.638e+01 -3.723e+01 -5.657e+01 -7.377e+01]\n",
      " [-9.100e-01 -2.840e+00 -6.810e+00 -6.340e+00 -1.076e+01 -9.720e+00\n",
      "  -1.283e+01 -1.345e+01 -1.509e+01 -9.660e+00]\n",
      " [ 9.100e-01  2.180e+00 -4.820e+00 -3.130e+00 -1.205e+01 -1.127e+01\n",
      "  -7.470e+00 -9.720e+00 -1.079e+01 -9.480e+00]\n",
      " [ 3.930e+00  1.010e+01  5.410e+00 -2.170e+00 -2.770e+00  3.550e+00\n",
      "  -5.100e+00 -1.586e+01 -1.971e+01 -1.570e+00]\n",
      " [ 9.100e-01  4.870e+00  9.510e+00  3.790e+00  7.090e+00  1.017e+01\n",
      "   2.800e+00  4.490e+00  1.001e+01  2.174e+01]\n",
      " [ 9.100e-01 -3.470e+00  7.000e-02  3.140e+00  4.910e+00 -1.128e+01\n",
      "  -5.660e+00 -1.132e+01 -1.368e+01 -1.685e+01]\n",
      " [ 3.930e+00  3.450e+00  1.075e+01  7.700e+00  2.870e+00 -6.690e+00\n",
      "  -9.410e+00 -1.320e+01 -1.657e+01 -1.026e+01]\n",
      " [ 0.000e+00  6.580e+00  4.490e+00  1.327e+01  9.950e+00  1.398e+01\n",
      "   1.118e+01  3.160e+00  9.700e-01 -3.470e+00]\n",
      " [ 0.000e+00  9.100e-01  3.560e+00  1.400e-01 -1.700e+00 -1.960e+00\n",
      "   1.130e+00  3.870e+00  3.800e-01  1.450e+00]]\n",
      "iter= 2 ,DDR_vs_OLS =  [[ -0.55  -3.51  -4.64  -2.96  -1.74   1.18  -3.19  10.61  19.21  18.28]\n",
      " [  0.6   -3.04  -6.62 -10.16   1.61  13.39  -4.08   3.28  26.79  19.73]\n",
      " [  0.6   -5.45 -11.37  -3.41  -2.76  11.99   9.46   2.99 -17.4   -6.51]\n",
      " [  0.21  -0.11  -3.36  -4.77  -6.27  -1.78   7.21  12.27  13.33  14.61]\n",
      " [  0.     1.28   4.78   2.09   4.79   7.23   5.06   7.05   2.26   3.16]\n",
      " [  0.    -2.6    1.45  -3.2   -5.27  -1.67   1.24  -0.48  -0.37   0.48]\n",
      " [  0.    -0.3   -0.97  -1.54  -3.26  -4.25  -5.37  -6.36  -3.31  -4.16]\n",
      " [  0.     0.74   1.65   1.84   1.65   0.63  -3.22  -2.9   -2.78  -5.36]\n",
      " [  0.    -0.23   0.34   1.51   2.93   1.7    2.06   1.48  -1.62  -3.74]\n",
      " [  0.     0.58  -1.43  -2.15  -1.29  -0.87  -0.28  -0.28  -1.12  -1.13]]\n",
      "iter= 3 ,DDR_vs_OLS =  [[   0.     -6.46   -1.76   -3.99   -4.99    3.73    6.26   -7.23  -13.36\n",
      "   -19.7 ]\n",
      " [   1.69   -6.34  -15.7    -7.28    4.8    -0.78    2.31   16.54   22.37\n",
      "     0.36]\n",
      " [   0.     -7.77  -13.97  -13.46  -22.89  -41.96  -52.75  -42.35  -58.77\n",
      "   -76.44]\n",
      " [  -2.52   -4.77  -13.84   -6.65  -15.52  -21.04  -70.85  -83.76  -97.08\n",
      "  -100.37]\n",
      " [  -2.52   -8.59   -4.14  -10.04  -19.63  -22.14  -35.67  -47.89  -72.9\n",
      "   -71.14]\n",
      " [  -2.52  -12.2   -13.39  -15.26  -18.09  -14.84  -14.98  -40.71  -44.99\n",
      "   -48.9 ]\n",
      " [   0.     -9.74   -8.9    -6.09  -15.97  -15.55  -22.85  -21.19  -26.24\n",
      "   -26.03]\n",
      " [   0.     -7.19  -11.47  -13.01  -12.17   -7.95  -20.07  -25.28  -33.57\n",
      "   -33.23]\n",
      " [   0.     -0.28   -0.28   -7.82   -1.81   -1.81   -2.73   -1.97    3.69\n",
      "     1.18]\n",
      " [   0.      2.24    2.24    1.84    1.84    2.28    2.28    2.28    2.28\n",
      "    -4.64]]\n",
      "iter= 4 ,DDR_vs_OLS =  [[  0.    18.    10.59  27.82  34.89  23.6   31.03  54.99  62.99  56.65]\n",
      " [  0.    15.51  16.9   47.36  36.35  42.05  39.5   73.17  69.82  51.39]\n",
      " [  0.    11.11  12.76  30.32  49.89  45.11  32.71  55.2   70.87  72.37]\n",
      " [  0.    -0.75  -3.21  12.24  39.43  38.55  60.89  38.81  69.78  75.41]\n",
      " [  0.     0.54   5.35   4.62  18.23   2.3    3.89  13.53  10.63   9.16]\n",
      " [  0.     2.67   3.57   7.12  12.83  11.73   6.08  20.53  32.16  18.45]\n",
      " [  0.   -13.61 -13.21  -3.79  -8.15 -11.44 -14.36  -9.91 -12.76  -2.47]\n",
      " [  0.    -0.5   -6.55  -0.49  -0.79  -3.81  -3.81  -1.91  -1.95  -7.26]\n",
      " [  0.     0.19   5.81  11.4    8.96   0.87  -3.29   6.88   1.84   2.2 ]\n",
      " [  0.     0.19   0.19   1.78   1.78   7.4    7.4   10.43  10.94   6.9 ]]\n",
      "iter= 5 ,DDR_vs_OLS =  [[ -4.72  12.68  19.15  -5.65 -27.11 -41.11 -24.89 -36.94 -51.18 -47.03]\n",
      " [ -4.72   4.91  -9.26 -23.33 -17.   -15.31 -14.44 -10.32  -5.26   2.89]\n",
      " [ -3.01   1.16  10.2   34.45  20.75  58.61  57.23  87.5   80.98  32.38]\n",
      " [  0.32   9.92  27.52  23.02  22.25  27.58  48.34  44.82  43.34  23.28]\n",
      " [ -4.72   9.44  30.35  16.42  26.89  10.19  13.7   25.63  25.03  33.1 ]\n",
      " [ -4.72   6.17  29.59  31.13  21.32  31.59  39.47  12.55  27.42  38.8 ]\n",
      " [  0.     2.79   4.92   5.93  21.31  -4.8    6.84   6.22  17.33  32.54]\n",
      " [ -4.72   0.13   5.49  21.19  20.33  21.24  25.93  31.47  21.62  25.63]\n",
      " [  0.    -2.18   5.08   4.59   6.22  15.82   4.57  11.6   14.    12.12]\n",
      " [  0.    -3.01  -2.91   3.11  -1.69   1.31   3.86   2.21  -1.56  -8.9 ]]\n",
      "iter= 6 ,DDR_vs_OLS =  [[-3.800e-01 -6.080e+00 -8.820e+00 -1.355e+01 -1.890e+01 -1.954e+01\n",
      "  -2.081e+01 -3.151e+01 -3.642e+01 -3.674e+01]\n",
      " [-3.800e-01 -6.240e+00 -8.710e+00 -1.221e+01 -1.716e+01 -1.271e+01\n",
      "  -1.259e+01 -1.371e+01 -1.142e+01 -1.364e+01]\n",
      " [-3.800e-01 -3.890e+00 -4.730e+00 -1.910e+00 -2.690e+00 -2.610e+00\n",
      "  -6.890e+00 -6.310e+00 -1.181e+01 -1.660e+01]\n",
      " [ 0.000e+00 -3.040e+00 -7.810e+00 -9.610e+00 -1.318e+01 -1.651e+01\n",
      "  -1.877e+01 -1.831e+01 -1.586e+01 -1.523e+01]\n",
      " [ 0.000e+00 -1.270e+00 -6.680e+00 -1.256e+01 -1.564e+01 -1.385e+01\n",
      "  -1.162e+01 -1.542e+01 -2.160e+01 -2.124e+01]\n",
      " [ 0.000e+00 -3.730e+00 -5.420e+00 -9.600e+00 -9.080e+00 -1.448e+01\n",
      "  -1.385e+01 -1.523e+01 -1.525e+01 -2.059e+01]\n",
      " [ 2.500e-01 -4.180e+00 -6.870e+00 -1.058e+01 -1.111e+01 -1.515e+01\n",
      "  -1.761e+01 -1.739e+01 -1.460e+01 -1.685e+01]\n",
      " [ 2.500e-01 -1.690e+00 -4.020e+00 -7.810e+00 -1.013e+01 -1.268e+01\n",
      "  -1.584e+01 -2.599e+01 -2.947e+01 -2.873e+01]\n",
      " [-2.000e-02 -3.500e-01 -4.560e+00 -4.860e+00 -5.960e+00 -8.000e+00\n",
      "  -9.260e+00 -1.296e+01 -1.336e+01 -1.845e+01]\n",
      " [-2.000e-02  8.700e-01  1.350e+00 -3.000e+00 -2.990e+00 -3.480e+00\n",
      "  -5.790e+00 -7.790e+00 -6.710e+00 -6.670e+00]]\n",
      "iter= 7 ,DDR_vs_OLS =  [[-1.700e-01 -4.690e+00 -4.680e+00 -3.990e+00 -6.940e+00 -8.940e+00\n",
      "  -1.095e+01 -1.632e+01 -1.823e+01 -1.852e+01]\n",
      " [-1.700e-01 -2.200e+00 -6.970e+00 -2.990e+00 -3.730e+00 -3.670e+00\n",
      "  -1.042e+01 -1.435e+01 -1.701e+01 -1.658e+01]\n",
      " [-8.800e-01 -2.650e+00 -5.560e+00 -7.300e+00 -7.940e+00 -9.800e+00\n",
      "  -1.068e+01 -1.072e+01 -1.375e+01 -1.527e+01]\n",
      " [-5.300e-01 -2.000e+00 -4.780e+00 -4.630e+00 -5.340e+00 -6.340e+00\n",
      "  -1.064e+01 -1.033e+01 -1.209e+01 -2.040e+01]\n",
      " [-5.300e-01 -4.420e+00 -5.650e+00 -6.420e+00 -8.330e+00 -1.027e+01\n",
      "  -1.294e+01 -1.369e+01 -1.634e+01 -2.184e+01]\n",
      " [-8.800e-01 -1.050e+00 -5.740e+00 -4.840e+00 -7.880e+00 -8.810e+00\n",
      "  -9.720e+00 -9.180e+00 -1.158e+01 -8.390e+00]\n",
      " [-5.300e-01 -9.400e-01 -2.460e+00 -1.970e+00 -4.100e+00 -3.620e+00\n",
      "  -4.220e+00 -3.820e+00 -5.650e+00 -7.120e+00]\n",
      " [-5.300e-01 -2.340e+00 -2.120e+00 -9.800e-01 -4.680e+00 -2.940e+00\n",
      "  -4.120e+00 -3.530e+00 -1.500e+00 -2.100e+00]\n",
      " [-5.300e-01 -9.200e-01  5.000e-02  2.000e-02 -8.900e-01  1.150e+00\n",
      "   0.000e+00  1.240e+00  1.970e+00  2.680e+00]\n",
      " [-5.300e-01 -1.000e+00 -7.800e-01  9.100e-01 -1.840e+00 -7.300e-01\n",
      "   8.100e-01  1.000e-02 -9.000e-02 -7.300e-01]]\n",
      "iter= 8 ,DDR_vs_OLS =  [[ 1.570e+00 -6.600e-01 -2.300e-01  1.900e+00  2.800e-01  7.750e+00\n",
      "   5.460e+00  6.170e+00  8.890e+00 -1.255e+01]\n",
      " [ 7.700e-01  3.640e+00  5.350e+00  8.070e+00  5.440e+00  6.240e+00\n",
      "   9.410e+00  6.100e+00  4.630e+00  9.860e+00]\n",
      " [ 7.700e-01  3.440e+00  8.540e+00  4.970e+00  1.308e+01  7.870e+00\n",
      "   8.220e+00  6.160e+00  3.610e+00  2.600e+00]\n",
      " [-1.200e-01  1.000e-02 -4.400e-01 -2.190e+00  1.058e+01  4.480e+00\n",
      "   2.770e+00 -3.230e+00 -1.620e+00 -6.630e+00]\n",
      " [-1.200e-01  3.820e+00  5.100e+00  6.130e+00  8.240e+00  9.720e+00\n",
      "   1.018e+01  7.840e+00  3.750e+00  5.310e+00]\n",
      " [-1.200e-01  8.800e-01  1.540e+00  3.850e+00  5.940e+00  6.490e+00\n",
      "   4.880e+00  8.100e+00  3.100e-01 -1.590e+00]\n",
      " [-1.200e-01  5.260e+00  4.760e+00  3.780e+00  4.310e+00  6.060e+00\n",
      "   6.400e+00  9.810e+00  1.263e+01  1.206e+01]\n",
      " [ 8.200e-01  1.470e+00  5.240e+00  2.860e+00  2.180e+00  4.460e+00\n",
      "   5.350e+00  6.380e+00  6.290e+00  9.530e+00]\n",
      " [ 0.000e+00  1.700e+00  4.610e+00  1.640e+00  2.000e+00  1.260e+00\n",
      "   3.080e+00  3.230e+00  5.450e+00  7.290e+00]\n",
      " [ 0.000e+00 -1.730e+00 -2.600e-01  1.580e+00  3.250e+00  3.970e+00\n",
      "   3.250e+00  3.250e+00  4.590e+00  4.510e+00]]\n",
      "iter= 9 ,DDR_vs_OLS =  [[  1.17   5.93  12.64  23.86  31.28  33.82  38.5   44.35  42.19  41.98]\n",
      " [ -0.07   1.91   4.56   7.81   6.79   4.47  10.77   9.24  15.81  28.14]\n",
      " [  0.29  -0.85   3.93   6.53   7.06   5.67   6.92  13.67  16.64  14.21]\n",
      " [  0.29  -1.57   2.59   0.32  -0.13  -0.28   0.24   6.46   6.23  16.71]\n",
      " [  0.19  -2.92  -1.5   -2.24  -1.17   1.37   1.91  -8.04 -12.58  -6.49]\n",
      " [  0.19  -5.19  -5.79  -5.36  -4.95  -2.9   -7.97  -7.    -3.01  -1.28]\n",
      " [  0.4   -2.19  -5.02  -4.39  -1.84   0.34   0.55  -1.07   0.56   0.74]\n",
      " [  0.4   -0.13  -0.95  -2.59  -3.01  -0.42   0.94   1.61   0.51  -0.21]\n",
      " [  0.    -1.16  -2.    -2.77  -4.53  -6.76  -8.47  -7.21  -7.83  -9.68]\n",
      " [  0.     0.51   0.35  -0.84  -3.42  -2.6   -5.7   -5.97  -5.59  -5.63]]\n"
     ]
    }
   ],
   "source": [
    "mu_all = np.arange(0.01,1.0,0.1)\n",
    "lamb_all = np.round(np.arange(0.01,1,0.1),4)\n",
    "regret_all = {}; cost_DDR_all = {}; w0_ddr_all = {}; W_ddr_all = {}\n",
    "cost_DDR_avg_all = np.zeros((len(mu_all),len(lamb_all)))\n",
    "regred_DDR_vs_OLS_all = np.zeros((len(mu_all),len(lamb_all)))\n",
    "\n",
    "for iter in iteration_all:\n",
    "    cost_DDR_all[iter],w0_ddr_all[iter],W_ddr_all[iter],cost_DDR_avg = obtain_DDR_out_of_sample_performance(mu_all,lamb_all,num_nodes,x_train_all[iter],c_train_all[iter],x_test_all[iter],c_test_all[iter],perfs)\n",
    "    cost_DDR_avg_all = cost_DDR_avg_all + cost_DDR_avg\n",
    "    regert_tem = (np.nanmean(cost_OLS_all[iter]) - cost_DDR_avg)/(np.nanmean(cost_OLS_all[iter]) - np.nanmean(cost_Oracle_all[iter])) * 100\n",
    "    print(\"iter=\",iter,\",DDR_vs_OLS = \",np.round(regert_tem,2))\n",
    "    regred_DDR_vs_OLS_all = regred_DDR_vs_OLS_all + regert_tem\n",
    "cost_DDR_avg_all = cost_DDR_avg_all/len(iteration_all)\n",
    "regred_DDR_vs_OLS_all = regred_DDR_vs_OLS_all/len(iteration_all)\n",
    "# print(\"regred_DDR_vs_OLS_all=\",regred_DDR_vs_OLS_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regred_DDR_vs_OLS_all= [[-0.54  0.39  1.51  0.04 -1.65 -2.48 -2.03 -3.17 -5.63 -8.23]\n",
      " [-0.08  0.43 -3.42 -0.12 -0.62  0.64 -0.97  1.75  3.02 -1.49]\n",
      " [-0.38 -0.77 -0.46  4.85  3.46  6.26  2.49  8.02  3.16 -1.91]\n",
      " [-0.13  0.04 -0.79  0.45  2.    1.34  0.54 -2.46  0.39 -1.92]\n",
      " [-0.38  0.78  3.57 -0.3   1.29 -1.15 -3.03 -4.24 -9.78 -7.07]\n",
      " [-0.72 -1.09  1.76  1.21  0.46  1.98  0.88 -2.41 -0.53 -0.11]\n",
      " [ 0.09 -2.75 -2.88 -1.58 -1.43 -5.86 -5.44 -5.71 -4.79 -3.27]\n",
      " [ 0.06 -0.89 -0.36  0.89 -0.44 -0.86 -2.57 -3.72 -6.13 -5.55]\n",
      " [-0.06  0.03  1.07  1.54  1.58  1.65 -0.44  0.51  0.37 -1.33]\n",
      " [-0.06 -0.19 -0.08 -0.1  -1.02  0.23  0.39  0.72  0.19 -1.65]]\n"
     ]
    }
   ],
   "source": [
    "print(\"regred_DDR_vs_OLS_all=\",np.round(regred_DDR_vs_OLS_all,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(DataPath+'cost_OLS_all.pkl', \"wb\") as tf:\n",
    "#     pickle.dump(cost_OLS_all,tf)\n",
    "# with open(DataPath+'cost_Oracle_all.pkl', \"wb\") as tf:\n",
    "#     pickle.dump(cost_Oracle_all,tf)\n",
    "# with open(DataPath+'cost_DDR_all.pkl', \"wb\") as tf:\n",
    "#     pickle.dump(cost_DDR_all,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 1\n",
    "# lamb = 1\n",
    "# cost_OLS_esti = x_test_all[seed] @ np.asarray(W_ols_all[seed]).T + w0_ols_all[seed]\n",
    "# cost_DDR_esti = x_test_all[seed] @ np.asarray(W_ddr_all[seed,mu][lamb]).T + w0_ddr_all[seed,mu][lamb]\n",
    "\n",
    "# S_test_index = 3\n",
    "# print(\"cost_DDR_esti=\",np.round(cost_DDR_esti[S_test_index,],2))\n",
    "# # print(\"cost:(0,1)-->(1,3) = \",cost_DDR_esti[S_test_index,0] + cost_DDR_esti[S_test_index,2])\n",
    "# # print(\"cost:(0,2)-->(2,3) = \",cost_DDR_esti[S_test_index,1] + cost_DDR_esti[S_test_index,3])\n",
    "\n",
    "# print(\"cost_OLS_esti=\",np.round(cost_OLS_esti[S_test_index,],2))\n",
    "# # print(\"cost:(0,1)-->(1,3) = \",cost_OLS_esti[S_test_index,0] + cost_OLS_esti[S_test_index,2])\n",
    "# # print(\"cost:(0,2)-->(2,3) = \",cost_OLS_esti[S_test_index,1] + cost_OLS_esti[S_test_index,3])\n",
    "\n",
    "\n",
    "# print(\"cost_Oracle=\",np.round(c_test_all[seed][S_test_index],2))\n",
    "# # print(\"cost:(0,1)-->(1,3) = \",c_test_all[seed][S_test_index,0] + c_test_all[seed][S_test_index,2])\n",
    "# # print(\"cost:(0,2)-->(2,3) = \",c_test_all[seed][S_test_index,1] + c_test_all[seed][S_test_index,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_compare2plus(c_item, c_base, c_oracle):\n",
    "    c_item = np.asarray(c_item)\n",
    "    c_base = np.asarray(c_base)\n",
    "    c_oracle = np.asarray(c_oracle)\n",
    "\n",
    "    N = len(c_item)\n",
    "    c_diff = c_item - c_base\n",
    "    lbel = np.zeros((N,1))\n",
    "    \n",
    "    equals = np.sum(c_diff == 0)\n",
    "    wins = np.sum(c_diff < 0)\n",
    "    lose = np.sum(c_diff > 0)\n",
    "    \n",
    "    lbel[c_diff < 0] = 1\n",
    "    lbel[c_diff > 0] = -1\n",
    "    \n",
    "    # print(\"Num_train =\",N,\",Num_equals =\",equals,\",Num_wins =\",wins,\",Num_lose =\",lose)\n",
    "    # print(\"base cost = \", np.mean(c_base),\",item cost = \",np.mean(c_item))\n",
    "    if N == equals:\n",
    "        win_ratio = 0.5\n",
    "    else:\n",
    "        win_ratio = wins/(N - equals)\n",
    "    # cost_reduction = (np.mean(c_base) - np.mean(c_item) )/np.abs(np.mean(c_oracle))\n",
    "    regret_reduction = (np.nanmean(c_base) - np.nanmean(c_item))/np.abs(np.nanmean(c_base) - np.nanmean(c_oracle))\n",
    "    return lbel, win_ratio, regret_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2H_DDR_vs_OLS_all = {}; regret_reduction_DDR_vs_OLS_all = {}\n",
    "# for mu in mu_all:\n",
    "#     for lamb in lamb_all:\n",
    "#         H2H_DDR_vs_OLS_arr = np.zeros(len(iteration_all)); regret_reduction_DDR_vs_OLS_arr = np.zeros(len(iteration_all))\n",
    "#         # print(\"lamb = \",lamb)\n",
    "#         for iter in iteration_all:\n",
    "#             lbel, H2H_DDR_vs_OLS_arr[iter-1], regret_reduction_DDR_vs_OLS_arr[iter-1] = cross_compare2plus(cost_DDR_all[iter][mu,lamb],cost_OLS_all[iter], cost_Oracle_all[iter])\n",
    "#         H2H_DDR_vs_OLS_all[mu,lamb] = H2H_DDR_vs_OLS_arr; regret_reduction_DDR_vs_OLS_all[mu,lamb] = regret_reduction_DDR_vs_OLS_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu = mu_all[0]\n",
    "# lamb = lamb_all[7]\n",
    "# import Figures\n",
    "# file_name = DataPath + \"figure_mu=\"+str(mu)+\"_lamb=\"+str(lamb)\n",
    "# Figures.figure_plot_upleft(H2H_DDR_vs_OLS_all[mu,lamb]*100, regret_reduction_DDR_vs_OLS_all[mu,lamb], file_name, size = (5, 5), move = [-0.12, 0.04, 0.35, 0.55], \n",
    "#                     ysame = 0, yrange = [6,6], sublabel = '', ypio = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# ax = plt.subplot()\n",
    "# ax.plot(lamb_all,regret_all[seed,mu])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPO figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2H_SPO_vs_OLS_arr = np.zeros(len(seed_all)); regret_reduction_SPO_vs_OLS_arr = np.zeros(len(seed_all))\n",
    "# seed_index = 0\n",
    "# for seed in seed_all:\n",
    "#     lbel, H2H_SPO_vs_OLS_arr[seed_index], regret_reduction_SPO_vs_OLS_arr[seed_index] = cross_compare2plus(cost_EPO_all[seed][\"SPO\"],cost_OLS_all[seed], cost_Oracle_all[seed])\n",
    "#     seed_index = seed_index + 1\n",
    "# H2H_SPO_vs_OLS_all = H2H_SPO_vs_OLS_arr; regret_reduction_SPO_vs_OLS_all = regret_reduction_SPO_vs_OLS_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figures.figure_plot_upleft(H2H_SPO_vs_OLS_all*100, regret_reduction_SPO_vs_OLS_all, \"\", size = (5, 5), move = [-0.12, 0.04, 0.35, 0.55], \n",
    "#                     ysame = 0, yrange = [6,6], sublabel = '', ypio = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regret_reduction_SPO_vs_OLS_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
