{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "import random\n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyepo\n",
    "# generate data\n",
    "grid = (5,5) # grid size\n",
    "num_data = 100 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "num_test = 1000\n",
    "deg = 1.2 # polynomial degree\n",
    "e = 0.5 # noise width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import data_generation\n",
    "data_gen = data_generation()\n",
    "\n",
    "#  ****** Data generation process is the same as SPO+ *********\n",
    "feats, costs = data_gen.generate_Shortest_Path_Data(num_data+num_test, num_feat, grid, deg, e, seed=42)\n",
    "\n",
    "#  ****** Data generation process is the same as DDR *********\n",
    "# lower = 0\n",
    "# upper = 1\n",
    "# p = 5\n",
    "# d = 40\n",
    "# alpha = 1\n",
    "# mis = 4\n",
    "# n_epsilon = 1\n",
    "# W_star = data_gen.generate_truth(\"\",lower, upper, p, d, version = 0) \n",
    "# x_test, z_test_ori, c_test, x_train, z_train_ori, c_train, W_star = data_gen.generate_samples(\"\",p, d, num_test, num_data, alpha, W_star, n_epsilon, mis, thres = 10, \n",
    "#                         version = 1, x_dist = 'normal', e_dist = 'normal', x_low = 0, x_up = 2, x_mean = 2, x_var = 0.25, bump = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build optModel\n",
    "from pyepo.model.grb import optGrbModel\n",
    "\n",
    "class shortestPathModel(optGrbModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.grid = (5,5)\n",
    "        self.arcs = self._getArcs()\n",
    "        super().__init__()\n",
    "\n",
    "    def _getArcs(self):\n",
    "        \"\"\"\n",
    "        A helper method to get list of arcs for grid network\n",
    "\n",
    "        Returns:\n",
    "            list: arcs\n",
    "        \"\"\"\n",
    "        arcs = []\n",
    "        for i in range(self.grid[0]):\n",
    "            # edges on rows\n",
    "            for j in range(self.grid[1] - 1):\n",
    "                v = i * self.grid[1] + j\n",
    "                arcs.append((v, v + 1))\n",
    "            # edges in columns\n",
    "            if i == self.grid[0] - 1:\n",
    "                continue\n",
    "            for j in range(self.grid[1]):\n",
    "                v = i * self.grid[1] + j\n",
    "                arcs.append((v, v + self.grid[1]))\n",
    "        return arcs\n",
    "\n",
    "    def _getModel(self):\n",
    "        \"\"\"\n",
    "        A method to build Gurobi model\n",
    "\n",
    "        Returns:\n",
    "            tuple: optimization model and variables\n",
    "        \"\"\"\n",
    "        import gurobipy as gp\n",
    "        from gurobipy import GRB\n",
    "        # ceate a model\n",
    "        m = gp.Model(\"shortest path\")\n",
    "        # varibles\n",
    "        x = m.addVars(self.arcs, name=\"x\")\n",
    "        # sense\n",
    "        m.modelSense = GRB.MINIMIZE\n",
    "        # flow conservation constraints\n",
    "        for i in range(self.grid[0]):\n",
    "            for j in range(self.grid[1]):\n",
    "                v = i * self.grid[1] + j\n",
    "                expr = 0\n",
    "                for e in self.arcs:\n",
    "                    # flow in\n",
    "                    if v == e[1]:\n",
    "                        expr += x[e]\n",
    "                    # flow out\n",
    "                    elif v == e[0]:\n",
    "                        expr -= x[e]\n",
    "                # source\n",
    "                if i == 0 and j == 0:\n",
    "                    m.addConstr(expr == -1)\n",
    "                # sink\n",
    "                elif i == self.grid[0] - 1 and j == self.grid[0] - 1:\n",
    "                    m.addConstr(expr == 1)\n",
    "                # transition\n",
    "                else:\n",
    "                    m.addConstr(expr == 0)\n",
    "        return m, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepara training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPO+ data generation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, c_train, c_test = train_test_split(feats, costs, test_size=num_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-03-25\n"
     ]
    }
   ],
   "source": [
    "optmodel = shortestPathModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1999.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2190.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# get optDataset\n",
    "dataset_train = pyepo.data.dataset.optDataset(optmodel, x_train, c_train)\n",
    "dataset_test = pyepo.data.dataset.optDataset(optmodel, x_test, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loader\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 20\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_feat, (grid[0]-1)*grid[1]+(grid[1]-1)*grid[0])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyepo\n",
    "regret = pyepo.metric.regret(reg, optmodel, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPO+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# init model\n",
    "reg = LinearRegression()\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    reg = reg.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of cores: 2\n"
     ]
    }
   ],
   "source": [
    "# init SPO+ loss\n",
    "spop = pyepo.func.SPOPlus(optmodel, processes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcs_arr = optmodel.arcs\n",
    "def obtain_path(arcs_arr,sol):\n",
    "    path_arr = []\n",
    "    for arc_index in range(len(arcs_arr)):\n",
    "        if sol[arc_index] > 0:\n",
    "            path_arr.append(arcs_arr[arc_index])\n",
    "    return path_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArcs(grid):\n",
    "    arcs = []\n",
    "    for i in range(grid[0]):\n",
    "        # edges on rows\n",
    "        for j in range(grid[1] - 1):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + 1))\n",
    "        # edges in columns\n",
    "        if i == grid[0] - 1:\n",
    "            continue\n",
    "        for j in range(grid[1]):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + grid[1]))\n",
    "    return arcs\n",
    "\n",
    "def solve_Shortest_Path(arcs,cost):\n",
    "    \"\"\"\n",
    "    A method to build Gurobi model\n",
    "\n",
    "    Returns:\n",
    "        tuple: optimization model and variables\n",
    "    \"\"\"\n",
    "    import gurobipy as gp\n",
    "    from gurobipy import GRB\n",
    "    # ceate a model\n",
    "    m = gp.Model(\"shortest path\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    # varibles\n",
    "    x = m.addVars(arcs, name=\"x\")\n",
    "    # sense\n",
    "    # m.modelSense = GRB.MINIMIZE\n",
    "    # flow conservation constraints\n",
    "    for i in range(grid[0]):\n",
    "        for j in range(grid[1]):\n",
    "            v = i * grid[1] + j\n",
    "            expr = 0\n",
    "            for e in arcs:\n",
    "                # flow in\n",
    "                if v == e[1]:\n",
    "                    expr += x[e]\n",
    "                # flow out\n",
    "                elif v == e[0]:\n",
    "                    expr -= x[e]\n",
    "            # source\n",
    "            if i == 0 and j == 0:\n",
    "                m.addConstr(expr == -1)\n",
    "            # sink\n",
    "            elif i == grid[0] - 1 and j == grid[0] - 1:\n",
    "                m.addConstr(expr == 1)\n",
    "            # transition\n",
    "            else:\n",
    "                m.addConstr(expr == 0)\n",
    "    m.setObjective( sum([cost[ind] * x[arcs_arr[ind]] for ind in range(len(arcs_arr))]) , GRB.MINIMIZE)\n",
    "    m.optimize()\n",
    "    sol = m.getAttr('x')\n",
    "    # print(\"sol = \",sol)\n",
    "    shortest_path = obtain_path(arcs_arr,sol)\n",
    "    # print(\"shortest_path = \",shortest_path)\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyepo import EPO\n",
    "def evaluation_SPO(predmodel, optmodel, dataloader):\n",
    "    \"\"\"\n",
    "    A function to evaluate model performance with normalized true regret\n",
    "\n",
    "    Args:\n",
    "        predmodel (nn): a regression neural network for cost prediction\n",
    "        optmodel (optModel): an PyEPO optimization model\n",
    "        dataloader (DataLoader): Torch dataloader from optDataSet\n",
    "\n",
    "    Returns:\n",
    "        float: true regret loss\n",
    "    \"\"\"\n",
    "    # evaluate\n",
    "    predmodel.eval()\n",
    "    loss = 0\n",
    "    optsum = 0\n",
    "    cost_pred_arr = []\n",
    "    cost_true_arr = []\n",
    "    # load data\n",
    "    for data in dataloader:\n",
    "        x, c, w, z = data\n",
    "        # cuda\n",
    "        if next(predmodel.parameters()).is_cuda:\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # predict\n",
    "        with torch.no_grad(): # no grad\n",
    "            cp = predmodel(x).to(\"cpu\").detach().numpy()\n",
    "        # print(\"cp[0] = \",cp[0])\n",
    "        # solve\n",
    "        for j in range(cp.shape[0]):\n",
    "            sol_pred = solve_Shortest_Path(arcs_arr,cp[j])\n",
    "            cost_pred = np.dot(sol_pred, c[j].to(\"cpu\").detach().numpy())\n",
    "            cost_pred_arr.append(cost_pred)\n",
    "            cost_true_arr.append(z[j].item())\n",
    "    # turn back train mode\n",
    "    predmodel.train()\n",
    "    # normalized\n",
    "    return cost_true_arr,cost_pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# set adam optimizer\n",
    "optimizer = torch.optim.Adam(reg.parameters(), lr=1e-2)\n",
    "# train mode\n",
    "reg.train()\n",
    "# init log\n",
    "cost_true_arr,cost_pred_arr = evaluation_SPO(reg, optmodel, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x107521790>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: Average Predict Cost =  8.29035397285223 , Average True Cost =  6.6683534908294675\n",
      "epoch =  0  Average Predict Cost =  8.20830439093709 , Average True Cost =  6.6683534908294675\n",
      "epoch =  1  Average Predict Cost =  8.150820441365243 , Average True Cost =  6.6683534908294675\n",
      "epoch =  2  Average Predict Cost =  8.054759571045636 , Average True Cost =  6.6683534908294675\n",
      "epoch =  3  Average Predict Cost =  7.962212584391236 , Average True Cost =  6.6683534908294675\n",
      "epoch =  4  Average Predict Cost =  7.9320243769586085 , Average True Cost =  6.6683534908294675\n",
      "epoch =  5  Average Predict Cost =  7.912762609243393 , Average True Cost =  6.6683534908294675\n",
      "epoch =  6  Average Predict Cost =  7.890208253651857 , Average True Cost =  6.6683534908294675\n",
      "epoch =  7  Average Predict Cost =  7.878643666177988 , Average True Cost =  6.6683534908294675\n",
      "epoch =  8  Average Predict Cost =  7.8472349779754875 , Average True Cost =  6.6683534908294675\n",
      "epoch =  9  Average Predict Cost =  7.814152697354555 , Average True Cost =  6.6683534908294675\n",
      "epoch =  10  Average Predict Cost =  7.792723110735416 , Average True Cost =  6.6683534908294675\n",
      "epoch =  11  Average Predict Cost =  7.747778155192733 , Average True Cost =  6.6683534908294675\n",
      "epoch =  12  Average Predict Cost =  7.739882046744228 , Average True Cost =  6.6683534908294675\n",
      "epoch =  13  Average Predict Cost =  7.723714066252112 , Average True Cost =  6.6683534908294675\n",
      "epoch =  14  Average Predict Cost =  7.707664265409112 , Average True Cost =  6.6683534908294675\n",
      "epoch =  15  Average Predict Cost =  7.709871816471219 , Average True Cost =  6.6683534908294675\n",
      "epoch =  16  Average Predict Cost =  7.703626409307122 , Average True Cost =  6.6683534908294675\n",
      "epoch =  17  Average Predict Cost =  7.700120757445693 , Average True Cost =  6.6683534908294675\n",
      "epoch =  18  Average Predict Cost =  7.704190114721656 , Average True Cost =  6.6683534908294675\n",
      "epoch =  19  Average Predict Cost =  7.708644987612963 , Average True Cost =  6.6683534908294675\n",
      "epoch =  20  Average Predict Cost =  7.709310630843043 , Average True Cost =  6.6683534908294675\n",
      "epoch =  21  Average Predict Cost =  7.7061604634076355 , Average True Cost =  6.6683534908294675\n",
      "epoch =  22  Average Predict Cost =  7.7126226540058855 , Average True Cost =  6.6683534908294675\n",
      "epoch =  23  Average Predict Cost =  7.731594470962882 , Average True Cost =  6.6683534908294675\n",
      "epoch =  24  Average Predict Cost =  7.705126710936427 , Average True Cost =  6.6683534908294675\n",
      "epoch =  25  Average Predict Cost =  7.713257384940982 , Average True Cost =  6.6683534908294675\n",
      "epoch =  26  Average Predict Cost =  7.698657761648297 , Average True Cost =  6.6683534908294675\n",
      "epoch =  27  Average Predict Cost =  7.704201328471303 , Average True Cost =  6.6683534908294675\n",
      "epoch =  28  Average Predict Cost =  7.705252401188016 , Average True Cost =  6.6683534908294675\n",
      "epoch =  29  Average Predict Cost =  7.721849595680833 , Average True Cost =  6.6683534908294675\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "# set adam optimizer\n",
    "optimizer = torch.optim.Adam(reg.parameters(), lr=1e-2)\n",
    "# train mode\n",
    "reg.train()\n",
    "# init log\n",
    "cost_true_arr,cost_pred_arr = evaluation_SPO(reg, optmodel, loader_test)\n",
    "print(\"epoch 0: Average Predict Cost = \", np.mean(cost_pred_arr),\", Average True Cost = \",np.mean(cost_true_arr))\n",
    "# init elpased time\n",
    "elapsed = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # start timing\n",
    "    tick = time.time()\n",
    "    # load data\n",
    "    for i, data in enumerate(loader_train):\n",
    "        x, c, w, z = data\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        cp = reg(x)\n",
    "        loss = spop(cp, c, w, z)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # record time\n",
    "        tock = time.time()\n",
    "        elapsed += tock - tick\n",
    "        # log\n",
    "    cost_true_arr,cost_pred_arr = evaluation_SPO(reg, optmodel, loader_test)\n",
    "    print(\"epoch = \",epoch,\" Average Predict Cost = \", np.mean(cost_pred_arr),\", Average True Cost = \",np.mean(cost_true_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyepo import EPO\n",
    "def evaluation_OLS(w0_ols,W_ols, dataloader):\n",
    "\n",
    "    # evaluate\n",
    "    cost_pred_arr = []\n",
    "    # load data\n",
    "    for data in dataloader:\n",
    "        x, c, w, z = data\n",
    "        feature = x.numpy()\n",
    "        # print(\"Feature Shape = \",np.shape(feature)[0])\n",
    "        for j in range(np.shape(feature)[0]):\n",
    "            cost = W_ols @ feature[j,:] + w0_ols\n",
    "            sol_pred = solve_Shortest_Path(arcs_arr,cost)\n",
    "            cost_pred = np.dot(sol_pred, c[j].to(\"cpu\").detach().numpy())\n",
    "            cost_pred_arr.append(cost_pred)\n",
    "    # print(\"Average OLS Cost = \", np.mean(cost_pred_arr))\n",
    "    return cost_pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average OLS Cost =  7.6799817386567595\n"
     ]
    }
   ],
   "source": [
    "from OLS import ols_method\n",
    "ols_method_obj = ols_method()\n",
    "W_ols, w0_ols, t_ols, obj_ols = ols_method_obj.ols_solver(\"\",x_train, c_train)\n",
    "cost_OLS_arr = evaluation_OLS(w0_ols,W_ols, loader_test)\n",
    "print(\"Average OLS Cost = \",np.mean(cost_OLS_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner problem of the shortest path problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_Inner_Problem(arcs,cost_true,cost_pred,mu,is_binary):\n",
    "    \"\"\"\n",
    "    A method to build Gurobi model\n",
    "\n",
    "    Returns:\n",
    "        tuple: optimization model and variables\n",
    "    \"\"\"\n",
    "    import gurobipy as gp\n",
    "    from gurobipy import GRB\n",
    "    # import gurobipy as grb\n",
    "    # ceate a model\n",
    "    m = gp.Model(\"shortest path\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    if is_binary:\n",
    "    # varibles\n",
    "        x = m.addVars(arcs, lb = 0,vtype=GRB.BINARY  ,name=\"x\")\n",
    "    else:\n",
    "        x = m.addVars(arcs, lb = 0,name=\"x\")\n",
    "    # sense\n",
    "    # m.modelSense = GRB.MINIMIZE\n",
    "    # flow conservation constraints\n",
    "    for i in range(grid[0]):\n",
    "        for j in range(grid[1]):\n",
    "            v = i * grid[1] + j\n",
    "            expr = 0\n",
    "            for e in arcs:\n",
    "                # flow in\n",
    "                if v == e[1]:\n",
    "                    expr += x[e]\n",
    "                # flow out\n",
    "                elif v == e[0]:\n",
    "                    expr -= x[e]\n",
    "            # source\n",
    "            if i == 0 and j == 0:\n",
    "                m.addConstr(expr == -1)\n",
    "            # sink\n",
    "            elif i == grid[0] - 1 and j == grid[0] - 1:\n",
    "                m.addConstr(expr == 1)\n",
    "            # transition\n",
    "            else:\n",
    "                m.addConstr(expr == 0)\n",
    "    m.setObjective( sum([-mu*cost_true[ind] * x[arcs_arr[ind]] - (1-mu)*cost_pred[ind] * x[arcs_arr[ind]] for ind in range(len(arcs_arr))]) , GRB.MAXIMIZE)\n",
    "    m.optimize()\n",
    "    sol = m.getAttr('x')\n",
    "    # print(\"sol = \",sol)\n",
    "    shortest_path = obtain_path(arcs_arr,sol)\n",
    "    obj = m.ObjVal\n",
    "    # print(\"shortest_path = \",shortest_path)\n",
    "    return obj,sol,shortest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dual problem of the inner problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_Inner_Problem_Dual(arcs_arr,cost_true,cost_pred,mu):\n",
    "    num_nodes = 25\n",
    "    import gurobipy as gp\n",
    "    from gurobipy import GRB\n",
    "    # import gurobipy as grb\n",
    "    # ceate a model\n",
    "    m = gp.Model(\"Maximium path\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    alpha = m.addVars(num_nodes,name=\"alpha\")\n",
    "    # sense\n",
    "    # m.modelSense = GRB.MINIMIZE\n",
    "    # flow conservation constraints\n",
    "    for ind in range(len(arcs_arr)):\n",
    "        e = arcs_arr[ind]\n",
    "        j = e[1]\n",
    "        i = e[0]\n",
    "        # print(\"j = \",j,\", i = \",i, \", e = \",e)\n",
    "        m.addConstr(alpha[j] - alpha[i] >= -mu*cost_true[ind] - (1-mu)*cost_pred[ind])\n",
    "\n",
    "    m.setObjective( alpha[num_nodes-1] - alpha[0], GRB.MINIMIZE)\n",
    "    m.optimize()\n",
    "    # # print(\"sol = \",sol)\n",
    "    obj = m.ObjVal\n",
    "    # print(\"obj = \",obj)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the equivalence between shortest path, its linear relaxation and dual problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_continous =  -2.700267559919159\n",
      "shortest_path_con =  [(0, 1), (1, 6), (6, 7), (7, 8), (8, 13), (13, 18), (18, 23), (23, 24)]\n",
      "obj_binary =  -2.700267559919159\n",
      "shortest_path_binary =  [(0, 1), (1, 6), (6, 7), (7, 8), (8, 13), (13, 18), (18, 23), (23, 24)]\n",
      "obj_dual =  -2.7002675599191592\n"
     ]
    }
   ],
   "source": [
    "cost_true_tem = np.random.uniform(0,1,40) \n",
    "cost_pred_tem = np.random.uniform(0,1,40) \n",
    "mu_fixed = 0.4\n",
    "obj_continous,sol_continous,shortest_path_con = solve_Inner_Problem(arcs_arr,cost_true_tem,cost_pred_tem,mu_fixed,False)\n",
    "print(\"obj_continous = \",obj_continous)\n",
    "print(\"shortest_path_con = \",shortest_path_con)\n",
    "\n",
    "obj_binary,sol_binary,shortest_path_binary = solve_Inner_Problem(arcs_arr,cost_true_tem,cost_pred_tem,mu_fixed,True)\n",
    "print(\"obj_binary = \",obj_binary)\n",
    "print(\"shortest_path_binary = \",shortest_path_binary)\n",
    "\n",
    "\n",
    "obj_dual = solve_Inner_Problem_Dual(arcs_arr,cost_true_tem,cost_pred_tem,mu_fixed)\n",
    "print(\"obj_dual = \",obj_dual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "def solve_DDR(lamb,mu_fixed,num_nodes,x_train,c_train):\n",
    "    N,p = x_train.shape\n",
    "    N,d = c_train.shape\n",
    "    # print(\"Num of data = \",N, \",num of feature = \", p, \", num of acrs = \", d)\n",
    "    \n",
    "    # DDR\n",
    "    m = Model(\"ddr\")\n",
    "    #m.setParam(\"DualReductions\",0)\n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    W_ind = tuplelist( [(i,j) for i in range(d) for j in range(p)] )\n",
    "    w0_ind = tuplelist( [i for i in range(d)])\n",
    "\n",
    "    W_ddr = m.addVars( W_ind, lb=-GRB.INFINITY,name = \"W\" )\n",
    "    w0_ddr = m.addVars( w0_ind, lb=-GRB.INFINITY,name = \"W0\" )\n",
    "    alpha = m.addVars(N,num_nodes,name=\"alpha\")\n",
    "    expr_obj = 0\n",
    "    err = []\n",
    "    for n in range(N):\n",
    "        cost_true_tem = c_train[n]\n",
    "        expr_obj = expr_obj + alpha[n,num_nodes-1] - alpha[n,0]\n",
    "        for ind in range(len(arcs_arr)):\n",
    "            e = arcs_arr[ind]\n",
    "            j = e[1]\n",
    "            i = e[0]\n",
    "            cost_pred_tem = quicksum([W_ddr[ind,j] * x_train[n,j] for j in range(p)]) + w0_ddr[ind]\n",
    "            # print(\"j = \",j,\", i = \",i, \", e = \",e)\n",
    "            m.addConstr(alpha[n,j] - alpha[n,i] >= -mu_fixed*cost_true_tem[ind] - (1-mu_fixed)*cost_pred_tem)\n",
    "            err.append(cost_true_tem[ind] - cost_pred_tem)\n",
    "    m.setObjective(quicksum([err[k] * err[k] for k in range(len(err))])/N + lamb*(expr_obj)/N, GRB.MINIMIZE)\n",
    "    m.optimize()\n",
    "    W_DDR_rst = m.getAttr('x', W_ddr)\n",
    "    w0_DDR_rst = m.getAttr('x', w0_ddr)\n",
    "    W_ddr_val = []\n",
    "    for i in range(d):\n",
    "        W_ddr_val.append([W_DDR_rst[(i,j)] for j in range(p)])\n",
    "    w0_ddr_val = [w0_DDR_rst[i] for i in range(d)]\n",
    "    # print(\"w0_DDR_rst = \",w0_ddr_val)\n",
    "    return w0_ddr_val,W_ddr_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average True Cost =  6.6683534908294675 Std =  1.2185374400285396\n",
      "Average SPO Cost =  7.721849595680833 Std =  1.560122179102593\n",
      "Average OLS Cost =  7.6799817386567595 Std =  1.5318926993671838\n"
     ]
    }
   ],
   "source": [
    "print(\"Average True Cost = \",np.mean(cost_true_arr),\"Std = \", np.std(cost_true_arr))\n",
    "print(\"Average SPO Cost = \", np.mean(cost_pred_arr),\"Std = \", np.std(cost_pred_arr))\n",
    "print(\"Average OLS Cost = \", np.mean(cost_OLS_arr),\"Std = \", np.std(cost_OLS_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== lambda =  0.1 ============\n",
      "lambda =  0.1 , mu =  0.1 , Lowerst Average DDR Cost =  7.69086926355958  Std =  1.5374735989970505\n",
      "lambda =  0.1 , mu =  0.15000000000000002 , Lowerst Average DDR Cost =  7.6902248392403125  Std =  1.5374344489144305\n",
      "lambda =  0.1 , mu =  0.20000000000000004 , Lowerst Average DDR Cost =  7.683062559485435  Std =  1.5288134090938752\n",
      "lambda =  0.1 , mu =  0.3500000000000001 , Lowerst Average DDR Cost =  7.680836561828852  Std =  1.5359545452277896\n",
      "lambda =  0.1 , mu =  0.6000000000000002 , Lowerst Average DDR Cost =  7.68034748211503  Std =  1.5321031530001343\n",
      "lambda =  0.1 , mu =  0.9000000000000002 , Lowerst Average DDR Cost =  7.677918752789497  Std =  1.5298038000216558\n",
      "lambda =  0.1 , mu =  0.9500000000000003 , Lowerst Average DDR Cost =  7.676757207006216  Std =  1.5304983332245425\n",
      "======== lambda =  0.15000000000000002 ============\n",
      "======== lambda =  0.20000000000000004 ============\n",
      "======== lambda =  0.25000000000000006 ============\n",
      "======== lambda =  0.30000000000000004 ============\n",
      "======== lambda =  0.3500000000000001 ============\n",
      "lambda =  0.3500000000000001 , mu =  0.8000000000000003 , Lowerst Average DDR Cost =  7.674798047125339  Std =  1.527915101747986\n",
      "======== lambda =  0.40000000000000013 ============\n",
      "======== lambda =  0.4500000000000001 ============\n",
      "======== lambda =  0.5000000000000001 ============\n",
      "======== lambda =  0.5500000000000002 ============\n",
      "======== lambda =  0.6000000000000002 ============\n",
      "======== lambda =  0.6500000000000001 ============\n",
      "======== lambda =  0.7000000000000002 ============\n",
      "======== lambda =  0.7500000000000002 ============\n",
      "======== lambda =  0.8000000000000003 ============\n",
      "======== lambda =  0.8500000000000003 ============\n",
      "======== lambda =  0.9000000000000002 ============\n",
      "lambda =  0.9000000000000002 , mu =  0.9000000000000002 , Lowerst Average DDR Cost =  7.673496220469475  Std =  1.5307839097013285\n",
      "======== lambda =  0.9500000000000003 ============\n"
     ]
    }
   ],
   "source": [
    "mu_arr = np.arange(0.1,1,0.05)\n",
    "# lamb_arr = np.arange(0.05,0.2,0.05)\n",
    "lamb_arr = np.arange(0.1,1,0.05)\n",
    "# lamb_arr = [0.1]\n",
    "minimum_value = 1000000000\n",
    "for lamb in lamb_arr:\n",
    "    print(\"======== lambda = \",lamb,\"============\")\n",
    "    for mu in mu_arr:\n",
    "        num_nodes = 25\n",
    "        w0_ddr_val,W_ddr_val = solve_DDR(lamb,mu,num_nodes,x_train,c_train)\n",
    "        cost_DDR_arr = evaluation_OLS(w0_ddr_val,W_ddr_val, loader_test)\n",
    "        \n",
    "        if np.mean(cost_DDR_arr) < minimum_value:\n",
    "            minimum_value = np.mean(cost_DDR_arr)\n",
    "            print(\"lambda = \",lamb, \", mu = \",mu, \", Lowerst Average DDR Cost = \",minimum_value, \" Std = \",np.std(cost_DDR_arr))\n",
    "        # print(\"lambda = \",lamb, \", mu = \",mu, \",Average DDR Cost = \",np.mean(cost_DDR_arr), \" Std = \",np.std(cost_DDR_arr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
