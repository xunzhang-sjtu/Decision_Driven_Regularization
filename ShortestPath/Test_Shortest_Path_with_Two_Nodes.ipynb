{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "from gurobipy import *\n",
    "from rsome import ro\n",
    "from rsome import grb_solver as grb\n",
    "import rsome as rso\n",
    "from rsome import cpt_solver as cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_generation_process = \"SPO_Data_Generation\"\n",
    "data_generation_process = \"DDR_Data_Generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 100 # number of training data\n",
    "num_feat = 4 # size of feature\n",
    "num_test = 10000\n",
    "deg = 1.0 # polynomial degree\n",
    "e = 1.0 # scale of normal std or the range of uniform. For the error term\n",
    "num_arcs = 10\n",
    "\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "p = num_feat # num of features\n",
    "d = num_arcs # num of arcs\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "mis = deg # model misspecification\n",
    "coef_seed = 1\n",
    "\n",
    "x_dist = 'uniform'\n",
    "e_dist = 'normal'\n",
    "x_low = -2\n",
    "x_up = 2\n",
    "x_mean = 2\n",
    "x_var = 2\n",
    "bump = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data/Shortest_Path_With_2_Nodes_0401_DDR_Data_Generation/\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "grandparent_directory = os.path.dirname(parent_directory)\n",
    "DataPath = os.path.dirname(grandparent_directory) + '/Data/Shortest_Path_With_2_Nodes_0401_' + data_generation_process + \"/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "print(\"DataPath:\", DataPath)\n",
    "DataPath = DataPath + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_coef_seed=\"+str(coef_seed)+\"_diff_W/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump):\n",
    "# #  ****** Coef generation *********\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,version = 0) \n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    np.random.seed(coef_seed)\n",
    "    x_test_all = {}; c_test_all = {}; x_train_all = {}; c_train_all = {}; W_star_all = {}\n",
    "    for iter in iteration_all:\n",
    "        W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, iter,version = 0) \n",
    "        DataPath_seed = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        # #  ****** Data generation *********\n",
    "        thres = num_test\n",
    "        x_test_all[iter], c_test_all[iter], x_train_all[iter], c_train_all[iter], W_star_all[iter] = data_gen.generate_samples(iter,DataPath_seed,p, d, num_test, num_train, alpha, W_star, mis, thres, \n",
    "                                data_generation_process, x_dist, e_dist, x_low, x_up, x_mean, x_var, bump) \n",
    "\n",
    "        # print()\n",
    "    return x_test_all, c_test_all, x_train_all, c_train_all, W_star_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute out-of-sample cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_oracle_cost(cost_test):\n",
    "    data_size = np.shape(cost_test)[0]\n",
    "    _cost = np.zeros(data_size)\n",
    "    for j in range(data_size):\n",
    "        _cost[j] = np.min(cost_test[j,:])\n",
    "    return _cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_out_of_sample_cost(W,w0,cost_test,feature):\n",
    "    data_size = np.shape(feature)[0]\n",
    "    _cost = np.zeros(data_size)\n",
    "    for j in range(data_size):\n",
    "        cost = W @ feature[j,:] + w0\n",
    "        opt_index = np.argmin(cost)\n",
    "        cost_test_tem = cost_test[j,:]\n",
    "        _cost[j] = cost_test_tem[opt_index]\n",
    "    return _cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_all = np.arange(0,10)\n",
    "x_test_all, c_test_all, x_train_all, c_train_all, W_star_all = Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5507979 , 0.70814782, 0.29090474, 0.51082761],\n",
       "       [0.89294695, 0.89629309, 0.12558531, 0.20724288],\n",
       "       [0.0514672 , 0.44080984, 0.02987621, 0.45683322],\n",
       "       [0.64914405, 0.27848728, 0.6762549 , 0.59086282],\n",
       "       [0.02398188, 0.55885409, 0.25925245, 0.4151012 ],\n",
       "       [0.28352508, 0.69313792, 0.44045372, 0.15686774],\n",
       "       [0.54464902, 0.78031476, 0.30636353, 0.22195788],\n",
       "       [0.38797126, 0.93638365, 0.97599542, 0.67238368],\n",
       "       [0.90283411, 0.84575087, 0.37799404, 0.09221701],\n",
       "       [0.6534109 , 0.55784076, 0.36156476, 0.2250545 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_star_all[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_Oracle_all = {}; cost_Oracle_avg = np.zeros(len(iteration_all))\n",
    "for iter in iteration_all:\n",
    "    # cost_Oracle_all[iter] = compute_oracle_cost(c_test_all[iter])\n",
    "    cost_Oracle_all[iter] = compute_out_of_sample_cost(W_star_all[iter],np.ones(num_arcs)*bump,c_test_all[iter],x_test_all[iter])\n",
    "    cost_Oracle_avg[iter] = np.nanmean(cost_Oracle_all[iter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-03-13\n"
     ]
    }
   ],
   "source": [
    "from OLS import ols_method\n",
    "ols_method_obj = ols_method()\n",
    "W_ols_all = {}; w0_ols_all = {}; t_ols_all = {}; obj_ols_all = {}\n",
    "cost_OLS_all = {}; cost_OLS_avg = np.zeros(len(iteration_all))\n",
    "for iter in iteration_all:\n",
    "    W_ols_all[iter], w0_ols_all[iter], t_ols_all[iter], obj_ols_all[iter] = ols_method_obj.ols_solver(\"\",x_train_all[iter], c_train_all[iter])\n",
    "    cost_OLS_all[iter] = compute_out_of_sample_cost(W_ols_all[iter],w0_ols_all[iter],c_test_all[iter],x_test_all[iter])\n",
    "    cost_OLS_avg[iter] = np.nanmean(cost_OLS_all[iter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_DDR(mu,lamb,num_acrs,num_feat,num_train,c_input,x_input):\n",
    "    model = ro.Model()            # create an RSOME model\n",
    "    w0_d = model.dvar(num_acrs)\n",
    "    W_d = model.dvar((num_acrs,num_feat))\n",
    "\n",
    "    alpha = model.dvar(num_train)                   \n",
    "\n",
    "    eps = model.dvar(num_train*num_acrs)                   \n",
    "    eps_index = 0\n",
    "    for i in range(num_train):\n",
    "        for j in range(num_acrs):\n",
    "            model.st(alpha[i] >= -mu * c_input[i,j] - (1 - mu) * (W_d[j,:] @ x_input[i,:] + w0_d[j]))\n",
    "            model.st(eps[eps_index] == c_input[i,j] - W_d[j,:] @ x_input[i,:] - w0_d[j])\n",
    "            eps_index = eps_index + 1\n",
    "    model.min(rso.norm(eps) + sum(alpha) * (lamb/num_train)) \n",
    "\n",
    "    model.solve(cpt,display=False,log=False)\n",
    "    # print(\"status=\",model.solution.status)\n",
    "    w0_d_sol = w0_d.get()\n",
    "    W_d_sol = W_d.get()\n",
    "    obj = model.obj()\n",
    "    return w0_d_sol,W_d_sol,obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(x_train, z_train, W, w0):\n",
    "    #W and w0 can be a tuplelist or an array\n",
    "#     x_train = data[3]\n",
    "#     z_train = data[5]\n",
    "    N,p = x_train.shape\n",
    "    N,d = z_train.shape\n",
    "    a = []\n",
    "    for n in range(N):\n",
    "        for i in range(d):\n",
    "            temp = []\n",
    "            for j in range(p):\n",
    "                temp.append(x_train[n][j]*W[i,j])\n",
    "            a.append((z_train[n][i] - sum(temp) - w0[i])*(z_train[n][i] - sum(temp) - w0[i]))      \n",
    "    return np.sum(a)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddr_solver(x_train, z_train, thres, mu, lamb, yconstraint = 0, A = 0, b = 0, yB = 0, B = 0):\n",
    "#     x_train = data[3]\n",
    "    z_train_min = np.minimum(z_train,thres) \n",
    "    N,p = x_train.shape\n",
    "    N,d = z_train.shape\n",
    "\n",
    "    # DDR\n",
    "    m = Model(\"ddr\")\n",
    "    #m.setParam(\"DualReductions\",0)\n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    W_ind = tuplelist( [(i,j) for i in range(d) for j in range(p)] )\n",
    "    w0_ind = tuplelist( [i for i in range(d)] )\n",
    "    t_ind = tuplelist( [n for n in range(N)] )\n",
    "    \n",
    "    W_ddr = m.addVars( W_ind, lb=-GRB.INFINITY )\n",
    "    w0_ddr = m.addVars( w0_ind, lb=-GRB.INFINITY )\n",
    "    t_ddr = m.addVars( t_ind, lb=-GRB.INFINITY )\n",
    "    \n",
    "    if yconstraint == 0:\n",
    "        m.setObjective( Loss(x_train, z_train, W_ddr, w0_ddr) + lamb*(quicksum([t_ddr[n]  for n in range(N)])/ N) , GRB.MINIMIZE)\n",
    "\n",
    "        if yB == 0:\n",
    "            m.addConstrs( (- mu*z_train[n,i] - (1- mu)*(quicksum(x_train[n][j]*W_ddr[i,j] for j in range(p)) + w0_ddr[i])-\\\n",
    "                        t_ddr[n] <= 0 for n in range(N) for i in range(d)) )\n",
    "\n",
    "            # m.addConstrs( (-mu*z_train[n,i] -(1- mu)*thres - t_ddr[n] <= 0 for n in range(N) for i in range(d)) )\n",
    "        else:\n",
    "            d,h = B.shape\n",
    "            m.addConstrs( (- mu*quicksum(B[i,k]*z_train_min[n,k] for k in range(h)) \\\n",
    "                        - (1- mu)*(quicksum(B[i,k]*(quicksum(x_train[n][j]*W_ddr[k,j] for j in range(p)) + w0_ddr[k]) \\\n",
    "                                            for k in range(h))) - t_ddr[n] <= 0 for n in range(N) for i in range(d)) )\n",
    "\n",
    "            m.addConstrs( (-mu*quicksum(B[i,k]*z_train_min[n,k] for k in range(h)) \\\n",
    "                        -(1- mu)*thres*quicksum(B[i,k] for k in range(h)) - t_ddr[n] <= 0 for n in range(N) for i in range(d)) )\n",
    "    else:\n",
    "        a,d = A.shape\n",
    "        beta_ind = tuplelist( [(n,k) for n in range(N) for k in range(a)] )\n",
    "        beta_ddr = m.addVars( beta_ind, lb= 0 )\n",
    "        \n",
    "        m.setObjective( Loss(x_train, z_train, W_ddr, w0_ddr) +\\\n",
    "                    lamb*(quicksum([t_ddr[n] + quicksum(beta_ddr[n,k]*b[k] for k in range(a))  for n in range(N)])/ N), GRB.MINIMIZE)\n",
    "\n",
    "\n",
    "        m.addConstrs( (- mu*z_train_min[n,i] - (1- mu)*(quicksum(x_train[n][j]*W_ddr[i,j] for j in range(p)) + w0_ddr[i])-\\\n",
    "                    t_ddr[n] - quicksum(A[k,i]*beta_ddr[n,k] for k in range(a)) <= 0 for n in range(N) for i in range(d)) )\n",
    "\n",
    "        m.addConstrs( (-mu*z_train_min[n,i] -(1- mu)*thres - t_ddr[n] - quicksum(A[k,i]*beta_ddr[n,k] for k in range(a)) <= 0 for n in range(N) for i in range(d)) )\n",
    "\n",
    "    m.optimize()\n",
    "\n",
    "    W = m.getAttr('x', W_ddr)\n",
    "    w0 = m.getAttr('x', w0_ddr)\n",
    "    t = m.getAttr('x', t_ddr)\n",
    "    W_results = []\n",
    "    for i in range(d):\n",
    "        W_results.append([W[(i,j)] for j in range(p)])\n",
    "    w0_results = [w0[i] for i in range(d)]\n",
    "#     t_results = [t[n] for n in range(N)]\n",
    "    return W_results, w0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter =  0 ,cost_ddr_avg_tem\n",
      "[[0.9998 0.9997 0.9997 0.9997 0.9996 0.9997 0.9996 0.9997 0.9997 0.9997]\n",
      " [0.9998 0.9997 0.9997 0.9997 0.9996 0.9996 0.9996 0.9996 0.9996 0.9996]\n",
      " [1.     0.9997 0.9998 0.9998 0.9998 0.9998 0.9997 0.9996 0.9996 0.9996]\n",
      " [1.     0.9999 0.9998 0.9999 0.9998 0.9998 0.9998 0.9996 0.9996 0.9996]\n",
      " [1.     0.9999 0.9999 0.9999 0.9998 0.9998 0.9997 0.9996 0.9996 0.9996]\n",
      " [1.     1.     0.9999 0.9998 0.9998 0.9998 0.9998 0.9997 0.9996 0.9996]\n",
      " [1.     1.     0.9999 0.9999 0.9999 0.9998 0.9998 0.9998 0.9996 0.9996]\n",
      " [1.0001 1.0001 0.9999 0.9999 0.9999 0.9998 0.9999 0.9999 0.9998 0.9997]\n",
      " [1.0001 1.0001 1.     0.9999 0.9999 0.9999 0.9999 0.9999 0.9999 0.9997]\n",
      " [1.     1.0001 1.0001 0.9999 0.9999 0.9998 0.9999 0.9998 1.     0.9998]]\n",
      "iter =  1 ,cost_ddr_avg_tem\n",
      "[[0.9997 0.9996 0.9997 0.9996 0.9996 0.9996 0.9995 0.9996 0.9996 0.9996]\n",
      " [0.9997 0.9997 0.9997 0.9996 0.9996 0.9996 0.9995 0.9996 0.9996 0.9996]\n",
      " [0.9998 0.9998 0.9999 0.9998 0.9998 0.9998 0.9998 0.9999 0.9998 0.9999]\n",
      " [0.9998 0.9998 0.9999 0.9999 0.9998 0.9998 0.9998 0.9999 0.9998 0.9999]\n",
      " [0.9998 0.9998 0.9998 0.9999 0.9999 0.9998 0.9998 0.9998 0.9999 0.9998]\n",
      " [0.9998 0.9998 0.9999 0.9999 0.9998 0.9998 0.9998 0.9998 0.9999 0.9998]\n",
      " [0.9997 0.9997 0.9998 0.9997 0.9997 0.9997 0.9997 0.9998 0.9998 0.9998]\n",
      " [0.9996 0.9996 0.9995 0.9996 0.9995 0.9996 0.9997 0.9997 0.9997 0.9997]\n",
      " [0.9997 0.9997 0.9996 0.9997 0.9996 0.9996 0.9996 0.9997 0.9997 0.9996]\n",
      " [0.9997 0.9997 0.9996 0.9996 0.9996 0.9996 0.9996 0.9997 0.9997 0.9996]]\n",
      "iter =  2 ,cost_ddr_avg_tem\n",
      "[[1.     0.9999 0.9999 0.9998 0.9998 0.9998 0.9997 0.9997 0.9997 0.9997]\n",
      " [1.     1.     0.9999 0.9998 0.9998 0.9997 0.9998 0.9997 0.9997 0.9997]\n",
      " [1.     0.9999 1.     0.9999 0.9999 0.9996 0.9997 0.9997 0.9997 0.9997]\n",
      " [1.0001 1.     0.9999 0.9999 0.9998 0.9998 0.9998 0.9998 0.9997 0.9997]\n",
      " [1.     0.9999 0.9999 0.9999 0.9999 0.9999 0.9999 0.9999 0.9999 1.    ]\n",
      " [1.0001 1.0001 1.0001 1.0001 1.     1.     1.     1.     1.     1.    ]\n",
      " [1.0002 1.0002 1.0002 1.0001 1.0002 1.0001 1.0001 1.     0.9999 0.9999]\n",
      " [1.0002 1.0002 1.0002 1.0002 1.0001 1.0001 1.0001 1.     1.     0.9999]\n",
      " [1.0001 1.0002 1.0001 1.0001 1.0001 1.0002 1.0002 1.0002 1.0001 1.    ]\n",
      " [1.0001 1.0001 1.0001 1.0001 1.0001 1.0001 1.0001 1.0002 1.0001 1.0001]]\n",
      "iter =  3 ,cost_ddr_avg_tem\n",
      "[[0.9996 0.9994 0.9994 0.9993 0.9992 0.9992 0.9993 0.9992 0.9991 0.9991]\n",
      " [0.9995 0.9995 0.9994 0.9994 0.9992 0.9992 0.9993 0.9993 0.9992 0.9992]\n",
      " [0.9995 0.9996 0.9995 0.9994 0.9994 0.9993 0.9993 0.9993 0.9992 0.9992]\n",
      " [0.9995 0.9995 0.9995 0.9994 0.9994 0.9993 0.9993 0.9993 0.9992 0.9992]\n",
      " [0.9995 0.9995 0.9995 0.9994 0.9994 0.9994 0.9994 0.9993 0.9993 0.9993]\n",
      " [0.9995 0.9994 0.9994 0.9994 0.9994 0.9994 0.9994 0.9993 0.9992 0.9992]\n",
      " [0.9995 0.9994 0.9995 0.9994 0.9994 0.9993 0.9993 0.9992 0.9992 0.9991]\n",
      " [0.9995 0.9995 0.9994 0.9994 0.9993 0.9993 0.9991 0.9992 0.9992 0.9992]\n",
      " [0.9994 0.9994 0.9993 0.9993 0.9992 0.9992 0.9992 0.9993 0.9992 0.9992]\n",
      " [0.9995 0.9994 0.9994 0.9994 0.9993 0.9993 0.9994 0.9993 0.9993 0.9993]]\n",
      "iter =  4 ,cost_ddr_avg_tem\n",
      "[[0.9996 0.9997 0.9997 0.9998 0.9999 0.9999 0.9998 0.9997 0.9998 0.9998]\n",
      " [0.9997 0.9996 0.9997 0.9997 0.9997 0.9998 0.9998 0.9997 0.9997 0.9997]\n",
      " [0.9996 0.9996 0.9997 0.9996 0.9996 0.9997 0.9997 0.9997 0.9996 0.9996]\n",
      " [0.9996 0.9996 0.9997 0.9997 0.9998 0.9998 0.9999 0.9998 0.9997 0.9997]\n",
      " [0.9997 0.9997 0.9996 0.9997 0.9997 0.9999 0.9999 0.9998 0.9998 0.9997]\n",
      " [0.9996 0.9996 0.9996 0.9997 0.9998 0.9998 0.9998 0.9998 0.9997 0.9997]\n",
      " [0.9995 0.9995 0.9995 0.9995 0.9996 0.9997 0.9996 0.9996 0.9995 0.9995]\n",
      " [0.9995 0.9993 0.9992 0.9993 0.9994 0.9994 0.9995 0.9995 0.9995 0.9996]\n",
      " [0.9994 0.9993 0.9992 0.9994 0.9994 0.9994 0.9994 0.9995 0.9995 0.9995]\n",
      " [0.9994 0.9993 0.9993 0.9993 0.9993 0.9994 0.9994 0.9995 0.9995 0.9995]]\n",
      "iter =  5 ,cost_ddr_avg_tem\n",
      "[[1.     1.     1.     1.0001 1.     1.     1.0001 1.0001 1.0001 1.0001]\n",
      " [1.     1.0001 1.0001 1.0002 1.0002 1.0002 1.0002 1.0001 1.     1.    ]\n",
      " [1.0001 1.0002 1.0002 1.0002 1.0001 1.0001 1.0001 1.0001 1.     1.0001]\n",
      " [1.0001 1.0001 1.     1.0001 1.0001 1.0001 1.0002 1.0001 1.0001 1.0001]\n",
      " [1.0002 1.0001 1.0001 1.0001 1.0001 1.0001 1.0001 1.0001 1.0001 1.0002]\n",
      " [1.0002 1.0001 1.0002 1.0001 1.0001 1.0001 1.0001 1.0001 1.0002 1.    ]\n",
      " [1.0001 1.0001 1.0001 1.0001 1.0002 1.0002 1.0001 1.0001 1.0001 1.0001]\n",
      " [1.0001 1.0002 1.0001 1.0001 1.0001 1.0002 1.0002 1.0002 1.0001 1.    ]\n",
      " [1.0001 1.0001 1.0001 1.0001 1.0002 1.0001 1.0002 1.0002 1.0002 1.0001]\n",
      " [1.     1.0001 1.0001 1.0001 1.0002 1.0002 1.0002 1.0002 1.0002 1.0002]]\n",
      "iter =  6 ,cost_ddr_avg_tem\n",
      "[[0.9989 0.9989 0.9989 0.9988 0.9988 0.9987 0.9987 0.9986 0.9985 0.9984]\n",
      " [0.9991 0.999  0.9991 0.999  0.9989 0.9987 0.9987 0.9987 0.9986 0.9988]\n",
      " [0.9992 0.9991 0.9991 0.9991 0.999  0.9988 0.9988 0.9987 0.9986 0.9987]\n",
      " [0.9992 0.9991 0.9991 0.9991 0.999  0.9989 0.9988 0.9986 0.9986 0.9986]\n",
      " [0.9992 0.9992 0.9991 0.999  0.9991 0.999  0.9989 0.9988 0.9987 0.9988]\n",
      " [0.9993 0.9993 0.9992 0.9991 0.9991 0.999  0.999  0.9989 0.9988 0.9988]\n",
      " [0.9994 0.9994 0.9993 0.9993 0.9994 0.9994 0.9993 0.9992 0.9991 0.9991]\n",
      " [0.9994 0.9994 0.9993 0.9993 0.9993 0.9993 0.9992 0.9991 0.9991 0.9991]\n",
      " [0.9995 0.9995 0.9994 0.9994 0.9993 0.9993 0.9992 0.9992 0.9991 0.999 ]\n",
      " [0.9993 0.9993 0.9993 0.9993 0.9992 0.9993 0.9993 0.9992 0.9991 0.9991]]\n",
      "iter =  7 ,cost_ddr_avg_tem\n",
      "[[1.0007 1.0006 1.0006 1.0007 1.0007 1.0006 1.0006 1.0005 1.0006 1.0007]\n",
      " [1.0006 1.0006 1.0006 1.0006 1.0008 1.0006 1.0006 1.0006 1.0006 1.0007]\n",
      " [1.0007 1.0006 1.0006 1.0007 1.0008 1.0008 1.0007 1.0007 1.0006 1.0006]\n",
      " [1.0007 1.0006 1.0006 1.0007 1.0007 1.0006 1.0007 1.0006 1.0006 1.0006]\n",
      " [1.0007 1.0007 1.0006 1.0005 1.0007 1.0007 1.0007 1.0007 1.0007 1.0006]\n",
      " [1.0005 1.0005 1.0004 1.0005 1.0006 1.0006 1.0006 1.0005 1.0005 1.0005]\n",
      " [1.0005 1.0004 1.0005 1.0005 1.0006 1.0005 1.0005 1.0004 1.0004 1.0004]\n",
      " [1.0003 1.0003 1.0003 1.0004 1.0005 1.0005 1.0005 1.0005 1.0005 1.0005]\n",
      " [1.0004 1.0003 1.0002 1.0004 1.0004 1.0005 1.0006 1.0005 1.0005 1.0005]\n",
      " [1.0004 1.0003 1.0002 1.0004 1.0003 1.0005 1.0005 1.0005 1.0005 1.0005]]\n",
      "iter =  8 ,cost_ddr_avg_tem\n",
      "[[0.9998 0.9998 0.9998 0.9998 0.9997 0.9997 0.9995 0.9995 0.9994 0.9994]\n",
      " [0.9998 0.9999 0.9998 0.9998 0.9997 0.9997 0.9996 0.9996 0.9995 0.9994]\n",
      " [0.9998 0.9998 0.9999 0.9998 0.9997 0.9997 0.9997 0.9996 0.9995 0.9994]\n",
      " [0.9998 0.9998 0.9999 0.9998 0.9998 0.9997 0.9997 0.9996 0.9996 0.9996]\n",
      " [0.9999 0.9999 0.9999 0.9999 0.9998 0.9997 0.9998 0.9997 0.9997 0.9996]\n",
      " [0.9999 0.9999 0.9998 0.9999 0.9999 0.9998 0.9999 0.9998 0.9998 0.9996]\n",
      " [0.9999 0.9999 0.9999 0.9998 0.9999 0.9999 0.9999 0.9999 0.9998 0.9997]\n",
      " [0.9999 0.9999 0.9999 0.9998 0.9998 0.9999 0.9998 0.9999 0.9998 0.9998]\n",
      " [0.9999 0.9999 0.9999 0.9998 0.9999 0.9998 0.9999 0.9999 0.9999 0.9998]\n",
      " [0.9999 0.9999 0.9999 0.9998 0.9999 0.9998 0.9999 0.9999 0.9999 0.9997]]\n",
      "iter =  9 ,cost_ddr_avg_tem\n",
      "[[0.9997 0.9997 0.9997 0.9997 0.9996 0.9994 0.9995 0.9995 0.9994 0.9994]\n",
      " [0.9998 0.9997 0.9996 0.9997 0.9996 0.9995 0.9994 0.9995 0.9995 0.9995]\n",
      " [0.9997 0.9997 0.9997 0.9997 0.9997 0.9995 0.9995 0.9995 0.9995 0.9996]\n",
      " [0.9997 0.9998 0.9997 0.9997 0.9998 0.9996 0.9995 0.9996 0.9996 0.9996]\n",
      " [0.9997 0.9998 0.9998 0.9997 0.9998 0.9996 0.9995 0.9995 0.9995 0.9996]\n",
      " [0.9997 0.9998 0.9998 0.9997 0.9998 0.9996 0.9995 0.9995 0.9995 0.9996]\n",
      " [0.9997 0.9997 0.9998 0.9997 0.9997 0.9997 0.9996 0.9996 0.9996 0.9996]\n",
      " [0.9998 0.9997 0.9998 0.9998 0.9998 0.9999 0.9996 0.9995 0.9996 0.9996]\n",
      " [0.9998 0.9997 0.9998 0.9998 0.9998 0.9999 0.9997 0.9996 0.9996 0.9997]\n",
      " [0.9997 0.9997 0.9998 0.9998 0.9998 0.9998 0.9998 0.9996 0.9996 0.9996]]\n"
     ]
    }
   ],
   "source": [
    "mu_all = np.arange(0.2,0.3,0.01)\n",
    "lamb_all = np.round(np.arange(0.2,0.3,0.01),4)\n",
    "\n",
    "W_ddr_all = {}; w0_ddr_all = {}; obj_ddr_all = {}\n",
    "cost_DDR_all = {}; cost_DDR_avg_all = {}\n",
    "for iter in iteration_all:\n",
    "    c_input = c_train_all[iter]\n",
    "    x_input = x_train_all[iter]\n",
    "    \n",
    "    cost_ddr_avg_tem = np.zeros((len(mu_all),len(lamb_all)))\n",
    "    for mu_index in range(len(mu_all)):\n",
    "        mu = mu_all[mu_index]\n",
    "        for lamb_index in range(len(lamb_all)):\n",
    "            lamb = lamb_all[lamb_index]\n",
    "            # print(\"iter = \",iter,\",mu = \",mu,\",lamb=\",lamb)\n",
    "            # w0_ddr_all[iter,mu,lamb],W_ddr_all[iter,mu,lamb],obj_ddr_all[iter,mu,lamb] = solve_DDR(mu,lamb,d,num_feat,num_train,c_input,x_input)\n",
    "            W_ddr_all[iter,mu,lamb], w0_ddr_all[iter,mu,lamb] = ddr_solver(x_input, c_input, num_test, mu, lamb)\n",
    "            cost_DDR_all[iter,mu,lamb] = compute_out_of_sample_cost(W_ddr_all[iter,mu,lamb],w0_ddr_all[iter,mu,lamb],c_test_all[iter],x_test_all[iter])\n",
    "            cost_ddr_avg_tem[mu_index,lamb_index] = np.nanmean(cost_DDR_all[iter,mu,lamb])\n",
    "    print(\"iter = \",iter,\",cost_ddr_avg_tem\")\n",
    "    print(np.round(cost_ddr_avg_tem/cost_OLS_avg[iter],4))\n",
    "    cost_DDR_avg_all[iter] = cost_ddr_avg_tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_DDR_vs_OLS_avg = np.zeros((len(mu_all),len(lamb_all)))\n",
    "for iter in iteration_all:\n",
    "    regret_DDR_vs_OLS_avg = regret_DDR_vs_OLS_avg + (cost_OLS_avg[iter] - cost_DDR_avg_all[iter])/(cost_OLS_avg[iter] - cost_Oracle_avg[iter])\n",
    "regret_DDR_vs_OLS_avg = regret_DDR_vs_OLS_avg/len(iteration_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regret_DDR_vs_OLS_avg=\n",
      "[[1.9214 2.6017 2.7393 2.5311 3.1318 3.4522 3.6545 3.6208 3.8888 3.9261]\n",
      " [1.7546 1.9402 2.293  2.2591 2.5726 3.1191 3.4287 3.392  3.8534 3.6412]\n",
      " [1.2092 1.2817 1.2817 1.3925 1.8033 2.3948 2.7436 2.8342 3.648  3.496 ]\n",
      " [1.363  1.0771 1.587  1.5122 1.6037 1.957  1.9844 2.7692 3.0173 3.0406]\n",
      " [0.9143 0.9943 1.3427 1.406  1.2567 1.4919 1.8498 2.2859 2.3749 2.2451]\n",
      " [1.09   1.1472 1.1172 1.3042 1.6164 1.567  1.7244 2.3214 2.308  2.8732]\n",
      " [1.2276 1.4435 1.3794 1.8188 1.4538 1.551  1.9442 2.339  2.9124 3.3034]\n",
      " [1.5904 1.5736 2.3322 2.1648 2.2542 1.9647 2.1069 2.0361 2.7468 3.2062]\n",
      " [1.7549 1.7147 2.2847 2.189  2.1464 2.1448 1.8874 1.7176 2.0176 2.856 ]\n",
      " [2.0154 1.8368 2.0784 2.2892 2.3283 2.1936 1.7065 1.6561 1.8699 2.4386]]\n"
     ]
    }
   ],
   "source": [
    "print(\"regret_DDR_vs_OLS_avg=\")\n",
    "print(np.round(regret_DDR_vs_OLS_avg*100,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
