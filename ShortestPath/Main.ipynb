{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generation_process = \"SPO_Data_Generation\"\n",
    "data_generation_process = \"DDR_Data_Generation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyepo\n",
    "# generate data\n",
    "grid = (5,5) # grid size\n",
    "num_train = 100 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "num_test = 10000\n",
    "deg = 8.0 # polynomial degree\n",
    "e = 10 # scale of normal std or the range of uniform. For the error term\n",
    "\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "p = 5 # num of features\n",
    "d = 40 # num of arcs\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "mis = deg # model misspecification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "grandparent_directory = os.path.dirname(parent_directory)\n",
    "DataPath = os.path.dirname(grandparent_directory) + '/Data_0317/' + data_generation_process + \"/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "print(\"grandparent_directory:\", grandparent_directory)\n",
    "print(\"DataPath:\", DataPath)\n",
    "\n",
    "DataPath = DataPath + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data(DataPath,lower, upper, p, d, coef_seed,seed_all,num_test, num_train, alpha,mis,data_generation_process):\n",
    "# #  ****** Coef generation *********\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,version = 0) \n",
    "\n",
    "    for seed in seed_all:\n",
    "        DataPath_seed = DataPath +\"Seed=\"+str(seed)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        # #  ****** Data generation *********\n",
    "        x_test, c_test, x_train, c_train, W_star = data_gen.generate_samples(seed,DataPath_seed,p, d, num_test, num_train, alpha, W_star, mis, thres = 10, \n",
    "                                version = data_generation_process, x_dist = 'normal', e_dist = 'normal', x_low = 0, x_up = 2, x_mean = 2, x_var = 0.25, bump = 0) \n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data_with_Diff_W(DataPath,lower, upper, p, d, coef_seed,seed_all,num_test, num_train, alpha,mis,data_generation_process):\n",
    "# #  ****** Coef generation *********\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    for seed in seed_all:\n",
    "        DataPath_seed = DataPath +\"Seed=\"+str(seed)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        # #  ****** Data generation *********\n",
    "        # print(\"W_star = \",W_star[0,:])\n",
    "        W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, seed,version = 0) \n",
    "        x_test, c_test, x_train, c_train, W_star = data_gen.generate_samples(seed,DataPath_seed,p, d, num_test, num_train, alpha, W_star, mis, thres = 10, \n",
    "                                version = data_generation_process, x_dist = 'normal', e_dist = 'normal', x_low = 0, x_up = 2, x_mean = 2, x_var = 0.25, bump = 0) \n",
    "        # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_Oracle(DataPath,seed_all,arcs, grid):\n",
    "    cost_Oracle_all = {}\n",
    "    for seed in seed_all:\n",
    "        DataPath_seed = DataPath +\"Seed=\"+str(seed)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        with open(DataPath_seed+'Data.pkl', \"rb\") as tf:\n",
    "            Data = pickle.load(tf)\n",
    "        c_test = Data[\"c_test\"]\n",
    "        from Peformance import performance_evaluation\n",
    "        perfs = performance_evaluation()\n",
    "        cost_Oracle_all[seed] = perfs.compute_Oracel_Cost(arcs, grid,c_test)\n",
    "        print(\"*** seed = \",seed,\" Average Oracle Cost = \",np.mean(cost_Oracle_all[seed]))\n",
    "        with open(DataPath_seed +'rst_Oracle.pkl', \"wb\") as tf:\n",
    "            pickle.dump(cost_Oracle_all[seed],tf)\n",
    "    return cost_Oracle_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPO approaches, including SPO+,PG,LTR and ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_EPO(DataPath,seed_all,batch_size,num_epochs,method_names):\n",
    "    cost_EPO = {}\n",
    "    from PYEPO import PyEPO_Method\n",
    "    epo_runner = PyEPO_Method()\n",
    "    # batch_size = 20\n",
    "    # num_epochs = 30\n",
    "    for seed in seed_all:\n",
    "        DataPath_seed = DataPath +\"Seed=\"+str(seed)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"*** seed = \",seed,\": Run EPO ******\")\n",
    "        cost_EPO[seed] = epo_runner.run(method_names,DataPath_seed,batch_size,num_feat,grid,num_epochs)\n",
    "    return cost_EPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_OLS(DataPath,seed_all,arcs,grid):\n",
    "    cost_OLS_all = {}\n",
    "    for seed in seed_all:\n",
    "        DataPath_seed = DataPath +\"Seed=\"+str(seed)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        from OLS import run_OLS_Shortest_Path\n",
    "        OLS_runner = run_OLS_Shortest_Path()\n",
    "        cost_OLS_all[seed] = OLS_runner.run(DataPath_seed,arcs,grid)\n",
    "        print(\"*** seed = \",seed,\" Average OLS Cost = \",np.mean(cost_OLS_all[seed]))\n",
    "    return cost_OLS_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_DDR(DataPath,seed_all,mu_arr,lamb_arr,arcs, grid):\n",
    "    from DDR import run_DDR_Shortest_Path\n",
    "    DDR_runner = run_DDR_Shortest_Path()\n",
    "    # mu_arr = np.arange(0.025,1.0,0.05)\n",
    "    # lamb_arr = np.arange(0.75,1.251,0.125)\n",
    "    cost_DDR_all = {}\n",
    "    for seed in seed_all:\n",
    "        DataPath_seed = DataPath +\"Seed=\"+str(seed)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"*** seed = \",seed,\": Run DDR ========\")\n",
    "        cost_DDR_all[seed] = DDR_runner.run(DataPath_seed,lamb_arr,mu_arr,arcs, grid,num_nodes=25)\n",
    "    return cost_DDR_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPO_Plus import shortestPathModel\n",
    "SPM = shortestPathModel()\n",
    "arcs = SPM._getArcs()\n",
    "\n",
    "# Data\n",
    "coef_seed = 2\n",
    "seed_all = np.arange(1,20)\n",
    "Prepare_Data(DataPath,lower, upper, p, d, coef_seed,seed_all,num_test, num_train, alpha,mis,data_generation_process)\n",
    "\n",
    "# Oracle\n",
    "cost_Oracle_all = Implement_Oracle(DataPath,seed_all,arcs, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EPO, including SPO, PG, LTR\n",
    "# batch_size = 20\n",
    "# num_epochs = 30\n",
    "# method_names = [\"spo+\",\"pg\",\"ltr\"]\n",
    "# cost_EPO_all = Implement_EPO(DataPath,seed_all,batch_size,num_epochs,method_names)\n",
    "\n",
    "# OLS\n",
    "cost_OLS_all = Implement_OLS(DataPath,seed_all,arcs,grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDR\n",
    "# mu_arr = -np.arange(0.025,1.0,0.05)\n",
    "mu_arr = np.arange(0.7,1.01,0.05)\n",
    "lamb_arr = np.arange(0.75,1.251,0.125)\n",
    "lamb_arr = [1.0]\n",
    "cost_DDR_all = Implement_DDR(DataPath,seed_all,mu_arr,lamb_arr,arcs, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_OLS_avg = 0; cost_SPO_avg = 0; cost_Oracle_avg = 0; cost_DDR_avg = np.zeros((len(lamb_arr),len(mu_arr)))\n",
    "for seed in seed_all:\n",
    "    cost_ddr_opt = 10000\n",
    "    lamb_opt = 0\n",
    "    mu_opt = 0\n",
    "    ddr_ols_ratio = 0\n",
    "\n",
    "    cost_Oracle_avg = cost_Oracle_avg + np.mean(cost_Oracle_all[seed])\n",
    "    cost_OLS_avg = cost_OLS_avg + np.mean(cost_OLS_all[seed])\n",
    "    # cost_SPO_avg = cost_SPO_avg + np.mean(cost_EPO_all[seed][\"SPO\"]) \n",
    "    lamb_index = 0\n",
    "    for lamb in lamb_arr:\n",
    "        mu_index = 0\n",
    "        for mu in mu_arr:\n",
    "            # print(\"Seed = \",seed,\", lamb_opt = \",lamb,\",mu_opt = \",mu,\", Average DRR Cost = \", np.round(np.mean(cost_DDR_all[seed][lamb,mu][\"cost\"]),4))\n",
    "            if np.mean(cost_DDR_all[seed][lamb,mu][\"cost\"]) < cost_ddr_opt:\n",
    "                cost_ddr_opt = np.mean(cost_DDR_all[seed][lamb,mu][\"cost\"])\n",
    "                lamb_opt = lamb\n",
    "                mu_opt = mu\n",
    "                ddr_ols_ratio = (np.mean(cost_OLS_all[seed]) - cost_ddr_opt)/(np.mean(cost_OLS_all[seed]) - np.mean(cost_Oracle_all[seed]))\n",
    "                # ddr_spo_ratio = ((np.mean(cost_EPO_all[seed][\"SPO\"])) - cost_ddr_opt)/(np.mean(cost_EPO_all[seed][\"SPO\"]) - np.mean(cost_Oracle_all[seed]))\n",
    "            cost_DDR_avg[lamb_index,mu_index] = cost_DDR_avg[lamb_index,mu_index] + np.mean(cost_DDR_all[seed][lamb,mu][\"cost\"])\n",
    "            mu_index = mu_index + 1\n",
    "        lamb_index = lamb_index + 1\n",
    "    print(\"Seed = \",seed,\", lamb_opt = \",lamb_opt,\",mu_opt = \",mu_opt, \\\n",
    "          \",DDR_OLS_ratio = \",np.round(ddr_ols_ratio,4),\\\n",
    "            # \",DDR_SPO_ratio = \",np.round(ddr_spo_ratio,4)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_OLS_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(8, 6))\n",
    "# ax.plot(mu_arr,np.ones(len(mu_arr))*cost_Oracle_avg/len(seed_all),'-',color = 'k',label=\"Oracle\")\n",
    "ax.plot(mu_arr,np.ones(len(mu_arr))*cost_OLS_avg/len(seed_all),'-',color = 'r',label=\"OLS\")\n",
    "# ax.plot(mu_arr,np.ones(len(mu_arr))*cost_SPO_avg/len(seed_all),'-',color = 'b',label=\"SPO+\")\n",
    "\n",
    "lamb_index = 0\n",
    "for lamb in lamb_arr:\n",
    "    name = r\"DDR:$\\lambda$=\"+str(lamb)\n",
    "    ax.plot(mu_arr,cost_DDR_avg[lamb_index,:]/len(seed_all),'-.',label=name)\n",
    "    lamb_index = lamb_index + 1\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((cost_OLS_avg - cost_Oracle_avg)/len(seed_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.008/((cost_OLS_avg - cost_Oracle_avg)/len(seed_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_compare2plus(c_item, c_base, c_oracle):\n",
    "#     c_item = np.asarray(c_item)\n",
    "#     c_base = np.asarray(c_base)\n",
    "#     c_oracle = np.asarray(c_oracle)\n",
    "\n",
    "#     N = len(c_item)\n",
    "#     c_diff = c_item - c_base\n",
    "#     lbel = np.zeros((N,1))\n",
    "    \n",
    "#     equals = np.sum(c_diff == 0)\n",
    "#     wins = np.sum(c_diff < 0)\n",
    "#     lose = np.sum(c_diff > 0)\n",
    "    \n",
    "#     lbel[c_diff < 0] = 1\n",
    "#     lbel[c_diff > 0] = -1\n",
    "    \n",
    "#     print(N, equals, wins, lose)\n",
    "#     print(\"base cost = \", np.mean(c_base),\",item cost = \",np.mean(c_item))\n",
    "#     if N == equals:\n",
    "#         win_ratio = 0.5\n",
    "#     else:\n",
    "#         win_ratio = wins/(N - equals)\n",
    "#     cost_reduction = (np.mean(c_base) - np.mean(c_item) )/np.abs(np.mean(c_oracle))\n",
    "#     regret_reduction = (np.mean(c_base) - np.mean(c_item))/np.abs(np.mean(c_base) - np.mean(c_oracle))\n",
    "#     return lbel, win_ratio, cost_reduction, regret_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 3\n",
    "# lbel, win_ratio, cost_spo_ols, regret_spo_ols = cross_compare2plus(cost_SPO_all[seed],cost_OLS_all[seed], cost_Oracle_all[seed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comparison(file_name,perf_eva,c_item, c_base, c_oracle,ypio):\n",
    "    if ypio == 0:\n",
    "#     # compares results\n",
    "        lbels, h2h, mci = perf_eva.cross_compare2(c_item, c_base, c_oracle)\n",
    "        store_results(file_name,lbels=lbels,h2h=h2h,mci=mci)\n",
    "        print(\"h2h = \",h2h)\n",
    "    else:\n",
    "        # compares results plus\n",
    "        lbels, h2h, mci, pio = perf_eva.cross_compare2plus(c_item, c_base, c_oracle)\n",
    "        store_results(file_name,lbels=lbels,h2h=h2h,mci=mci,pio=pio)\n",
    "        print(\"h2h = \",h2h,\" pio = \",pio)\n",
    "    # return lbels, h2h, mci"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
