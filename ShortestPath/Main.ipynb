{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "import random\n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyepo\n",
    "# generate data\n",
    "grid = (5,5) # grid size\n",
    "num_data = 100 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "num_test = 1000\n",
    "deg = 8 # polynomial degree\n",
    "e = 0.5 # noise width\n",
    "feats, costs = pyepo.data.shortestpath.genData(num_data+num_test, num_feat, grid, deg, e, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build optModel\n",
    "from pyepo.model.grb import optGrbModel\n",
    "\n",
    "class shortestPathModel(optGrbModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.grid = (5,5)\n",
    "        self.arcs = self._getArcs()\n",
    "        super().__init__()\n",
    "\n",
    "    def _getArcs(self):\n",
    "        \"\"\"\n",
    "        A helper method to get list of arcs for grid network\n",
    "\n",
    "        Returns:\n",
    "            list: arcs\n",
    "        \"\"\"\n",
    "        arcs = []\n",
    "        for i in range(self.grid[0]):\n",
    "            # edges on rows\n",
    "            for j in range(self.grid[1] - 1):\n",
    "                v = i * self.grid[1] + j\n",
    "                arcs.append((v, v + 1))\n",
    "            # edges in columns\n",
    "            if i == self.grid[0] - 1:\n",
    "                continue\n",
    "            for j in range(self.grid[1]):\n",
    "                v = i * self.grid[1] + j\n",
    "                arcs.append((v, v + self.grid[1]))\n",
    "        return arcs\n",
    "\n",
    "    def _getModel(self):\n",
    "        \"\"\"\n",
    "        A method to build Gurobi model\n",
    "\n",
    "        Returns:\n",
    "            tuple: optimization model and variables\n",
    "        \"\"\"\n",
    "        import gurobipy as gp\n",
    "        from gurobipy import GRB\n",
    "        # ceate a model\n",
    "        m = gp.Model(\"shortest path\")\n",
    "        # varibles\n",
    "        x = m.addVars(self.arcs, name=\"x\")\n",
    "        # sense\n",
    "        m.modelSense = GRB.MINIMIZE\n",
    "        # flow conservation constraints\n",
    "        for i in range(self.grid[0]):\n",
    "            for j in range(self.grid[1]):\n",
    "                v = i * self.grid[1] + j\n",
    "                expr = 0\n",
    "                for e in self.arcs:\n",
    "                    # flow in\n",
    "                    if v == e[1]:\n",
    "                        expr += x[e]\n",
    "                    # flow out\n",
    "                    elif v == e[0]:\n",
    "                        expr -= x[e]\n",
    "                # source\n",
    "                if i == 0 and j == 0:\n",
    "                    m.addConstr(expr == -1)\n",
    "                # sink\n",
    "                elif i == self.grid[0] - 1 and j == self.grid[0] - 1:\n",
    "                    m.addConstr(expr == 1)\n",
    "                # transition\n",
    "                else:\n",
    "                    m.addConstr(expr == 0)\n",
    "        return m, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepara training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, c_train, c_test = train_test_split(feats, costs, test_size=num_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "optmodel = shortestPathModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2047.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2105.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# get optDataset\n",
    "dataset_train = pyepo.data.dataset.optDataset(optmodel, x_train, c_train)\n",
    "dataset_test = pyepo.data.dataset.optDataset(optmodel, x_test, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loader\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 20\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_feat, (grid[0]-1)*grid[1]+(grid[1]-1)*grid[0])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyepo\n",
    "regret = pyepo.metric.regret(reg, optmodel, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPO+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# init model\n",
    "reg = LinearRegression()\n",
    "# cuda\n",
    "if torch.cuda.is_available():\n",
    "    reg = reg.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of cores: 2\n"
     ]
    }
   ],
   "source": [
    "# init SPO+ loss\n",
    "spop = pyepo.func.SPOPlus(optmodel, processes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcs_arr = optmodel.arcs\n",
    "def obtain_path(arcs_arr,sol):\n",
    "    path_arr = []\n",
    "    for arc_index in range(len(arcs_arr)):\n",
    "        if sol[arc_index] > 0:\n",
    "            path_arr.append(arcs_arr[arc_index])\n",
    "    return path_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArcs(grid):\n",
    "    arcs = []\n",
    "    for i in range(grid[0]):\n",
    "        # edges on rows\n",
    "        for j in range(grid[1] - 1):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + 1))\n",
    "        # edges in columns\n",
    "        if i == grid[0] - 1:\n",
    "            continue\n",
    "        for j in range(grid[1]):\n",
    "            v = i * grid[1] + j\n",
    "            arcs.append((v, v + grid[1]))\n",
    "    return arcs\n",
    "\n",
    "def solve_Shortest_Path(arcs,cost):\n",
    "    \"\"\"\n",
    "    A method to build Gurobi model\n",
    "\n",
    "    Returns:\n",
    "        tuple: optimization model and variables\n",
    "    \"\"\"\n",
    "    import gurobipy as gp\n",
    "    from gurobipy import GRB\n",
    "    # ceate a model\n",
    "    m = gp.Model(\"shortest path\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    # varibles\n",
    "    x = m.addVars(arcs, name=\"x\")\n",
    "    # sense\n",
    "    # m.modelSense = GRB.MINIMIZE\n",
    "    # flow conservation constraints\n",
    "    for i in range(grid[0]):\n",
    "        for j in range(grid[1]):\n",
    "            v = i * grid[1] + j\n",
    "            expr = 0\n",
    "            for e in arcs:\n",
    "                # flow in\n",
    "                if v == e[1]:\n",
    "                    expr += x[e]\n",
    "                # flow out\n",
    "                elif v == e[0]:\n",
    "                    expr -= x[e]\n",
    "            # source\n",
    "            if i == 0 and j == 0:\n",
    "                m.addConstr(expr == -1)\n",
    "            # sink\n",
    "            elif i == grid[0] - 1 and j == grid[0] - 1:\n",
    "                m.addConstr(expr == 1)\n",
    "            # transition\n",
    "            else:\n",
    "                m.addConstr(expr == 0)\n",
    "    m.setObjective( sum([cost[ind] * x[arcs_arr[ind]] for ind in range(len(arcs_arr))]) , GRB.MINIMIZE)\n",
    "    m.optimize()\n",
    "    sol = m.getAttr('x')\n",
    "    # print(\"sol = \",sol)\n",
    "    shortest_path = obtain_path(arcs_arr,sol)\n",
    "    # print(\"shortest_path = \",shortest_path)\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyepo import EPO\n",
    "def evaluation_SPO(predmodel, optmodel, dataloader):\n",
    "    \"\"\"\n",
    "    A function to evaluate model performance with normalized true regret\n",
    "\n",
    "    Args:\n",
    "        predmodel (nn): a regression neural network for cost prediction\n",
    "        optmodel (optModel): an PyEPO optimization model\n",
    "        dataloader (DataLoader): Torch dataloader from optDataSet\n",
    "\n",
    "    Returns:\n",
    "        float: true regret loss\n",
    "    \"\"\"\n",
    "    # evaluate\n",
    "    predmodel.eval()\n",
    "    loss = 0\n",
    "    optsum = 0\n",
    "    cost_pred_arr = []\n",
    "    cost_true_arr = []\n",
    "    # load data\n",
    "    for data in dataloader:\n",
    "        x, c, w, z = data\n",
    "        # cuda\n",
    "        if next(predmodel.parameters()).is_cuda:\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # predict\n",
    "        with torch.no_grad(): # no grad\n",
    "            cp = predmodel(x).to(\"cpu\").detach().numpy()\n",
    "        # print(\"cp[0] = \",cp[0])\n",
    "        # solve\n",
    "        for j in range(cp.shape[0]):\n",
    "            sol_pred = solve_Shortest_Path(arcs_arr,cp[j])\n",
    "            cost_pred = np.dot(sol_pred, c[j].to(\"cpu\").detach().numpy())\n",
    "            cost_pred_arr.append(cost_pred)\n",
    "            cost_true_arr.append(z[j].item())\n",
    "    # turn back train mode\n",
    "    predmodel.train()\n",
    "    # normalized\n",
    "    return cost_true_arr,cost_pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# set adam optimizer\n",
    "optimizer = torch.optim.Adam(reg.parameters(), lr=1e-2)\n",
    "# train mode\n",
    "reg.train()\n",
    "# init log\n",
    "cost_true_arr,cost_pred_arr = evaluation_SPO(reg, optmodel, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: Average Predict Cost =  7.136241209888456 , Average True Cost =  3.1390362380291337\n",
      "epoch =  0  Average Predict Cost =  6.379391024581886 , Average True Cost =  3.1390362380291337\n",
      "epoch =  1  Average Predict Cost =  5.4756480223350605 , Average True Cost =  3.1390362380291337\n",
      "epoch =  2  Average Predict Cost =  4.838942884278971 , Average True Cost =  3.1390362380291337\n",
      "epoch =  3  Average Predict Cost =  4.457336277460297 , Average True Cost =  3.1390362380291337\n",
      "epoch =  4  Average Predict Cost =  4.208240241712387 , Average True Cost =  3.1390362380291337\n",
      "epoch =  5  Average Predict Cost =  4.055453209710371 , Average True Cost =  3.1390362380291337\n",
      "epoch =  6  Average Predict Cost =  3.976217794608865 , Average True Cost =  3.1390362380291337\n",
      "epoch =  7  Average Predict Cost =  3.9194117392043717 , Average True Cost =  3.1390362380291337\n",
      "epoch =  8  Average Predict Cost =  3.8570133776327804 , Average True Cost =  3.1390362380291337\n",
      "epoch =  9  Average Predict Cost =  3.8062406312374497 , Average True Cost =  3.1390362380291337\n",
      "epoch =  10  Average Predict Cost =  3.7834201531779637 , Average True Cost =  3.1390362380291337\n",
      "epoch =  11  Average Predict Cost =  3.7606361961345045 , Average True Cost =  3.1390362380291337\n",
      "epoch =  12  Average Predict Cost =  3.7475363941089035 , Average True Cost =  3.1390362380291337\n",
      "epoch =  13  Average Predict Cost =  3.723145411254138 , Average True Cost =  3.1390362380291337\n",
      "epoch =  14  Average Predict Cost =  3.706209941141982 , Average True Cost =  3.1390362380291337\n",
      "epoch =  15  Average Predict Cost =  3.7077491550720754 , Average True Cost =  3.1390362380291337\n",
      "epoch =  16  Average Predict Cost =  3.7071931884055465 , Average True Cost =  3.1390362380291337\n",
      "epoch =  17  Average Predict Cost =  3.6912443042642424 , Average True Cost =  3.1390362380291337\n",
      "epoch =  18  Average Predict Cost =  3.692367561559522 , Average True Cost =  3.1390362380291337\n",
      "epoch =  19  Average Predict Cost =  3.687655528201465 , Average True Cost =  3.1390362380291337\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "# set adam optimizer\n",
    "optimizer = torch.optim.Adam(reg.parameters(), lr=1e-2)\n",
    "# train mode\n",
    "reg.train()\n",
    "# init log\n",
    "cost_true_arr,cost_pred_arr = evaluation_SPO(reg, optmodel, loader_test)\n",
    "print(\"epoch 0: Average Predict Cost = \", np.mean(cost_pred_arr),\", Average True Cost = \",np.mean(cost_true_arr))\n",
    "# init elpased time\n",
    "elapsed = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # start timing\n",
    "    tick = time.time()\n",
    "    # load data\n",
    "    for i, data in enumerate(loader_train):\n",
    "        x, c, w, z = data\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "        # forward pass\n",
    "        cp = reg(x)\n",
    "        loss = spop(cp, c, w, z)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # record time\n",
    "        tock = time.time()\n",
    "        elapsed += tock - tick\n",
    "        # log\n",
    "    cost_true_arr,cost_pred_arr = evaluation_SPO(reg, optmodel, loader_test)\n",
    "    print(\"epoch = \",epoch,\" Average Predict Cost = \", np.mean(cost_pred_arr),\", Average True Cost = \",np.mean(cost_true_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyepo import EPO\n",
    "def evaluation_OLS(w0_ols,W_ols, dataloader):\n",
    "\n",
    "    # evaluate\n",
    "    cost_pred_arr = []\n",
    "    # load data\n",
    "    for data in dataloader:\n",
    "        x, c, w, z = data\n",
    "        feature = x.numpy()\n",
    "        # print(\"Feature Shape = \",np.shape(feature)[0])\n",
    "        for j in range(np.shape(feature)[0]):\n",
    "            cost = W_ols @ feature[j,:] + w0_ols\n",
    "\n",
    "            sol_pred = solve_Shortest_Path(arcs_arr,cost)\n",
    "            cost_pred = np.dot(sol_pred, c[j].to(\"cpu\").detach().numpy())\n",
    "            cost_pred_arr.append(cost_pred)\n",
    "    # print(\"Average OLS Cost = \", np.mean(cost_pred_arr))\n",
    "    return cost_pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average OLS Cost =  3.878286223104791\n"
     ]
    }
   ],
   "source": [
    "from OLS import ols_method\n",
    "ols_method_obj = ols_method()\n",
    "W_ols, w0_ols, t_ols, obj_ols = ols_method_obj.ols_solver(\"\",x_train, c_train)\n",
    "cost_OLS_arr = evaluation_OLS(w0_ols,W_ols, loader_test)\n",
    "print(\"Average OLS Cost = \",np.mean(cost_OLS_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner problem of the shortest path problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_Inner_Problem(arcs,cost_true,cost_pred,mu,is_binary):\n",
    "    \"\"\"\n",
    "    A method to build Gurobi model\n",
    "\n",
    "    Returns:\n",
    "        tuple: optimization model and variables\n",
    "    \"\"\"\n",
    "    import gurobipy as gp\n",
    "    from gurobipy import GRB\n",
    "    # import gurobipy as grb\n",
    "    # ceate a model\n",
    "    m = gp.Model(\"shortest path\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    if is_binary:\n",
    "    # varibles\n",
    "        x = m.addVars(arcs, lb = 0,vtype=GRB.BINARY  ,name=\"x\")\n",
    "    else:\n",
    "        x = m.addVars(arcs, lb = 0,name=\"x\")\n",
    "    # sense\n",
    "    # m.modelSense = GRB.MINIMIZE\n",
    "    # flow conservation constraints\n",
    "    for i in range(grid[0]):\n",
    "        for j in range(grid[1]):\n",
    "            v = i * grid[1] + j\n",
    "            expr = 0\n",
    "            for e in arcs:\n",
    "                # flow in\n",
    "                if v == e[1]:\n",
    "                    expr += x[e]\n",
    "                # flow out\n",
    "                elif v == e[0]:\n",
    "                    expr -= x[e]\n",
    "            # source\n",
    "            if i == 0 and j == 0:\n",
    "                m.addConstr(expr == -1)\n",
    "            # sink\n",
    "            elif i == grid[0] - 1 and j == grid[0] - 1:\n",
    "                m.addConstr(expr == 1)\n",
    "            # transition\n",
    "            else:\n",
    "                m.addConstr(expr == 0)\n",
    "    m.setObjective( sum([-mu*cost_true[ind] * x[arcs_arr[ind]] - (1-mu)*cost_pred[ind] * x[arcs_arr[ind]] for ind in range(len(arcs_arr))]) , GRB.MAXIMIZE)\n",
    "    m.optimize()\n",
    "    sol = m.getAttr('x')\n",
    "    # print(\"sol = \",sol)\n",
    "    shortest_path = obtain_path(arcs_arr,sol)\n",
    "    obj = m.ObjVal\n",
    "    # print(\"shortest_path = \",shortest_path)\n",
    "    return obj,sol,shortest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dual problem of the inner problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_Inner_Problem_Dual(arcs_arr,cost_true,cost_pred,mu):\n",
    "    num_nodes = 25\n",
    "    import gurobipy as gp\n",
    "    from gurobipy import GRB\n",
    "    # import gurobipy as grb\n",
    "    # ceate a model\n",
    "    m = gp.Model(\"Maximium path\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    alpha = m.addVars(num_nodes,name=\"alpha\")\n",
    "    # sense\n",
    "    # m.modelSense = GRB.MINIMIZE\n",
    "    # flow conservation constraints\n",
    "    for ind in range(len(arcs_arr)):\n",
    "        e = arcs_arr[ind]\n",
    "        j = e[1]\n",
    "        i = e[0]\n",
    "        # print(\"j = \",j,\", i = \",i, \", e = \",e)\n",
    "        m.addConstr(alpha[j] - alpha[i] >= -mu*cost_true[ind] - (1-mu)*cost_pred[ind])\n",
    "\n",
    "    m.setObjective( alpha[num_nodes-1] - alpha[0], GRB.MINIMIZE)\n",
    "    m.optimize()\n",
    "    # # print(\"sol = \",sol)\n",
    "    obj = m.ObjVal\n",
    "    # print(\"obj = \",obj)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the equivalence between shortest path, its linear relaxation and dual problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_continous =  -2.9892711344135536\n",
      "shortest_path_con =  [(0, 1), (1, 6), (6, 7), (7, 12), (12, 17), (17, 18), (18, 19), (19, 24)]\n",
      "obj_binary =  -2.9892711344135536\n",
      "shortest_path_binary =  [(0, 1), (1, 6), (6, 7), (7, 12), (12, 17), (17, 18), (18, 19), (19, 24)]\n",
      "obj_dual =  -2.989271134413554\n"
     ]
    }
   ],
   "source": [
    "cost_true_tem = np.random.uniform(0,1,40) \n",
    "cost_pred_tem = np.random.uniform(0,1,40) \n",
    "mu_fixed = 0.4\n",
    "obj_continous,sol_continous,shortest_path_con = solve_Inner_Problem(arcs_arr,cost_true_tem,cost_pred_tem,mu_fixed,False)\n",
    "print(\"obj_continous = \",obj_continous)\n",
    "print(\"shortest_path_con = \",shortest_path_con)\n",
    "\n",
    "obj_binary,sol_binary,shortest_path_binary = solve_Inner_Problem(arcs_arr,cost_true_tem,cost_pred_tem,mu_fixed,True)\n",
    "print(\"obj_binary = \",obj_binary)\n",
    "print(\"shortest_path_binary = \",shortest_path_binary)\n",
    "\n",
    "\n",
    "obj_dual = solve_Inner_Problem_Dual(arcs_arr,cost_true_tem,cost_pred_tem,mu_fixed)\n",
    "print(\"obj_dual = \",obj_dual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of data =  100 ,num of feature =  5 , num of acrs =  40\n",
      "w0_DDR_rst =  [0.998046755687908, 0.8832275474135606, 0.7866783362596907, 0.5146931027805473, 0.7323818653474223, 1.0100768031635359, 0.955461237077251, 0.7622801550999415, 0.5728046407191613, 1.0541020143164537, 1.9169067053676396, 0.5755638268867738, 0.4439154469931597, 0.9974919880329596, 1.0837616596178246, 0.9456201807464173, 0.955881271780924, 1.0570042167311804, 1.3522492023927934, 0.5787878112395486, 1.3036749952246065, 0.4796126203548161, 0.8732293407154771, 1.861713901623303, 0.9259219797813144, 0.9414173649113472, 0.5909047820658426, 1.041936351551086, 0.593155750517096, 0.7752974394032575, 1.0036120939499136, 1.0896323892234394, 0.9835865813461081, 0.8360954465294345, 1.1129490838633338, 1.080878454116059, 0.7425630376739402, 1.395042712285413, 1.048514672205736, 1.4793445930052782]\n"
     ]
    }
   ],
   "source": [
    "N,p = x_train.shape\n",
    "N,d = c_train.shape\n",
    "print(\"Num of data = \",N, \",num of feature = \", p, \", num of acrs = \", d)\n",
    "\n",
    "lamb = 1\n",
    "mu_fixed = 0.5\n",
    "# DDR\n",
    "m = Model(\"ddr\")\n",
    "#m.setParam(\"DualReductions\",0)\n",
    "m.setParam('OutputFlag', 0)\n",
    "\n",
    "W_ind = tuplelist( [(i,j) for i in range(d) for j in range(p)] )\n",
    "w0_ind = tuplelist( [i for i in range(d)])\n",
    "\n",
    "W_ddr = m.addVars( W_ind, lb=-GRB.INFINITY,name = \"W\" )\n",
    "w0_ddr = m.addVars( w0_ind, lb=-GRB.INFINITY,name = \"W0\" )\n",
    "alpha = m.addVars(N,num_nodes,name=\"alpha\")\n",
    "expr_obj = 0\n",
    "err = []\n",
    "for n in range(N):\n",
    "    cost_true_tem = c_train[n]\n",
    "    expr_obj = expr_obj + alpha[n,num_nodes-1] - alpha[n,0]\n",
    "    for ind in range(len(arcs_arr)):\n",
    "        e = arcs_arr[ind]\n",
    "        j = e[1]\n",
    "        i = e[0]\n",
    "        cost_pred_tem = quicksum([W_ddr[ind,j] * x_train[n,j] for j in range(p)]) + w0_ddr[ind]\n",
    "        # print(\"j = \",j,\", i = \",i, \", e = \",e)\n",
    "        m.addConstr(alpha[n,j] - alpha[n,i] >= -mu_fixed*cost_true_tem[ind] - (1-mu_fixed)*cost_pred_tem)\n",
    "        err.append(cost_true_tem[ind] - cost_pred_tem)\n",
    "m.setObjective(quicksum([err[k] * err[k] for k in range(len(err))])/N + lamb*(expr_obj)/N, GRB.MINIMIZE)\n",
    "m.optimize()\n",
    "W_DDR_rst = m.getAttr('x', W_ddr)\n",
    "w0_DDR_rst = m.getAttr('x', w0_ddr)\n",
    "W_results = []\n",
    "for i in range(d):\n",
    "    W_results.append([W_DDR_rst[(i,j)] for j in range(p)])\n",
    "w0_results = [w0_DDR_rst[i] for i in range(d)]\n",
    "print(\"w0_DDR_rst = \",w0_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
