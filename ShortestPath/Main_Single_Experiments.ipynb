{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "import random\n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyepo\n",
    "# generate data\n",
    "grid = (5,5) # grid size\n",
    "num_data = 100 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "num_test = 1000\n",
    "deg = 1.5 # polynomial degree\n",
    "e = 0.5 # noise width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import data_generation\n",
    "data_gen = data_generation()\n",
    "\n",
    "#  ****** Data generation process is the same as SPO+ *********\n",
    "# feats, costs = data_gen.generate_Shortest_Path_Data(num_data+num_test, num_feat, grid, deg, e, seed=42)\n",
    "# split train test data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, c_train, c_test = train_test_split(feats, costs, test_size=num_test, random_state=42)\n",
    "\n",
    "#  ****** Data generation process is the same as DDR *********\n",
    "lower = 0\n",
    "upper = 1\n",
    "p = 5\n",
    "d = 40\n",
    "alpha = 1\n",
    "mis = 4\n",
    "n_epsilon = 1\n",
    "W_star = data_gen.generate_truth(\"\",lower, upper, p, d, version = 0) \n",
    "x_test, z_test_ori, c_test, x_train, z_train_ori, c_train, W_star = data_gen.generate_samples(\"\",p, d, num_test, num_data, alpha, W_star, n_epsilon, mis, thres = 10, \n",
    "                        version = 1, x_dist = 'normal', e_dist = 'normal', x_low = 0, x_up = 2, x_mean = 2, x_var = 0.25, bump = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPO+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run() missing 1 required positional argument: 'is_run_SPO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      4\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m----> 5\u001b[0m arcs,loader_train,loader_test,cost_Oracle,cost_SPO \u001b[38;5;241m=\u001b[39m \u001b[43mSPO_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: run() missing 1 required positional argument: 'is_run_SPO'"
     ]
    }
   ],
   "source": [
    "from SPO_Plus import run_SPO_Shortest_Path\n",
    "SPO_runner = run_SPO_Shortest_Path()\n",
    "batch_size = 20\n",
    "num_epochs = 30\n",
    "arcs,loader_train,loader_test,cost_Oracle,cost_SPO = SPO_runner.run(x_train,c_train,x_test,c_test,batch_size,num_feat,grid,num_epochs,True)\n",
    "                                                                run(DataPath_seed,x_train,c_train,x_test,c_test,batch_size,num_feat,grid,num_epochs,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average OLS Cost =  6.742132800042629\n"
     ]
    }
   ],
   "source": [
    "from OLS import run_OLS_Shortest_Path\n",
    "OLS_runner = run_OLS_Shortest_Path()\n",
    "cost_OLS = OLS_runner.run(arcs,x_train,c_train,grid,loader_test)\n",
    "print(\"Average OLS Cost = \",np.mean(cost_OLS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Oracle Cost =  5.942930629730225 Std =  1.379642731178901\n",
      "Average SPO Cost =  6.77633664688468 Std =  1.6921440034748845\n",
      "Average OLS Cost =  6.742132800042629 Std =  1.673809164608691\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Oracle Cost = \",np.mean(cost_Oracle),\"Std = \", np.std(cost_Oracle))\n",
    "print(\"Average SPO Cost = \", np.mean(cost_SPO),\"Std = \", np.std(cost_SPO))\n",
    "print(\"Average OLS Cost = \", np.mean(cost_OLS),\"Std = \", np.std(cost_OLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== lambda =  0.1 ============\n",
      "lambda =  0.1 , mu =  0.1 , Lowerst Average DDR Cost =  6.744603146925568  Std =  1.6700484263066824\n",
      "lambda =  0.1 , mu =  0.20000000000000004 , Lowerst Average DDR Cost =  6.744319741591811  Std =  1.6732742820144157\n",
      "lambda =  0.1 , mu =  0.25000000000000006 , Lowerst Average DDR Cost =  6.738677947416901  Std =  1.6724724106727604\n",
      "lambda =  0.1 , mu =  0.3500000000000001 , Lowerst Average DDR Cost =  6.7375347759723665  Std =  1.6740263761904977\n",
      "======== lambda =  0.15 ============\n",
      "======== lambda =  0.2 ============\n",
      "======== lambda =  0.25 ============\n",
      "======== lambda =  0.3 ============\n",
      "======== lambda =  0.35 ============\n",
      "======== lambda =  0.4 ============\n"
     ]
    }
   ],
   "source": [
    "from DDR import run_DDR_Shortest_Path\n",
    "DDR_runner = run_DDR_Shortest_Path()\n",
    "\n",
    "mu_arr = np.arange(0.1,1,0.05)\n",
    "lamb_arr = np.arange(0.1,1,0.05)\n",
    "lamb_arr = [0.1,0.15,0.2,0.25,0.3,0.35,0.4]\n",
    "minimum_value = 1000000000\n",
    "for lamb in lamb_arr:\n",
    "    print(\"======== lambda = \",lamb,\"============\")\n",
    "    for mu in mu_arr:\n",
    "        num_nodes = 25\n",
    "        # w0_ddr_val,W_ddr_val = solve_DDR(lamb,mu,num_nodes,x_train,c_train)\n",
    "        cost_DDR = DDR_runner.run(arcs,x_train, c_train, grid,loader_test,lamb,mu,num_nodes)\n",
    "        if np.mean(cost_DDR) < minimum_value:\n",
    "            minimum_value = np.mean(cost_DDR)\n",
    "            print(\"lambda = \",lamb, \", mu = \",mu, \", Lowest Average DDR Cost = \",minimum_value, \" Std = \",np.std(cost_DDR))\n",
    "        # print(\"lambda = \",lamb, \", mu = \",mu, \",Average DDR Cost = \",np.mean(cost_DDR), \" Std = \",np.std(cost_DDR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
