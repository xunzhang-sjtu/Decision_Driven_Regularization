{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "from gurobipy import *\n",
    "from rsome import ro\n",
    "from rsome import grb_solver as grb\n",
    "import rsome as rso\n",
    "from rsome import cpt_solver as cpt\n",
    "import pandas as pd\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "from Performance import performance_evaluation\n",
    "perfs = performance_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump):\n",
    "# #  ****** Coef generation *********\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,data_generation_process) \n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    np.random.seed(coef_seed)\n",
    "    x_test_all = {}; c_test_all = {}; x_train_all = {}; c_train_all = {}; W_star_all = {}; noise_train_all = {}; noise_test_all = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_iter = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_iter).mkdir(parents=True, exist_ok=True)\n",
    "        W_star = data_gen.generate_truth(DataPath_iter,lower, upper, p, d, iter,data_generation_process) \n",
    "        # #  ****** Data generation *********\n",
    "        x_test_all[iter], c_test_all[iter], x_train_all[iter], c_train_all[iter], noise_train_all[iter],noise_test_all[iter],W_star_all[iter] = data_gen.generate_samples(iter,DataPath_iter,p, d, num_test, num_train, alpha, W_star, mis, num_test, \n",
    "                                data_generation_process, x_dist, e_dist, x_low, x_up, x_mean, x_var, bump) \n",
    "        # print()\n",
    "    return x_test_all, c_test_all, x_train_all, c_train_all, noise_train_all,noise_test_all,W_star_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_Oracle(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,iteration_all,num_feat,data_generation_process):\n",
    "    cost_Oracle_with_noise_all = {}; cost_Oracle_wo_noise_all = {}\n",
    "    for iter in iteration_all:\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            cost_Oracle_with_noise_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "            # print(\"Oracle: iter=\",iter,\",cost_Oracle_with_noise_all=\",np.nanmean(cost_Oracle_with_noise_all[iter]))\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_Oracle_with_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter],True)\n",
    "            cost_Oracle_wo_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter],False)\n",
    "\n",
    "            # print(\"Oracle: iter=\",iter,\",cost_Oracle_with_noise_all=\",np.nanmean(cost_Oracle_with_noise_all[iter]),\",cost_Oracle_wo_noise_all=\",np.nanmean(cost_Oracle_wo_noise_all[iter]))\n",
    "    return cost_Oracle_with_noise_all,cost_Oracle_wo_noise_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_OLS(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process):\n",
    "    from OLS import ols_method\n",
    "    ols_method_obj = ols_method()\n",
    "    W_ols_all = {}; w0_ols_all = {}; t_ols_all = {}; obj_ols_all = {}\n",
    "    cost_OLS_with_noise_all = {}; cost_OLS_wo_noise_all = {}\n",
    "    for iter in iteration_all:\n",
    "        # compute OLS performance\n",
    "        W_ols_all[iter], w0_ols_all[iter], t_ols_all[iter], obj_ols_all[iter] = ols_method_obj.ols_solver(\"\",x_train_all[iter], c_train_all[iter])\n",
    "        cost_dem = (W_ols_all[iter] @ x_test_all[iter].T).T + w0_ols_all[iter]\n",
    "\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            cost_OLS_with_noise_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_OLS_with_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter],True)\n",
    "            cost_OLS_wo_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter],False)\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            print(\"OLS: iter=\",iter,\",cost_OLS_with_noise_all =\",np.nanmean(cost_OLS_with_noise_all[iter]))\n",
    "    return cost_OLS_with_noise_all,cost_OLS_wo_noise_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_DDR(mu_all,lamb_all,arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process):\n",
    "    from DDR import DDR_method\n",
    "    ddr_object = DDR_method()\n",
    "    num_nodes = grid[0] * grid[0]\n",
    "\n",
    "    w0_ddr_dict = {}; W_ddr_dict = {}\n",
    "    cost_DDR_with_noise_all = {}; cost_DDR_wo_noise_all = {}\n",
    "    for iter in iteration_all:\n",
    "        for mu in mu_all:\n",
    "            for lamb in lamb_all:\n",
    "                w0_ddr_dict[iter,mu,lamb],W_ddr_dict[iter,mu,lamb],alpha_rst,obj_ddr = ddr_object.solve_DDR(arcs,lamb,mu,num_nodes,x_train_all[iter],c_train_all[iter])\n",
    "                cost_pred = (W_ddr_dict[iter,mu,lamb] @ x_test_all[iter].T).T + w0_ddr_dict[iter,mu,lamb]\n",
    "\n",
    "                if data_generation_process == \"SPO_Data_Generation\":\n",
    "                    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "                    cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "                    cost_DDR_with_noise_all[iter,mu,lamb] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "                if data_generation_process == \"DDR_Data_Generation\":\n",
    "                    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "                    cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "                    cost_DDR_with_noise_all[iter,mu,lamb] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],True)\n",
    "                    cost_DDR_wo_noise_all[iter,mu,lamb] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],False)\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            print(\"DDR: iter=\",iter,\",mu=\",mu,\",lamb=\",lamb,\",cost_DDR_with_noise_all =\",np.nanmean(cost_DDR_with_noise_all[iter,mu,lamb]))\n",
    "\n",
    "    return cost_DDR_with_noise_all,cost_DDR_wo_noise_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grandparent_directory: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Code_MacBook\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data/Shortest_Path_Reproduce/3by3_grid_SPO_Data_Generation_exp=1/\n"
     ]
    }
   ],
   "source": [
    "grid = (3,3) # grid size\n",
    "from Network import network_design\n",
    "Network = network_design()\n",
    "arcs,arc_index_mapping = Network._getArcs(grid)\n",
    "\n",
    "num_train = 100 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "num_test = 1000\n",
    "deg = 1.0 # polynomial degree\n",
    "e = 0.5 # scale of normal std or the range of uniform. For the error term\n",
    "\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "p = num_feat # num of features\n",
    "d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "num_nodes = grid[0]*grid[0]\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "mis = deg # model misspecification\n",
    "coef_seed = 1\n",
    "\n",
    "x_dist = 'uniform'\n",
    "e_dist = 'normal'\n",
    "x_low = -2\n",
    "x_up = 2\n",
    "x_mean = 2\n",
    "x_var = 2\n",
    "bump = 100\n",
    "iteration_all = np.arange(0,100)\n",
    "mu_all = np.round(np.arange(0.1,1.0,0.1),4)\n",
    "lamb_all = np.round(np.arange(0.0,1.0,0.1),4)\n",
    "\n",
    "data_generation_process = \"SPO_Data_Generation\"\n",
    "# data_generation_process = \"DDR_Data_Generation\"\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "grandparent_directory = os.path.dirname(parent_directory)\n",
    "DataPath = os.path.dirname(grandparent_directory) + '/Data/Shortest_Path_Reproduce/'+str(grid[0])+'by'+str(grid[1])+'_grid_' + data_generation_process + \"/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "print(\"grandparent_directory:\", grandparent_directory)\n",
    "print(\"DataPath:\", DataPath)\n",
    "DataPath = DataPath + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_coef_seed=\"+str(coef_seed)+\"_diff_W/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all = Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_Oracle_with_noise_all,cost_Oracle_wo_noise_all = Implement_Oracle(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_OLS_with_noise_all,cost_OLS_wo_noise_all = Implement_OLS(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_DDR_with_noise_all,cost_DDR_wo_noise_all = Implement_DDR(mu_all,lamb_all,arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DataPath+'cost_OLS_with_noise_all.pkl', \"wb\") as tf:\n",
    "    pickle.dump(cost_OLS_with_noise_all,tf)\n",
    "with open(DataPath+'cost_Oracle_with_noise_all.pkl', \"wb\") as tf:\n",
    "    pickle.dump(cost_Oracle_with_noise_all,tf)\n",
    "with open(DataPath+'cost_DDR_with_noise_all.pkl', \"wb\") as tf:\n",
    "    pickle.dump(cost_DDR_with_noise_all,tf)\n",
    "# with open(DataPath+'cost_SPO_all.pkl', \"wb\") as tf:\n",
    "#     pickle.dump(cost_SPO_all,tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DataPath+'cost_OLS_with_noise_all.pkl', \"rb\") as tf:\n",
    "    cost_OLS_with_noise_all = pickle.load(tf)\n",
    "with open(DataPath+'cost_Oracle_with_noise_all.pkl', \"rb\") as tf:\n",
    "    cost_Oracle_with_noise_all = pickle.load(tf)\n",
    "with open(DataPath+'cost_DDR_with_noise_all.pkl', \"rb\") as tf:\n",
    "    cost_DDR_with_noise_all = pickle.load(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_compare2plus(c_item, c_base, c_oracle):\n",
    "    N = len(c_item)\n",
    "    c_diff = c_base - c_item\n",
    "    lbel = np.zeros((N,1))\n",
    "    \n",
    "    equals = np.sum(c_diff == 0)\n",
    "    wins = np.sum(c_diff > 0) # indicate num of c_item is lower than c_base\n",
    "    lose = np.sum(c_diff < 0)\n",
    "    \n",
    "    lbel[c_diff < 0] = 1\n",
    "    lbel[c_diff > 0] = -1\n",
    "    \n",
    "#     print(N, equals, wins, lose)\n",
    "    if N == equals:\n",
    "        win_ratio = 0.5\n",
    "    else:\n",
    "        win_ratio = wins/(N - equals)\n",
    "    cost_reduction = (np.mean(c_diff))/np.abs(np.mean(c_base))\n",
    "    regret_reduction = (np.mean(c_diff))/np.abs(np.mean(c_base) - np.mean(c_oracle))\n",
    "    return win_ratio, cost_reduction, regret_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu= 0.1 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.1 ,lamb= 0.1 h2h_ddr_ols= 0.5170314743410628 regret= 0.0031610811861140474\n",
      "mu= 0.1 ,lamb= 0.2 h2h_ddr_ols= 0.4976963299955762 regret= 0.0027429592579982474\n",
      "mu= 0.1 ,lamb= 0.3 h2h_ddr_ols= 0.49526713563630215 regret= -0.002225139649929707\n",
      "mu= 0.1 ,lamb= 0.4 h2h_ddr_ols= 0.48851949282799095 regret= -0.010116729074699883\n",
      "mu= 0.1 ,lamb= 0.5 h2h_ddr_ols= 0.4768235641265946 regret= -0.023395117810296077\n",
      "mu= 0.1 ,lamb= 0.6 h2h_ddr_ols= 0.4658581249117211 regret= -0.03916977393185568\n",
      "mu= 0.1 ,lamb= 0.7 h2h_ddr_ols= 0.45746600266712784 regret= -0.06437895955307399\n",
      "mu= 0.1 ,lamb= 0.8 h2h_ddr_ols= 0.44999695684689844 regret= -0.08661564748955534\n",
      "mu= 0.1 ,lamb= 0.9 h2h_ddr_ols= 0.44010264584244596 regret= -0.11225241993855115\n",
      "mu= 0.2 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.2 ,lamb= 0.1 h2h_ddr_ols= 0.528192776673457 regret= 0.003683185572765377\n",
      "mu= 0.2 ,lamb= 0.2 h2h_ddr_ols= 0.5184142206320707 regret= 0.0033494446471122\n",
      "mu= 0.2 ,lamb= 0.3 h2h_ddr_ols= 0.5028410466356715 regret= 0.001792600970695566\n",
      "mu= 0.2 ,lamb= 0.4 h2h_ddr_ols= 0.49802920796904787 regret= 0.0010851193550819225\n",
      "mu= 0.2 ,lamb= 0.5 h2h_ddr_ols= 0.4927840491530135 regret= -0.005132228261260316\n",
      "mu= 0.2 ,lamb= 0.6 h2h_ddr_ols= 0.48025161401986255 regret= -0.018159456343845977\n",
      "mu= 0.2 ,lamb= 0.7 h2h_ddr_ols= 0.4661562161978793 regret= -0.03738903107672751\n",
      "mu= 0.2 ,lamb= 0.8 h2h_ddr_ols= 0.4560226022036888 regret= -0.05475351668975611\n",
      "mu= 0.2 ,lamb= 0.9 h2h_ddr_ols= 0.4497879424249611 regret= -0.07861478543200497\n",
      "mu= 0.3 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.3 ,lamb= 0.1 h2h_ddr_ols= 0.5204760143294435 regret= 0.002584927478659129\n",
      "mu= 0.3 ,lamb= 0.2 h2h_ddr_ols= 0.5173369290162114 regret= 0.0019287110232054372\n",
      "mu= 0.3 ,lamb= 0.3 h2h_ddr_ols= 0.5110655122564488 regret= 0.0018007502169205137\n",
      "mu= 0.3 ,lamb= 0.4 h2h_ddr_ols= 0.5010946628209473 regret= -0.0003981495424276752\n",
      "mu= 0.3 ,lamb= 0.5 h2h_ddr_ols= 0.49301869349212496 regret= -0.004094394749813086\n",
      "mu= 0.3 ,lamb= 0.6 h2h_ddr_ols= 0.48912224433966583 regret= -0.009421150477563665\n",
      "mu= 0.3 ,lamb= 0.7 h2h_ddr_ols= 0.4827753868933206 regret= -0.01573134700838171\n",
      "mu= 0.3 ,lamb= 0.8 h2h_ddr_ols= 0.47693874570637645 regret= -0.02426022470807947\n",
      "mu= 0.3 ,lamb= 0.9 h2h_ddr_ols= 0.46636188018956504 regret= -0.039528876315013596\n",
      "mu= 0.4 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.4 ,lamb= 0.1 h2h_ddr_ols= 0.5301361546949781 regret= 0.0016338527818424795\n",
      "mu= 0.4 ,lamb= 0.2 h2h_ddr_ols= 0.5189529107825104 regret= 0.003188492265253711\n",
      "mu= 0.4 ,lamb= 0.3 h2h_ddr_ols= 0.5127964759296366 regret= 0.004119226909157356\n",
      "mu= 0.4 ,lamb= 0.4 h2h_ddr_ols= 0.5083992672768454 regret= 0.003256330383325885\n",
      "mu= 0.4 ,lamb= 0.5 h2h_ddr_ols= 0.502827005656839 regret= 0.0009925337344869741\n",
      "mu= 0.4 ,lamb= 0.6 h2h_ddr_ols= 0.4952168437854273 regret= -0.0036962483236057777\n",
      "mu= 0.4 ,lamb= 0.7 h2h_ddr_ols= 0.49029266214221706 regret= -0.006103478589257194\n",
      "mu= 0.4 ,lamb= 0.8 h2h_ddr_ols= 0.48605199403765936 regret= -0.010632025597028272\n",
      "mu= 0.4 ,lamb= 0.9 h2h_ddr_ols= 0.478988072465979 regret= -0.01711881349424377\n",
      "mu= 0.5 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.5 ,lamb= 0.1 h2h_ddr_ols= 0.5051037851037851 regret= -0.00019216999913794196\n",
      "mu= 0.5 ,lamb= 0.2 h2h_ddr_ols= 0.5006290976903475 regret= 0.0005147366034553656\n",
      "mu= 0.5 ,lamb= 0.3 h2h_ddr_ols= 0.4933007615914767 regret= 0.001964412034863059\n",
      "mu= 0.5 ,lamb= 0.4 h2h_ddr_ols= 0.49814753367144243 regret= 0.00298745800783939\n",
      "mu= 0.5 ,lamb= 0.5 h2h_ddr_ols= 0.49793150565002636 regret= 0.0010468532237571885\n",
      "mu= 0.5 ,lamb= 0.6 h2h_ddr_ols= 0.49619718347357916 regret= -0.0007671765436081379\n",
      "mu= 0.5 ,lamb= 0.7 h2h_ddr_ols= 0.49646725206062053 regret= -0.00048191399201398457\n",
      "mu= 0.5 ,lamb= 0.8 h2h_ddr_ols= 0.4906298429652501 regret= -0.004258038754195988\n",
      "mu= 0.5 ,lamb= 0.9 h2h_ddr_ols= 0.4800180373620606 regret= -0.009503023824844971\n",
      "mu= 0.6 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.6 ,lamb= 0.1 h2h_ddr_ols= 0.5025283327783326 regret= 4.785017123346021e-05\n",
      "mu= 0.6 ,lamb= 0.2 h2h_ddr_ols= 0.5201930518308362 regret= 0.001453552990899985\n",
      "mu= 0.6 ,lamb= 0.3 h2h_ddr_ols= 0.5071282889897247 regret= 0.0016944339438935984\n",
      "mu= 0.6 ,lamb= 0.4 h2h_ddr_ols= 0.4931439461775438 regret= 0.002433543619729752\n",
      "mu= 0.6 ,lamb= 0.5 h2h_ddr_ols= 0.49920319042155525 regret= 0.003588438143347238\n",
      "mu= 0.6 ,lamb= 0.6 h2h_ddr_ols= 0.5047009536943272 regret= 0.005178715137607271\n",
      "mu= 0.6 ,lamb= 0.7 h2h_ddr_ols= 0.4991933115879319 regret= 0.0032785212638572\n",
      "mu= 0.6 ,lamb= 0.8 h2h_ddr_ols= 0.4931666583382551 regret= 0.0007756133342591236\n",
      "mu= 0.6 ,lamb= 0.9 h2h_ddr_ols= 0.49055239473968454 regret= -0.0003087669016127234\n",
      "mu= 0.7 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.7 ,lamb= 0.1 h2h_ddr_ols= 0.512612554112554 regret= -0.00011018756227654861\n",
      "mu= 0.7 ,lamb= 0.2 h2h_ddr_ols= 0.5166807644969409 regret= 0.0021926975073041305\n",
      "mu= 0.7 ,lamb= 0.3 h2h_ddr_ols= 0.5181000105520073 regret= 0.0033482851801208942\n",
      "mu= 0.7 ,lamb= 0.4 h2h_ddr_ols= 0.5089374070295198 regret= 0.0027470154487474314\n",
      "mu= 0.7 ,lamb= 0.5 h2h_ddr_ols= 0.509088829411694 regret= 0.004199317241621796\n",
      "mu= 0.7 ,lamb= 0.6 h2h_ddr_ols= 0.5087112824515432 regret= 0.0054779233829989815\n",
      "mu= 0.7 ,lamb= 0.7 h2h_ddr_ols= 0.5111676140250405 regret= 0.006746761773233403\n",
      "mu= 0.7 ,lamb= 0.8 h2h_ddr_ols= 0.5109099901574472 regret= 0.005847556105623374\n",
      "mu= 0.7 ,lamb= 0.9 h2h_ddr_ols= 0.5002627788694882 regret= 0.0030752471787955458\n",
      "mu= 0.8 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.8 ,lamb= 0.1 h2h_ddr_ols= 0.5235595238095239 regret= -0.0001189764187856397\n",
      "mu= 0.8 ,lamb= 0.2 h2h_ddr_ols= 0.5213870296370297 regret= 0.0006530978925311456\n",
      "mu= 0.8 ,lamb= 0.3 h2h_ddr_ols= 0.5362878902143607 regret= 0.0024358736144650447\n",
      "mu= 0.8 ,lamb= 0.4 h2h_ddr_ols= 0.5171495376828193 regret= 0.0017290087992114463\n",
      "mu= 0.8 ,lamb= 0.5 h2h_ddr_ols= 0.5226908251532868 regret= 0.002381935415810967\n",
      "mu= 0.8 ,lamb= 0.6 h2h_ddr_ols= 0.5159092984525876 regret= 0.002189260645819739\n",
      "mu= 0.8 ,lamb= 0.7 h2h_ddr_ols= 0.5109124500337253 regret= 0.002448269505005057\n",
      "mu= 0.8 ,lamb= 0.8 h2h_ddr_ols= 0.5050149919174811 regret= 0.0027893597905102267\n",
      "mu= 0.8 ,lamb= 0.9 h2h_ddr_ols= 0.5066086433124036 regret= 0.0036220732607536014\n",
      "mu= 0.9 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.9 ,lamb= 0.1 h2h_ddr_ols= 0.5166666666666666 regret= -0.0004365382380236616\n",
      "mu= 0.9 ,lamb= 0.2 h2h_ddr_ols= 0.4928650793650793 regret= -0.0005748085989370595\n",
      "mu= 0.9 ,lamb= 0.3 h2h_ddr_ols= 0.50425 regret= 0.0005428242300204827\n",
      "mu= 0.9 ,lamb= 0.4 h2h_ddr_ols= 0.5164726662226662 regret= 0.00147000885688734\n",
      "mu= 0.9 ,lamb= 0.5 h2h_ddr_ols= 0.5342707292707293 regret= 0.002182087660540324\n",
      "mu= 0.9 ,lamb= 0.6 h2h_ddr_ols= 0.5470978833258244 regret= 0.0028667838883260554\n",
      "mu= 0.9 ,lamb= 0.7 h2h_ddr_ols= 0.5447797403404988 regret= 0.003165007832268083\n",
      "mu= 0.9 ,lamb= 0.8 h2h_ddr_ols= 0.5322852321397213 regret= 0.0030323886792582386\n",
      "mu= 0.9 ,lamb= 0.9 h2h_ddr_ols= 0.5172509371986355 regret= 0.002382568796351437\n"
     ]
    }
   ],
   "source": [
    "h2h_ddr_vs_ols_all = {}; cost_reduction_ddr_vs_ols_all = {}; regret_reduction_ddr_vs_ols_all = {}\n",
    "h2h_ddr_vs_ols_avg = np.zeros((len(mu_all),len(lamb_all))); regret_ddr_vs_ols_avg = np.zeros((len(mu_all),len(lamb_all)))\n",
    "\n",
    "mu_index = 0\n",
    "for mu in mu_all:\n",
    "    lamb_index = 0\n",
    "    for lamb in lamb_all:\n",
    "\n",
    "        h2h_ddr_ols = np.zeros(len(iteration_all)); cost_reduction_ddr_vs_ols = np.zeros(len(iteration_all)); regret_reduction_ddr_vs_ols = np.zeros(len(iteration_all))\n",
    "        for iter_index in range(len(iteration_all)):\n",
    "            iter = iteration_all[iter_index]\n",
    "            h2h_ddr_ols[iter_index],cost_reduction_ddr_vs_ols[iter_index],regret_reduction_ddr_vs_ols[iter_index] = cross_compare2plus(cost_DDR_with_noise_all[iter,mu,lamb], cost_OLS_with_noise_all[iter], cost_Oracle_with_noise_all[iter])\n",
    "        h2h_ddr_vs_ols_avg[mu_index,lamb_index] = np.nanmean(h2h_ddr_ols)\n",
    "        regret_ddr_vs_ols_avg[mu_index,lamb_index] = np.nanmean(regret_reduction_ddr_vs_ols)\n",
    "        print(\"mu=\",mu,\",lamb=\",lamb,\"h2h_ddr_ols=\",np.nanmean(h2h_ddr_ols),\"regret=\",np.nanmean(regret_reduction_ddr_vs_ols))\n",
    "        lamb_index = lamb_index + 1\n",
    "    \n",
    "        h2h_ddr_vs_ols_all[mu,lamb] = h2h_ddr_ols\n",
    "        cost_reduction_ddr_vs_ols_all[mu,lamb] = cost_reduction_ddr_vs_ols\n",
    "        regret_reduction_ddr_vs_ols_all[mu,lamb] = regret_reduction_ddr_vs_ols\n",
    "    mu_index = mu_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_DDR_vs_OLS_para_avg_df = pd.DataFrame(regret_ddr_vs_ols_avg)\n",
    "regret_DDR_vs_OLS_para_avg_df.index = [\"$\\mu=\"+str(mu)+\"$\" for mu in mu_all]\n",
    "regret_DDR_vs_OLS_para_avg_df.columns = [\"$\\lambda=\"+str(lamb)+\"$\" for lamb in lamb_all]\n",
    "regret_DDR_vs_OLS_para_avg_df.to_csv(DataPath+\"regret_ddr_vs_ols_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2h_DDR_vs_OLS_para_avg_df = pd.DataFrame(h2h_ddr_vs_ols_avg)\n",
    "h2h_DDR_vs_OLS_para_avg_df.index = [\"$\\mu=\"+str(mu)+\"$\" for mu in mu_all]\n",
    "h2h_DDR_vs_OLS_para_avg_df.columns = [\"$\\lambda=\"+str(lamb)+\"$\" for lamb in lamb_all]\n",
    "h2h_DDR_vs_OLS_para_avg_df.to_csv(DataPath+\"h2h_ddr_vs_ols_avg.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
