{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "from gurobipy import *\n",
    "from rsome import ro\n",
    "from rsome import grb_solver as grb\n",
    "import rsome as rso\n",
    "from rsome import cpt_solver as cpt\n",
    "import pandas as pd\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "from Performance import performance_evaluation\n",
    "perfs = performance_evaluation()\n",
    "\n",
    "from Network import network_design\n",
    "Network = network_design()\n",
    "\n",
    "from PYEPO import PyEPO_Method\n",
    "epo_runner = PyEPO_Method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump):\n",
    "# #  ****** Coef generation *********\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,data_generation_process) \n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    np.random.seed(coef_seed)\n",
    "    x_test_all = {}; c_test_all = {}; x_train_all = {}; c_train_all = {}; W_star_all = {}; noise_train_all = {}; noise_test_all = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_iter = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_iter).mkdir(parents=True, exist_ok=True)\n",
    "        W_star = data_gen.generate_truth(DataPath_iter,lower, upper, p, d, iter,data_generation_process) \n",
    "        # #  ****** Data generation *********\n",
    "        x_test_all[iter], c_test_all[iter], x_train_all[iter], c_train_all[iter], noise_train_all[iter],noise_test_all[iter],W_star_all[iter] = data_gen.generate_samples(iter,DataPath_iter,p, d, num_test, num_train, alpha, W_star, mis, num_test, \n",
    "                                data_generation_process, x_dist, e_dist, x_low, x_up, x_mean, x_var, bump) \n",
    "        # print()\n",
    "    return x_test_all, c_test_all, x_train_all, c_train_all, noise_train_all,noise_test_all,W_star_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_Oracle(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,iteration_all,num_feat,data_generation_process):\n",
    "    cost_Oracle_with_noise_all = {}; cost_Oracle_wo_noise_all = {}\n",
    "    for iter in iteration_all:\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            non_negative_cols = (cost_oracle_ori > 0).all(axis=0)\n",
    "            cost_oracle_ori = cost_oracle_ori[:,non_negative_cols]\n",
    "\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            cost_Oracle_with_noise_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "            if iter % 20 == 0 and iter > 0:\n",
    "                print(\"Oracle: iter=\",iter,\",cost_Oracle_with_noise_all=\",np.nanmean(cost_Oracle_with_noise_all[iter]))\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_Oracle_with_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter],True)\n",
    "            cost_Oracle_wo_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter],False)\n",
    "\n",
    "            # print(\"Oracle: iter=\",iter,\",cost_Oracle_with_noise_all=\",np.nanmean(cost_Oracle_with_noise_all[iter]),\",cost_Oracle_wo_noise_all=\",np.nanmean(cost_Oracle_wo_noise_all[iter]))\n",
    "    return cost_Oracle_with_noise_all,cost_Oracle_wo_noise_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_OLS(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process):\n",
    "    from OLS import ols_method\n",
    "    ols_method_obj = ols_method()\n",
    "    W_ols_all = {}; w0_ols_all = {}; t_ols_all = {}; obj_ols_all = {}\n",
    "    cost_OLS_with_noise_all = {}; cost_OLS_wo_noise_all = {}\n",
    "    for iter in iteration_all:\n",
    "        # compute OLS performance\n",
    "        W_ols_all[iter], w0_ols_all[iter], t_ols_all[iter], obj_ols_all[iter] = ols_method_obj.ols_solver(\"\",x_train_all[iter], c_train_all[iter])\n",
    "        cost_dem = (W_ols_all[iter] @ x_test_all[iter].T).T + w0_ols_all[iter]\n",
    "\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            non_negative_cols = (cost_oracle_ori > 0).all(axis=0)\n",
    "            cost_oracle_ori = cost_oracle_ori[:,non_negative_cols]\n",
    "            cost_dem = cost_dem[non_negative_cols,:]\n",
    "            \n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            cost_OLS_with_noise_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_OLS_with_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter],True)\n",
    "            cost_OLS_wo_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter],False)\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            print(\"OLS: iter=\",iter,\",cost_OLS_with_noise_all =\",np.nanmean(cost_OLS_with_noise_all[iter]))\n",
    "    return cost_OLS_with_noise_all,cost_OLS_wo_noise_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_DDR(mu_all,lamb_all,arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process):\n",
    "    from DDR import DDR_method\n",
    "    ddr_object = DDR_method()\n",
    "    num_nodes = grid[0] * grid[0]\n",
    "\n",
    "    w0_ddr_dict = {}; W_ddr_dict = {}\n",
    "    cost_DDR_with_noise_all = {}; cost_DDR_wo_noise_all = {}\n",
    "    for iter in iteration_all:\n",
    "        for mu in mu_all:\n",
    "            for lamb in lamb_all:\n",
    "                w0_ddr_dict[iter,mu,lamb],W_ddr_dict[iter,mu,lamb],alpha_rst,obj_ddr = ddr_object.solve_DDR(arcs,lamb,mu,num_nodes,x_train_all[iter],c_train_all[iter])\n",
    "                cost_pred = (W_ddr_dict[iter,mu,lamb] @ x_test_all[iter].T).T + w0_ddr_dict[iter,mu,lamb]\n",
    "\n",
    "                if data_generation_process == \"SPO_Data_Generation\":\n",
    "                    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "                    non_negative_cols = (cost_oracle_ori > 0).all(axis=0)\n",
    "                    cost_oracle_ori = cost_oracle_ori[:,non_negative_cols]\n",
    "                    cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "                    \n",
    "                    cost_pred = cost_pred[non_negative_cols,:]\n",
    "            \n",
    "                    cost_DDR_with_noise_all[iter,mu,lamb] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "                if data_generation_process == \"DDR_Data_Generation\":\n",
    "                    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "                    cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "                    # cost_DDR_with_noise_all[iter,mu,lamb] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],True)\n",
    "                    cost_DDR_wo_noise_all[iter,mu,lamb] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],False)\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            print(\"DDR: iter=\",iter,\",mu=\",mu,\",lamb=\",lamb,\",cost_DDR_with_noise_all =\",np.nanmean(cost_DDR_with_noise_all[iter,mu,lamb]))\n",
    "\n",
    "    return cost_DDR_with_noise_all,cost_DDR_wo_noise_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "                  arcs,grid,epo_runner,perfs,num_feat,mis,data_generation_process):\n",
    "    W_EPO_all = {}; w0_EPO_all = {}\n",
    "    cost_EPO_wo_noise_all = {}; cost_EPO_with_noise_all = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_seed = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        W_EPO_all[iter],w0_EPO_all[iter] = epo_runner.run(method_names,DataPath_seed,batch_size,num_feat,grid,num_epochs,\\\n",
    "                                        x_train_all[iter],c_train_all[iter],arcs)\n",
    "        \n",
    "        cost_pred = (W_EPO_all[iter] @ x_test_all[iter].T).T + w0_EPO_all[iter]\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            non_negative_cols = (cost_oracle_ori > 0).all(axis=0)\n",
    "            cost_oracle_ori = cost_oracle_ori[:,non_negative_cols]\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            \n",
    "            cost_pred = cost_pred[non_negative_cols,:]\n",
    "            cost_EPO_with_noise_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_EPO_wo_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],False)\n",
    "            cost_EPO_with_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],True)\n",
    "\n",
    "        print(method_names[0],\": iter=\",iter,\",cost=\",np.nanmean(cost_EPO_with_noise_all[iter]))\n",
    "\n",
    "    return cost_EPO_with_noise_all,cost_EPO_wo_noise_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_compare2plus(c_item, c_base, c_oracle):\n",
    "    N = len(c_item)\n",
    "    c_diff = c_base - c_item\n",
    "    lbel = np.zeros((N,1))\n",
    "    \n",
    "    equals = np.sum(c_diff == 0)\n",
    "    wins = np.sum(c_diff > 0) # indicate num of c_item is lower than c_base\n",
    "    lose = np.sum(c_diff < 0)\n",
    "    \n",
    "    lbel[c_diff < 0] = 1\n",
    "    lbel[c_diff > 0] = -1\n",
    "    \n",
    "#     print(N, equals, wins, lose)\n",
    "    if N == equals:\n",
    "        win_ratio = 0.5\n",
    "    else:\n",
    "        win_ratio = wins/(N - equals)\n",
    "    cost_reduction = (np.mean(c_diff))/np.abs(np.mean(c_base))\n",
    "    regret_reduction = (np.mean(c_diff))/np.abs(np.mean(c_base) - np.mean(c_oracle))\n",
    "    return win_ratio, cost_reduction, regret_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = 1000\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "x_dist = 'uniform'\n",
    "e_dist = 'normal'\n",
    "x_low = -2\n",
    "x_up = 2\n",
    "x_mean = 2\n",
    "x_var = 2\n",
    "bump = 100\n",
    "\n",
    "coef_seed = 1\n",
    "data_generation_process = \"SPO_Data_Generation\"\n",
    "# data_generation_process = \"DDR_Data_Generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "grandparent_directory = os.path.dirname(parent_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data/Shortest_Path_Reproduce/Various_Settings/5by5_grid_SPO_Data_Generation/data_size=100_deg=1.0_e=0.5_d=40_p=5_x_dist=uniform_num_test=1000_diff_W/\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3158.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of cores: 2\n",
      "epoch =  0 in sample cost =  31.13405355811119 ,diff =  99999968.86594644\n",
      "epoch =  1 in sample cost =  31.056644147634508 ,diff =  0.07740941047668315\n",
      "epoch =  2 in sample cost =  31.049678152799608 ,diff =  0.006965994834899902\n",
      "epoch =  3 in sample cost =  31.049357117414473 ,diff =  0.0003210353851343939\n",
      "epoch =  4 in sample cost =  31.023529167175294 ,diff =  0.025827950239179387\n",
      "epoch =  5 in sample cost =  30.925333638191223 ,diff =  0.09819552898407125\n",
      "epoch =  6 in sample cost =  30.85796445608139 ,diff =  0.06736918210983234\n",
      "epoch =  7 in sample cost =  30.727446374893187 ,diff =  0.13051808118820318\n",
      "epoch =  8 in sample cost =  30.73369214296341 ,diff =  0.006245768070222368\n",
      "epoch =  9 in sample cost =  30.65458482146263 ,diff =  0.07910732150077848\n",
      "epoch =  10 in sample cost =  30.600940964221955 ,diff =  0.053643857240675885\n",
      "epoch =  11 in sample cost =  30.53211574435234 ,diff =  0.0688252198696162\n",
      "epoch =  12 in sample cost =  30.48008214354515 ,diff =  0.05203360080718866\n",
      "epoch =  13 in sample cost =  30.412041496038437 ,diff =  0.06804064750671301\n",
      "epoch =  14 in sample cost =  30.36160848021507 ,diff =  0.05043301582336568\n",
      "epoch =  15 in sample cost =  30.292882603406905 ,diff =  0.06872587680816622\n",
      "epoch =  16 in sample cost =  30.336520928144456 ,diff =  0.04363832473755025\n",
      "epoch =  17 in sample cost =  30.264834662675856 ,diff =  0.07168626546859969\n",
      "epoch =  18 in sample cost =  30.244636205434798 ,diff =  0.020198457241058065\n",
      "epoch =  19 in sample cost =  30.220056887865066 ,diff =  0.02457931756973153\n",
      "epoch =  20 in sample cost =  30.17263142466545 ,diff =  0.04742546319961605\n",
      "epoch =  21 in sample cost =  30.1647050344944 ,diff =  0.007926390171050457\n",
      "epoch =  22 in sample cost =  30.158231726884843 ,diff =  0.006473307609557111\n",
      "epoch =  23 in sample cost =  30.053880215883254 ,diff =  0.1043515110015889\n",
      "epoch =  24 in sample cost =  30.010428825616838 ,diff =  0.04345139026641576\n",
      "epoch =  25 in sample cost =  30.015582963228226 ,diff =  0.005154137611388165\n",
      "epoch =  26 in sample cost =  30.030921194553375 ,diff =  0.01533823132514911\n",
      "epoch =  27 in sample cost =  30.030921194553375 ,diff =  0.0\n",
      "spo+ : iter= 0 ,cost= 31.096787690071586\n"
     ]
    }
   ],
   "source": [
    "num_train = 100\n",
    "num_feat = 5 # size of feature\n",
    "p = num_feat\n",
    "deg = 1.0 # polynomial degree\n",
    "mis = deg # model misspecification\n",
    "e = 0.5 # scale of normal std or the range of uniform. For the error term\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "\n",
    "iteration_all = np.arange(0,100)\n",
    "mu_all = np.round(np.arange(0.1,1.0,0.1),4)\n",
    "lamb_all = np.round(np.arange(0.0,1.0,0.1),4)\n",
    "\n",
    "# EPO, including SPO, PG, LTR\n",
    "batch_size = 20\n",
    "num_epochs = 1000\n",
    "# method_names = [\"spo+\",\"pg\",\"ltr\"]\n",
    "\n",
    "grid_all = [(2,2),(3,3),(4,4),(5,5)]\n",
    "for grid in grid_all:\n",
    "    arcs,arc_index_mapping = Network._getArcs(grid)\n",
    "    d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "    num_nodes = grid[0]*grid[0]\n",
    "    DataPath_parent = os.path.dirname(grandparent_directory) + '/Data/Shortest_Path_Reproduce/Size_of_Network/'+str(grid[0])+'by'+str(grid[1])+'_grid_' + data_generation_process + \"/\"\n",
    "    pathlib.Path(DataPath_parent).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    DataPath = DataPath_parent + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_p=\"+str(p)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "    pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "    print(\"DataPath:\", DataPath)\n",
    "    x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all = Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)\n",
    "    cost_Oracle_with_noise_all,cost_Oracle_wo_noise_all = Implement_Oracle(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,iteration_all,num_feat,data_generation_process)\n",
    "    cost_OLS_with_noise_all,cost_OLS_wo_noise_all = Implement_OLS(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process)\n",
    "    cost_DDR_with_noise_all,cost_DDR_wo_noise_all = Implement_DDR(mu_all,lamb_all,arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process)\n",
    "    \n",
    "    method_names = [\"spo+\"]\n",
    "    cost_SPO_with_noise_all,cost_SPO_wo_noise_all = Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "                  arcs,grid,epo_runner,perfs,num_feat,mis,data_generation_process)\n",
    "    \n",
    "    with open(DataPath+'cost_OLS_with_noise_all.pkl', \"wb\") as tf:\n",
    "        pickle.dump(cost_OLS_with_noise_all,tf)\n",
    "    with open(DataPath+'cost_Oracle_with_noise_all.pkl', \"wb\") as tf:\n",
    "        pickle.dump(cost_Oracle_with_noise_all,tf)\n",
    "    with open(DataPath+'cost_DDR_with_noise_all.pkl', \"wb\") as tf:\n",
    "        pickle.dump(cost_DDR_with_noise_all,tf)\n",
    "    with open(DataPath+'cost_SPO_with_noise_all.pkl', \"wb\") as tf:\n",
    "        pickle.dump(cost_SPO_with_noise_all,tf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
