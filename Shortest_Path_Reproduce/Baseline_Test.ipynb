{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "from gurobipy import *\n",
    "from rsome import ro\n",
    "from rsome import grb_solver as grb\n",
    "import rsome as rso\n",
    "from rsome import cpt_solver as cpt\n",
    "import pandas as pd\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "from Performance import performance_evaluation\n",
    "perfs = performance_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump):\n",
    "# #  ****** Coef generation *********\n",
    "    from Data import data_generation\n",
    "    data_gen = data_generation()\n",
    "    # W_star = data_gen.generate_truth(DataPath,lower, upper, p, d, coef_seed,data_generation_process) \n",
    "    # print(\"W_star = \",W_star[0,:])\n",
    "    np.random.seed(coef_seed)\n",
    "    x_test_all = {}; c_test_all = {}; x_train_all = {}; c_train_all = {}; W_star_all = {}; noise_train_all = {}; noise_test_all = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_iter = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_iter).mkdir(parents=True, exist_ok=True)\n",
    "        W_star = data_gen.generate_truth(DataPath_iter,lower, upper, p, d, iter,data_generation_process) \n",
    "        # #  ****** Data generation *********\n",
    "        x_test_all[iter], c_test_all[iter], x_train_all[iter], c_train_all[iter], noise_train_all[iter],noise_test_all[iter],W_star_all[iter] = data_gen.generate_samples(iter,DataPath_iter,p, d, num_test, num_train, alpha, W_star, mis, num_test, \n",
    "                                data_generation_process, x_dist, e_dist, x_low, x_up, x_mean, x_var, bump) \n",
    "        # print()\n",
    "    return x_test_all, c_test_all, x_train_all, c_train_all, noise_train_all,noise_test_all,W_star_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_Oracle(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,iteration_all,num_feat,data_generation_process):\n",
    "    cost_Oracle_with_noise_all = {}; cost_Oracle_wo_noise_all = {}\n",
    "    for iter in iteration_all:\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            cost_Oracle_with_noise_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "            print(\"Oracle: iter=\",iter,\",cost_Oracle_with_noise_all=\",np.nanmean(cost_Oracle_with_noise_all[iter]))\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_Oracle_with_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter],True)\n",
    "            cost_Oracle_wo_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_oracle_pred,cost_oracle_pred,noise_test_all[iter],False)\n",
    "\n",
    "            # print(\"Oracle: iter=\",iter,\",cost_Oracle_with_noise_all=\",np.nanmean(cost_Oracle_with_noise_all[iter]),\",cost_Oracle_wo_noise_all=\",np.nanmean(cost_Oracle_wo_noise_all[iter]))\n",
    "    return cost_Oracle_with_noise_all,cost_Oracle_wo_noise_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_OLS(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process):\n",
    "    from OLS import ols_method\n",
    "    ols_method_obj = ols_method()\n",
    "    W_ols_all = {}; w0_ols_all = {}; t_ols_all = {}; obj_ols_all = {}\n",
    "    cost_OLS_with_noise_all = {}; cost_OLS_wo_noise_all = {}\n",
    "    for iter in iteration_all:\n",
    "        # compute OLS performance\n",
    "        W_ols_all[iter], w0_ols_all[iter], t_ols_all[iter], obj_ols_all[iter] = ols_method_obj.ols_solver(\"\",x_train_all[iter], c_train_all[iter])\n",
    "        cost_dem = (W_ols_all[iter] @ x_test_all[iter].T).T + w0_ols_all[iter]\n",
    "\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            cost_OLS_with_noise_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_OLS_with_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter],True)\n",
    "            cost_OLS_wo_noise_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter],False)\n",
    "        if iter % 20 == 0 and iter > 0:\n",
    "            print(\"OLS: iter=\",iter,\",cost_OLS_with_noise_all =\",np.nanmean(cost_OLS_with_noise_all[iter]))\n",
    "    return cost_OLS_with_noise_all,cost_OLS_wo_noise_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_DDR(mu_all,lamb_all,arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process):\n",
    "    from DDR import DDR_method\n",
    "    ddr_object = DDR_method()\n",
    "    num_nodes = grid[0] * grid[0]\n",
    "\n",
    "    w0_ddr_dict = {}; W_ddr_dict = {}\n",
    "    cost_DDR_with_noise_all = {}; cost_DDR_wo_noise_all = {}\n",
    "    for iter in iteration_all:\n",
    "        for mu in mu_all:\n",
    "            for lamb in lamb_all:\n",
    "                w0_ddr_dict[iter,mu,lamb],W_ddr_dict[iter,mu,lamb],alpha_rst,obj_ddr = ddr_object.solve_DDR(arcs,lamb,mu,num_nodes,x_train_all[iter],c_train_all[iter])\n",
    "                cost_pred = (W_ddr_dict[iter,mu,lamb] @ x_test_all[iter].T).T + w0_ddr_dict[iter,mu,lamb]\n",
    "\n",
    "                if data_generation_process == \"SPO_Data_Generation\":\n",
    "                    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "                    cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "                    cost_DDR_with_noise_all[iter,mu,lamb] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "                if data_generation_process == \"DDR_Data_Generation\":\n",
    "                    cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "                    cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "                    # cost_DDR_with_noise_all[iter,mu,lamb] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],True)\n",
    "                    cost_DDR_wo_noise_all[iter,mu,lamb] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_pred,cost_oracle_pred,noise_test_all[iter],False)\n",
    "        if iter % 1 == 0 and iter > 0:\n",
    "            print(\"DDR: iter=\",iter,\",mu=\",mu,\",lamb=\",lamb,\",cost_DDR_with_noise_all =\",np.nanmean(cost_DDR_with_noise_all[iter,mu,lamb]))\n",
    "\n",
    "    return cost_DDR_with_noise_all,cost_DDR_wo_noise_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grandparent_directory: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Code_MacBook\n",
      "DataPath: /Users/zhangxun/Dropbox/Research/Decision_Driven_Regularization/Data/Shortest_Path_Reproduce/5by5_grid_SPO_Data_Generation_S=100/\n"
     ]
    }
   ],
   "source": [
    "grid = (5,5) # grid size\n",
    "num_train = 100 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "num_test = 1000\n",
    "deg = 1.0 # polynomial degree\n",
    "e = 0.5 # scale of normal std or the range of uniform. For the error term\n",
    "\n",
    "lower = 0 # coef lower bound\n",
    "upper = 1 # coef upper bound\n",
    "p = num_feat # num of features\n",
    "d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "num_nodes = grid[0]*grid[0]\n",
    "alpha = e # scale of normal std or the range of uniform. For the error term\n",
    "mis = deg # model misspecification\n",
    "coef_seed = 1\n",
    "\n",
    "x_dist = 'uniform'\n",
    "e_dist = 'normal'\n",
    "x_low = -2\n",
    "x_up = 2\n",
    "x_mean = 2\n",
    "x_var = 2\n",
    "bump = 100\n",
    "\n",
    "data_generation_process = \"SPO_Data_Generation\"\n",
    "# data_generation_process = \"DDR_Data_Generation\"\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "grandparent_directory = os.path.dirname(parent_directory)\n",
    "DataPath = os.path.dirname(grandparent_directory) + '/Data/Shortest_Path_Reproduce/'+str(grid[0])+'by'+str(grid[1])+'_grid_' + data_generation_process + \"_S=100/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)\n",
    "print(\"grandparent_directory:\", grandparent_directory)\n",
    "print(\"DataPath:\", DataPath)\n",
    "DataPath = DataPath + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "pathlib.Path(DataPath).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_all = np.arange(0,100)\n",
    "x_test_all, c_test_all, x_train_all, c_train_all,noise_train_all,noise_test_all,W_star_all = Prepare_Data(DataPath,lower, upper, p, d, coef_seed,iteration_all,num_test, num_train, alpha,mis,data_generation_process,x_dist, e_dist, x_low, x_up, x_mean, x_var, bump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-03-13\n",
      "Oracle: iter= 0 ,cost_Oracle_with_noise_all= 29.3866090601035\n",
      "Oracle: iter= 1 ,cost_Oracle_with_noise_all= 29.206888258544698\n",
      "Oracle: iter= 2 ,cost_Oracle_with_noise_all= 29.84722265331638\n",
      "Oracle: iter= 3 ,cost_Oracle_with_noise_all= 29.54973437815811\n",
      "Oracle: iter= 4 ,cost_Oracle_with_noise_all= 30.04309887526118\n",
      "Oracle: iter= 5 ,cost_Oracle_with_noise_all= 29.822800718946777\n",
      "Oracle: iter= 6 ,cost_Oracle_with_noise_all= 29.553496105402882\n",
      "Oracle: iter= 7 ,cost_Oracle_with_noise_all= 29.344619889515098\n",
      "Oracle: iter= 8 ,cost_Oracle_with_noise_all= 29.18228176386138\n",
      "Oracle: iter= 9 ,cost_Oracle_with_noise_all= 29.529635487694396\n",
      "Oracle: iter= 10 ,cost_Oracle_with_noise_all= 29.314580959557848\n",
      "Oracle: iter= 11 ,cost_Oracle_with_noise_all= 29.861832481945385\n",
      "Oracle: iter= 12 ,cost_Oracle_with_noise_all= 29.60493782617165\n",
      "Oracle: iter= 13 ,cost_Oracle_with_noise_all= 29.38400175647671\n",
      "Oracle: iter= 14 ,cost_Oracle_with_noise_all= 29.635930717106408\n",
      "Oracle: iter= 15 ,cost_Oracle_with_noise_all= 30.181635844143702\n",
      "Oracle: iter= 16 ,cost_Oracle_with_noise_all= 30.05752349464362\n",
      "Oracle: iter= 17 ,cost_Oracle_with_noise_all= 29.26361728445232\n",
      "Oracle: iter= 18 ,cost_Oracle_with_noise_all= 29.382238974359545\n",
      "Oracle: iter= 19 ,cost_Oracle_with_noise_all= 29.6232498138704\n",
      "Oracle: iter= 20 ,cost_Oracle_with_noise_all= 29.477691153720873\n",
      "Oracle: iter= 21 ,cost_Oracle_with_noise_all= 28.87225026641973\n",
      "Oracle: iter= 22 ,cost_Oracle_with_noise_all= 29.641549563742373\n",
      "Oracle: iter= 23 ,cost_Oracle_with_noise_all= 29.255435756574407\n",
      "Oracle: iter= 24 ,cost_Oracle_with_noise_all= 29.501101434160105\n",
      "Oracle: iter= 25 ,cost_Oracle_with_noise_all= 29.590998033615435\n",
      "Oracle: iter= 26 ,cost_Oracle_with_noise_all= 29.79413315770647\n",
      "Oracle: iter= 27 ,cost_Oracle_with_noise_all= 29.86904459503073\n",
      "Oracle: iter= 28 ,cost_Oracle_with_noise_all= 29.377133919973733\n",
      "Oracle: iter= 29 ,cost_Oracle_with_noise_all= 29.357010370926098\n",
      "Oracle: iter= 30 ,cost_Oracle_with_noise_all= 29.51054495525926\n",
      "Oracle: iter= 31 ,cost_Oracle_with_noise_all= 29.797744789806213\n",
      "Oracle: iter= 32 ,cost_Oracle_with_noise_all= 29.8093110916919\n",
      "Oracle: iter= 33 ,cost_Oracle_with_noise_all= 29.88363149081398\n",
      "Oracle: iter= 34 ,cost_Oracle_with_noise_all= 29.81816039385491\n",
      "Oracle: iter= 35 ,cost_Oracle_with_noise_all= 29.871723361353883\n",
      "Oracle: iter= 36 ,cost_Oracle_with_noise_all= 29.99393804861785\n",
      "Oracle: iter= 37 ,cost_Oracle_with_noise_all= 29.71111069873784\n",
      "Oracle: iter= 38 ,cost_Oracle_with_noise_all= 29.364223839994064\n",
      "Oracle: iter= 39 ,cost_Oracle_with_noise_all= 29.520210480522717\n",
      "Oracle: iter= 40 ,cost_Oracle_with_noise_all= 29.9677596736168\n",
      "Oracle: iter= 41 ,cost_Oracle_with_noise_all= 29.264275158062222\n",
      "Oracle: iter= 42 ,cost_Oracle_with_noise_all= 29.40882646521643\n",
      "Oracle: iter= 43 ,cost_Oracle_with_noise_all= 29.49553353569724\n",
      "Oracle: iter= 44 ,cost_Oracle_with_noise_all= 30.082088554521754\n",
      "Oracle: iter= 45 ,cost_Oracle_with_noise_all= 29.576358665158892\n",
      "Oracle: iter= 46 ,cost_Oracle_with_noise_all= 29.46904316473143\n",
      "Oracle: iter= 47 ,cost_Oracle_with_noise_all= 30.04987311362342\n",
      "Oracle: iter= 48 ,cost_Oracle_with_noise_all= 29.383121564093123\n",
      "Oracle: iter= 49 ,cost_Oracle_with_noise_all= 29.790771611505384\n",
      "Oracle: iter= 50 ,cost_Oracle_with_noise_all= 29.343470355798846\n",
      "Oracle: iter= 51 ,cost_Oracle_with_noise_all= 29.54981023600169\n",
      "Oracle: iter= 52 ,cost_Oracle_with_noise_all= 29.187028192746453\n",
      "Oracle: iter= 53 ,cost_Oracle_with_noise_all= 29.8196255431431\n",
      "Oracle: iter= 54 ,cost_Oracle_with_noise_all= 29.25652627526734\n",
      "Oracle: iter= 55 ,cost_Oracle_with_noise_all= 29.69143375533606\n",
      "Oracle: iter= 56 ,cost_Oracle_with_noise_all= 29.993258837768234\n",
      "Oracle: iter= 57 ,cost_Oracle_with_noise_all= 30.101107978378888\n",
      "Oracle: iter= 58 ,cost_Oracle_with_noise_all= 29.004198396200852\n",
      "Oracle: iter= 59 ,cost_Oracle_with_noise_all= 29.3638991550161\n",
      "Oracle: iter= 60 ,cost_Oracle_with_noise_all= 29.673924033100285\n",
      "Oracle: iter= 61 ,cost_Oracle_with_noise_all= 29.688016610754524\n",
      "Oracle: iter= 62 ,cost_Oracle_with_noise_all= 29.4042501838099\n",
      "Oracle: iter= 63 ,cost_Oracle_with_noise_all= 29.75428608595321\n",
      "Oracle: iter= 64 ,cost_Oracle_with_noise_all= 29.360110217198606\n",
      "Oracle: iter= 65 ,cost_Oracle_with_noise_all= 29.515122259592093\n",
      "Oracle: iter= 66 ,cost_Oracle_with_noise_all= 29.614486897461916\n",
      "Oracle: iter= 67 ,cost_Oracle_with_noise_all= 29.59048996784916\n",
      "Oracle: iter= 68 ,cost_Oracle_with_noise_all= 29.476747024359618\n",
      "Oracle: iter= 69 ,cost_Oracle_with_noise_all= 29.454887049285333\n",
      "Oracle: iter= 70 ,cost_Oracle_with_noise_all= 29.897402793645437\n",
      "Oracle: iter= 71 ,cost_Oracle_with_noise_all= 29.555939153650634\n",
      "Oracle: iter= 72 ,cost_Oracle_with_noise_all= 29.930720795792677\n",
      "Oracle: iter= 73 ,cost_Oracle_with_noise_all= 29.65027850511607\n",
      "Oracle: iter= 74 ,cost_Oracle_with_noise_all= 29.701813471196946\n",
      "Oracle: iter= 75 ,cost_Oracle_with_noise_all= 29.650494867279193\n",
      "Oracle: iter= 76 ,cost_Oracle_with_noise_all= 29.65601205353559\n",
      "Oracle: iter= 77 ,cost_Oracle_with_noise_all= 29.70350778662532\n",
      "Oracle: iter= 78 ,cost_Oracle_with_noise_all= 29.898399591284164\n",
      "Oracle: iter= 79 ,cost_Oracle_with_noise_all= 29.563140714740243\n",
      "Oracle: iter= 80 ,cost_Oracle_with_noise_all= 29.4445010707317\n",
      "Oracle: iter= 81 ,cost_Oracle_with_noise_all= 29.086888120744508\n",
      "Oracle: iter= 82 ,cost_Oracle_with_noise_all= 29.49744342158828\n",
      "Oracle: iter= 83 ,cost_Oracle_with_noise_all= 29.4770946678311\n",
      "Oracle: iter= 84 ,cost_Oracle_with_noise_all= 29.72468817986422\n",
      "Oracle: iter= 85 ,cost_Oracle_with_noise_all= 29.168032968206223\n",
      "Oracle: iter= 86 ,cost_Oracle_with_noise_all= 29.30052078835479\n",
      "Oracle: iter= 87 ,cost_Oracle_with_noise_all= 29.502891605778508\n",
      "Oracle: iter= 88 ,cost_Oracle_with_noise_all= 29.707174641787155\n",
      "Oracle: iter= 89 ,cost_Oracle_with_noise_all= 29.7548223890246\n",
      "Oracle: iter= 90 ,cost_Oracle_with_noise_all= 29.478195276938\n",
      "Oracle: iter= 91 ,cost_Oracle_with_noise_all= 29.502245941777\n",
      "Oracle: iter= 92 ,cost_Oracle_with_noise_all= 30.084330246157666\n",
      "Oracle: iter= 93 ,cost_Oracle_with_noise_all= 29.68574132302822\n",
      "Oracle: iter= 94 ,cost_Oracle_with_noise_all= 29.61533251904387\n",
      "Oracle: iter= 95 ,cost_Oracle_with_noise_all= 29.298220611515983\n",
      "Oracle: iter= 96 ,cost_Oracle_with_noise_all= 29.1898719599432\n",
      "Oracle: iter= 97 ,cost_Oracle_with_noise_all= 29.3970151273445\n",
      "Oracle: iter= 98 ,cost_Oracle_with_noise_all= 29.688287253872428\n",
      "Oracle: iter= 99 ,cost_Oracle_with_noise_all= 29.824942211681957\n"
     ]
    }
   ],
   "source": [
    "from Network import network_design\n",
    "Network = network_design()\n",
    "arcs,arc_index_mapping = Network._getArcs(grid)\n",
    "\n",
    "cost_Oracle_with_noise_all,cost_Oracle_wo_noise_all = Implement_Oracle(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS: iter= 20 ,cost_OLS_with_noise_all = 29.753776569887517\n",
      "OLS: iter= 40 ,cost_OLS_with_noise_all = 30.269029629341485\n",
      "OLS: iter= 60 ,cost_OLS_with_noise_all = 29.890047525489848\n",
      "OLS: iter= 80 ,cost_OLS_with_noise_all = 29.776666480830645\n"
     ]
    }
   ],
   "source": [
    "cost_OLS_with_noise_all,cost_OLS_wo_noise_all = Implement_OLS(arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDR: iter= 1 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.65109719021676\n",
      "DDR: iter= 2 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.356211891837965\n",
      "DDR: iter= 3 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.788252922121124\n",
      "DDR: iter= 4 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.36010856426727\n",
      "DDR: iter= 5 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.169854805130687\n",
      "DDR: iter= 6 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.937245822291704\n",
      "DDR: iter= 7 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.72658514639245\n",
      "DDR: iter= 8 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.480551341650383\n",
      "DDR: iter= 9 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.87084667377576\n",
      "DDR: iter= 10 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.67115809059136\n",
      "DDR: iter= 11 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.231641970699158\n",
      "DDR: iter= 12 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.863476901813033\n",
      "DDR: iter= 13 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.622711193501992\n",
      "DDR: iter= 14 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.03900617176271\n",
      "DDR: iter= 15 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.41162150228776\n",
      "DDR: iter= 16 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.349374287830774\n",
      "DDR: iter= 17 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.508004942338438\n",
      "DDR: iter= 18 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.677738937756153\n",
      "DDR: iter= 19 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.989825491532514\n",
      "DDR: iter= 20 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.756444699057045\n",
      "DDR: iter= 21 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.073934812212414\n",
      "DDR: iter= 22 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.92286238527407\n",
      "DDR: iter= 23 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.504128992356208\n",
      "DDR: iter= 24 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.859397607951898\n",
      "DDR: iter= 25 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.03343676771735\n",
      "DDR: iter= 26 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.19607826374913\n",
      "DDR: iter= 27 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.161933558147407\n",
      "DDR: iter= 28 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.631461442739955\n",
      "DDR: iter= 29 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.645809734712827\n",
      "DDR: iter= 30 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.73683753317543\n",
      "DDR: iter= 31 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.225443196345363\n",
      "DDR: iter= 32 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.190252162528257\n",
      "DDR: iter= 33 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.234398644707397\n",
      "DDR: iter= 34 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.341719641321028\n",
      "DDR: iter= 35 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.143862431550836\n",
      "DDR: iter= 36 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.24386080116703\n",
      "DDR: iter= 37 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.039023772276312\n",
      "DDR: iter= 38 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.650988093747582\n",
      "DDR: iter= 39 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.88705474556259\n",
      "DDR: iter= 40 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.27117205532961\n",
      "DDR: iter= 41 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.62086511715858\n",
      "DDR: iter= 42 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.876153944802486\n",
      "DDR: iter= 43 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.801307807116363\n",
      "DDR: iter= 44 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.46999955102508\n",
      "DDR: iter= 45 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.964936162364086\n",
      "DDR: iter= 46 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.796721088989656\n",
      "DDR: iter= 47 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.293247555798818\n",
      "DDR: iter= 48 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.705668354079904\n",
      "DDR: iter= 49 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.25097952813913\n",
      "DDR: iter= 50 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.600843902882573\n",
      "DDR: iter= 51 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.901042575809676\n",
      "DDR: iter= 52 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.402253854390672\n",
      "DDR: iter= 53 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.206342298034382\n",
      "DDR: iter= 54 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.48338124499186\n",
      "DDR: iter= 55 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.015333109264358\n",
      "DDR: iter= 56 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.41268622819784\n",
      "DDR: iter= 57 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.457308639053153\n",
      "DDR: iter= 58 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.26578242747544\n",
      "DDR: iter= 59 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.760544189432704\n",
      "DDR: iter= 60 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.88684086757512\n",
      "DDR: iter= 61 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.137714461664704\n",
      "DDR: iter= 62 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.826063316300875\n",
      "DDR: iter= 63 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.197188469509456\n",
      "DDR: iter= 64 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.630947511556656\n",
      "DDR: iter= 65 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.921390155534596\n",
      "DDR: iter= 66 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.84329071359038\n",
      "DDR: iter= 67 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.867035887003556\n",
      "DDR: iter= 68 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.16471342279236\n",
      "DDR: iter= 69 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.900530227796665\n",
      "DDR: iter= 70 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.29056534398403\n",
      "DDR: iter= 71 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.958843403907768\n",
      "DDR: iter= 72 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.13121391883427\n",
      "DDR: iter= 73 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.958160987914475\n",
      "DDR: iter= 74 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.077719617915594\n",
      "DDR: iter= 75 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.019305149289096\n",
      "DDR: iter= 76 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.926056345288682\n",
      "DDR: iter= 77 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.026974899415166\n",
      "DDR: iter= 78 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.377452211192285\n",
      "DDR: iter= 79 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.93655643726029\n",
      "DDR: iter= 80 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.76834174099611\n",
      "DDR: iter= 81 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.507787878127385\n",
      "DDR: iter= 82 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.77339904277226\n",
      "DDR: iter= 83 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.780154609693753\n",
      "DDR: iter= 84 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.004662298256996\n",
      "DDR: iter= 85 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.393320174674283\n",
      "DDR: iter= 86 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.582547990809942\n",
      "DDR: iter= 87 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.109805416296563\n",
      "DDR: iter= 88 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.003579727096188\n",
      "DDR: iter= 89 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.126046423459833\n",
      "DDR: iter= 90 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.810983698085195\n",
      "DDR: iter= 91 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.838729751735475\n",
      "DDR: iter= 92 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.47539481385847\n",
      "DDR: iter= 93 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.054184520316117\n",
      "DDR: iter= 94 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.0397115292276\n",
      "DDR: iter= 95 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.570460380502755\n",
      "DDR: iter= 96 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.450817263466895\n",
      "DDR: iter= 97 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.787639694671444\n",
      "DDR: iter= 98 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 29.954083634714813\n",
      "DDR: iter= 99 ,mu= 0.9 ,lamb= 0.9 ,cost_DDR_with_noise_all = 30.29801737692161\n"
     ]
    }
   ],
   "source": [
    "mu_all = np.round(np.arange(0.1,1.0,0.1),4)\n",
    "lamb_all = np.round(np.arange(0.0,1.0,0.1),4)\n",
    "cost_DDR_with_noise_all,cost_DDR_wo_noise_all = Implement_DDR(mu_all,lamb_all,arcs, grid,mis,bump,W_star_all,x_test_all,noise_test_all,x_train_all,c_train_all,iteration_all,num_feat,data_generation_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DataPath+'cost_OLS_with_noise_all.pkl', \"wb\") as tf:\n",
    "    pickle.dump(cost_OLS_with_noise_all,tf)\n",
    "with open(DataPath+'cost_Oracle_with_noise_all.pkl', \"wb\") as tf:\n",
    "    pickle.dump(cost_Oracle_with_noise_all,tf)\n",
    "with open(DataPath+'cost_DDR_with_noise_all.pkl', \"wb\") as tf:\n",
    "    pickle.dump(cost_DDR_with_noise_all,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DataPath+'cost_OLS_with_noise_all.pkl', \"rb\") as tf:\n",
    "    cost_OLS_with_noise_all = pickle.load(tf)\n",
    "with open(DataPath+'cost_Oracle_with_noise_all.pkl', \"rb\") as tf:\n",
    "    cost_Oracle_with_noise_all = pickle.load(tf)\n",
    "with open(DataPath+'cost_DDR_with_noise_all.pkl', \"rb\") as tf:\n",
    "    cost_DDR_with_noise_all = pickle.load(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_compare2plus(c_item, c_base, c_oracle):\n",
    "    N = len(c_item)\n",
    "    c_diff = c_base - c_item\n",
    "    lbel = np.zeros((N,1))\n",
    "    \n",
    "    equals = np.sum(c_diff == 0)\n",
    "    wins = np.sum(c_diff > 0) # indicate num of c_item is lower than c_base\n",
    "    lose = np.sum(c_diff < 0)\n",
    "    \n",
    "    lbel[c_diff < 0] = 1\n",
    "    lbel[c_diff > 0] = -1\n",
    "    \n",
    "#     print(N, equals, wins, lose)\n",
    "    if N == equals:\n",
    "        win_ratio = 0.5\n",
    "    else:\n",
    "        win_ratio = wins/(N - equals)\n",
    "    cost_reduction = (np.mean(c_diff))/np.abs(np.mean(c_base))\n",
    "    regret_reduction = (np.mean(c_diff))/np.abs(np.mean(c_base) - np.mean(c_oracle))\n",
    "    return win_ratio, cost_reduction, regret_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu= 0.1 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.1 ,lamb= 0.1 h2h_ddr_ols= 0.5054385181142962 regret= 0.0008182865055642739\n",
      "mu= 0.1 ,lamb= 0.2 h2h_ddr_ols= 0.5019022219578873 regret= 0.00024680200489297054\n",
      "mu= 0.1 ,lamb= 0.3 h2h_ddr_ols= 0.4939105547446935 regret= -0.0054629493523739294\n",
      "mu= 0.1 ,lamb= 0.4 h2h_ddr_ols= 0.48554207547175493 regret= -0.013951982938941317\n",
      "mu= 0.1 ,lamb= 0.5 h2h_ddr_ols= 0.47422402629487387 regret= -0.027772911598010076\n",
      "mu= 0.1 ,lamb= 0.6 h2h_ddr_ols= 0.46539300213764084 regret= -0.043678841405654624\n",
      "mu= 0.1 ,lamb= 0.7 h2h_ddr_ols= 0.4520284409338725 regret= -0.06441425029184952\n",
      "mu= 0.1 ,lamb= 0.8 h2h_ddr_ols= 0.4386004413782556 regret= -0.09216405326802832\n",
      "mu= 0.1 ,lamb= 0.9 h2h_ddr_ols= 0.42803609469724835 regret= -0.11878315345231873\n",
      "mu= 0.2 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.2 ,lamb= 0.1 h2h_ddr_ols= 0.504197363091746 regret= 0.00013077908938838846\n",
      "mu= 0.2 ,lamb= 0.2 h2h_ddr_ols= 0.5027239289731302 regret= 0.0007695041988238504\n",
      "mu= 0.2 ,lamb= 0.3 h2h_ddr_ols= 0.4934880208922443 regret= -0.0035862115361723294\n",
      "mu= 0.2 ,lamb= 0.4 h2h_ddr_ols= 0.48933186364222925 regret= -0.006339163645577855\n",
      "mu= 0.2 ,lamb= 0.5 h2h_ddr_ols= 0.48369444233240766 regret= -0.014306486881249234\n",
      "mu= 0.2 ,lamb= 0.6 h2h_ddr_ols= 0.47520336924200557 regret= -0.025329701577304367\n",
      "mu= 0.2 ,lamb= 0.7 h2h_ddr_ols= 0.4680622903827522 regret= -0.03891890423521076\n",
      "mu= 0.2 ,lamb= 0.8 h2h_ddr_ols= 0.46035183973009663 regret= -0.05364363994348497\n",
      "mu= 0.2 ,lamb= 0.9 h2h_ddr_ols= 0.4527343098105218 regret= -0.07178792351498796\n",
      "mu= 0.3 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.3 ,lamb= 0.1 h2h_ddr_ols= 0.509139775798403 regret= 0.00031625696769645753\n",
      "mu= 0.3 ,lamb= 0.2 h2h_ddr_ols= 0.5094257598225738 regret= 0.002166330288033838\n",
      "mu= 0.3 ,lamb= 0.3 h2h_ddr_ols= 0.5079858540215123 regret= 0.0029551250555261634\n",
      "mu= 0.3 ,lamb= 0.4 h2h_ddr_ols= 0.5012922696642228 regret= -0.0007611409524500002\n",
      "mu= 0.3 ,lamb= 0.5 h2h_ddr_ols= 0.49127494266870664 regret= -0.006703059248932034\n",
      "mu= 0.3 ,lamb= 0.6 h2h_ddr_ols= 0.48841544732802844 regret= -0.012068632420885883\n",
      "mu= 0.3 ,lamb= 0.7 h2h_ddr_ols= 0.4803952314435697 regret= -0.023053083653854042\n",
      "mu= 0.3 ,lamb= 0.8 h2h_ddr_ols= 0.47226476287548974 regret= -0.03347927962176834\n",
      "mu= 0.3 ,lamb= 0.9 h2h_ddr_ols= 0.4636436866617551 regret= -0.046584100075414116\n",
      "mu= 0.4 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.4 ,lamb= 0.1 h2h_ddr_ols= 0.5217132673269786 regret= 0.0006914590077860093\n",
      "mu= 0.4 ,lamb= 0.2 h2h_ddr_ols= 0.5100291637269209 regret= 0.00041164176498793744\n",
      "mu= 0.4 ,lamb= 0.3 h2h_ddr_ols= 0.5086779243253087 regret= 0.0007228797153930666\n",
      "mu= 0.4 ,lamb= 0.4 h2h_ddr_ols= 0.4985953600434513 regret= -0.0022793272243065237\n",
      "mu= 0.4 ,lamb= 0.5 h2h_ddr_ols= 0.4953225920657671 regret= -0.004620221551239418\n",
      "mu= 0.4 ,lamb= 0.6 h2h_ddr_ols= 0.48762078138288023 regret= -0.010428566894105063\n",
      "mu= 0.4 ,lamb= 0.7 h2h_ddr_ols= 0.4819218041760366 regret= -0.016995197141071793\n",
      "mu= 0.4 ,lamb= 0.8 h2h_ddr_ols= 0.4752769360320086 regret= -0.02407075566874326\n",
      "mu= 0.4 ,lamb= 0.9 h2h_ddr_ols= 0.47076939502708803 regret= -0.03170944805997982\n",
      "mu= 0.5 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.5 ,lamb= 0.1 h2h_ddr_ols= 0.5125893642850771 regret= -0.0003013632183088719\n",
      "mu= 0.5 ,lamb= 0.2 h2h_ddr_ols= 0.5146081714911375 regret= 0.0006498946342820278\n",
      "mu= 0.5 ,lamb= 0.3 h2h_ddr_ols= 0.5118010814907166 regret= 0.0008718289731911542\n",
      "mu= 0.5 ,lamb= 0.4 h2h_ddr_ols= 0.5067551566060134 regret= 2.9253854490934525e-05\n",
      "mu= 0.5 ,lamb= 0.5 h2h_ddr_ols= 0.5005771853238441 regret= -0.0021626700592854336\n",
      "mu= 0.5 ,lamb= 0.6 h2h_ddr_ols= 0.4919914601318958 regret= -0.006567121587503044\n",
      "mu= 0.5 ,lamb= 0.7 h2h_ddr_ols= 0.49222032396019477 regret= -0.00990953257160858\n",
      "mu= 0.5 ,lamb= 0.8 h2h_ddr_ols= 0.4859740018732533 regret= -0.01427986527286424\n",
      "mu= 0.5 ,lamb= 0.9 h2h_ddr_ols= 0.47750001284546406 regret= -0.021110089841749988\n",
      "mu= 0.6 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.6 ,lamb= 0.1 h2h_ddr_ols= 0.5078748573295956 regret= -0.0002670400174986465\n",
      "mu= 0.6 ,lamb= 0.2 h2h_ddr_ols= 0.5097502971074642 regret= -0.0002523769728920628\n",
      "mu= 0.6 ,lamb= 0.3 h2h_ddr_ols= 0.5095947531651498 regret= -0.00046388659921527825\n",
      "mu= 0.6 ,lamb= 0.4 h2h_ddr_ols= 0.5064562962639225 regret= -0.0007382272460211359\n",
      "mu= 0.6 ,lamb= 0.5 h2h_ddr_ols= 0.5031793150135021 regret= -0.0012169875611445285\n",
      "mu= 0.6 ,lamb= 0.6 h2h_ddr_ols= 0.49793824117566887 regret= -0.002906255112084196\n",
      "mu= 0.6 ,lamb= 0.7 h2h_ddr_ols= 0.4950838745437484 regret= -0.004712653260466738\n",
      "mu= 0.6 ,lamb= 0.8 h2h_ddr_ols= 0.48800141996562085 regret= -0.008421470302659932\n",
      "mu= 0.6 ,lamb= 0.9 h2h_ddr_ols= 0.4839564670825486 regret= -0.011707086826039336\n",
      "mu= 0.7 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.7 ,lamb= 0.1 h2h_ddr_ols= 0.5030122899975841 regret= -0.0003580480075531016\n",
      "mu= 0.7 ,lamb= 0.2 h2h_ddr_ols= 0.5213015230160132 regret= -4.100357882704953e-06\n",
      "mu= 0.7 ,lamb= 0.3 h2h_ddr_ols= 0.5081353115697889 regret= -0.0003500391825395053\n",
      "mu= 0.7 ,lamb= 0.4 h2h_ddr_ols= 0.5057021592031622 regret= -0.0005395024134134245\n",
      "mu= 0.7 ,lamb= 0.5 h2h_ddr_ols= 0.5108129540848768 regret= -6.156253012663918e-05\n",
      "mu= 0.7 ,lamb= 0.6 h2h_ddr_ols= 0.5069738087935971 regret= -0.0008185898396768493\n",
      "mu= 0.7 ,lamb= 0.7 h2h_ddr_ols= 0.5014472220076792 regret= -0.001700211372619716\n",
      "mu= 0.7 ,lamb= 0.8 h2h_ddr_ols= 0.4980254565532294 regret= -0.0034623295227850354\n",
      "mu= 0.7 ,lamb= 0.9 h2h_ddr_ols= 0.4971020528449821 regret= -0.0037043779544110272\n",
      "mu= 0.8 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.8 ,lamb= 0.1 h2h_ddr_ols= 0.5182720057720058 regret= 1.6253416510046268e-06\n",
      "mu= 0.8 ,lamb= 0.2 h2h_ddr_ols= 0.513560495884143 regret= -0.00010640278803208532\n",
      "mu= 0.8 ,lamb= 0.3 h2h_ddr_ols= 0.522559704406894 regret= 0.000562002206308346\n",
      "mu= 0.8 ,lamb= 0.4 h2h_ddr_ols= 0.5230212156738243 regret= 0.00021689370133022898\n",
      "mu= 0.8 ,lamb= 0.5 h2h_ddr_ols= 0.5173171798281129 regret= 0.0006909397707933165\n",
      "mu= 0.8 ,lamb= 0.6 h2h_ddr_ols= 0.5155992089631571 regret= 0.0006362746172867805\n",
      "mu= 0.8 ,lamb= 0.7 h2h_ddr_ols= 0.5161691948593902 regret= 0.000655605365239958\n",
      "mu= 0.8 ,lamb= 0.8 h2h_ddr_ols= 0.5142403687472012 regret= 9.454281213382437e-05\n",
      "mu= 0.8 ,lamb= 0.9 h2h_ddr_ols= 0.5093852127307572 regret= -0.0006987545082679718\n",
      "mu= 0.9 ,lamb= 0.0 h2h_ddr_ols= 0.5 regret= 0.0\n",
      "mu= 0.9 ,lamb= 0.1 h2h_ddr_ols= 0.5046190476190477 regret= 0.0004236893713566502\n",
      "mu= 0.9 ,lamb= 0.2 h2h_ddr_ols= 0.50190873015873 regret= -0.00028858835240923184\n",
      "mu= 0.9 ,lamb= 0.3 h2h_ddr_ols= 0.5212682456432456 regret= -0.00019454073827568057\n",
      "mu= 0.9 ,lamb= 0.4 h2h_ddr_ols= 0.5018113159630188 regret= -0.0004478863712125315\n",
      "mu= 0.9 ,lamb= 0.5 h2h_ddr_ols= 0.5040702849582377 regret= -0.00040939970322716635\n",
      "mu= 0.9 ,lamb= 0.6 h2h_ddr_ols= 0.5054835438354788 regret= -2.365406078662145e-05\n",
      "mu= 0.9 ,lamb= 0.7 h2h_ddr_ols= 0.5126295334318243 regret= 1.690894961721009e-05\n",
      "mu= 0.9 ,lamb= 0.8 h2h_ddr_ols= 0.5079969175791833 regret= -0.00033139995737176137\n",
      "mu= 0.9 ,lamb= 0.9 h2h_ddr_ols= 0.5059227132803691 regret= -0.0001600364736996671\n"
     ]
    }
   ],
   "source": [
    "h2h_ddr_vs_ols_all = {}; cost_reduction_ddr_vs_ols_all = {}; regret_reduction_ddr_vs_ols_all = {}\n",
    "h2h_ddr_vs_ols_avg = np.zeros((len(mu_all),len(lamb_all))); regret_ddr_vs_ols_avg = np.zeros((len(mu_all),len(lamb_all)))\n",
    "\n",
    "mu_index = 0\n",
    "for mu in mu_all:\n",
    "    lamb_index = 0\n",
    "    for lamb in lamb_all:\n",
    "\n",
    "        h2h_ddr_ols = np.zeros(len(iteration_all)); cost_reduction_ddr_vs_ols = np.zeros(len(iteration_all)); regret_reduction_ddr_vs_ols = np.zeros(len(iteration_all))\n",
    "        for iter_index in range(len(iteration_all)):\n",
    "            iter = iteration_all[iter_index]\n",
    "            h2h_ddr_ols[iter_index],cost_reduction_ddr_vs_ols[iter_index],regret_reduction_ddr_vs_ols[iter_index] = cross_compare2plus(cost_DDR_with_noise_all[iter,mu,lamb], cost_OLS_with_noise_all[iter], cost_Oracle_with_noise_all[iter])\n",
    "        h2h_ddr_vs_ols_avg[mu_index,lamb_index] = np.nanmean(h2h_ddr_ols)\n",
    "        regret_ddr_vs_ols_avg[mu_index,lamb_index] = np.nanmean(regret_reduction_ddr_vs_ols)\n",
    "        print(\"mu=\",mu,\",lamb=\",lamb,\"h2h_ddr_ols=\",np.nanmean(h2h_ddr_ols),\"regret=\",np.nanmean(regret_reduction_ddr_vs_ols))\n",
    "        lamb_index = lamb_index + 1\n",
    "    \n",
    "        h2h_ddr_vs_ols_all[mu,lamb] = h2h_ddr_ols\n",
    "        cost_reduction_ddr_vs_ols_all[mu,lamb] = cost_reduction_ddr_vs_ols\n",
    "        regret_reduction_ddr_vs_ols_all[mu,lamb] = regret_reduction_ddr_vs_ols\n",
    "    mu_index = mu_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_DDR_vs_OLS_para_avg_df = pd.DataFrame(regret_ddr_vs_ols_avg)\n",
    "regret_DDR_vs_OLS_para_avg_df.index = [\"$\\mu=\"+str(mu)+\"$\" for mu in mu_all]\n",
    "regret_DDR_vs_OLS_para_avg_df.columns = [\"$\\lambda=\"+str(lamb)+\"$\" for lamb in lamb_all]\n",
    "regret_DDR_vs_OLS_para_avg_df.to_csv(DataPath+\"regret_ddr_vs_ols_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\lambda=0.0$</th>\n",
       "      <th>$\\lambda=0.1$</th>\n",
       "      <th>$\\lambda=0.2$</th>\n",
       "      <th>$\\lambda=0.3$</th>\n",
       "      <th>$\\lambda=0.4$</th>\n",
       "      <th>$\\lambda=0.5$</th>\n",
       "      <th>$\\lambda=0.6$</th>\n",
       "      <th>$\\lambda=0.7$</th>\n",
       "      <th>$\\lambda=0.8$</th>\n",
       "      <th>$\\lambda=0.9$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.1$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>-0.005463</td>\n",
       "      <td>-0.013952</td>\n",
       "      <td>-0.027773</td>\n",
       "      <td>-0.043679</td>\n",
       "      <td>-0.064414</td>\n",
       "      <td>-0.092164</td>\n",
       "      <td>-0.118783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.2$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>-0.003586</td>\n",
       "      <td>-0.006339</td>\n",
       "      <td>-0.014306</td>\n",
       "      <td>-0.025330</td>\n",
       "      <td>-0.038919</td>\n",
       "      <td>-0.053644</td>\n",
       "      <td>-0.071788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.3$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>-0.006703</td>\n",
       "      <td>-0.012069</td>\n",
       "      <td>-0.023053</td>\n",
       "      <td>-0.033479</td>\n",
       "      <td>-0.046584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.4$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>-0.002279</td>\n",
       "      <td>-0.004620</td>\n",
       "      <td>-0.010429</td>\n",
       "      <td>-0.016995</td>\n",
       "      <td>-0.024071</td>\n",
       "      <td>-0.031709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.5$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>-0.006567</td>\n",
       "      <td>-0.009910</td>\n",
       "      <td>-0.014280</td>\n",
       "      <td>-0.021110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.6$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000464</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>-0.001217</td>\n",
       "      <td>-0.002906</td>\n",
       "      <td>-0.004713</td>\n",
       "      <td>-0.008421</td>\n",
       "      <td>-0.011707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.7$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>-0.001700</td>\n",
       "      <td>-0.003462</td>\n",
       "      <td>-0.003704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.8$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>-0.000699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.9$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>-0.000160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           $\\lambda=0.0$  $\\lambda=0.1$  $\\lambda=0.2$  $\\lambda=0.3$  \\\n",
       "$\\mu=0.1$            0.0       0.000818       0.000247      -0.005463   \n",
       "$\\mu=0.2$            0.0       0.000131       0.000770      -0.003586   \n",
       "$\\mu=0.3$            0.0       0.000316       0.002166       0.002955   \n",
       "$\\mu=0.4$            0.0       0.000691       0.000412       0.000723   \n",
       "$\\mu=0.5$            0.0      -0.000301       0.000650       0.000872   \n",
       "$\\mu=0.6$            0.0      -0.000267      -0.000252      -0.000464   \n",
       "$\\mu=0.7$            0.0      -0.000358      -0.000004      -0.000350   \n",
       "$\\mu=0.8$            0.0       0.000002      -0.000106       0.000562   \n",
       "$\\mu=0.9$            0.0       0.000424      -0.000289      -0.000195   \n",
       "\n",
       "           $\\lambda=0.4$  $\\lambda=0.5$  $\\lambda=0.6$  $\\lambda=0.7$  \\\n",
       "$\\mu=0.1$      -0.013952      -0.027773      -0.043679      -0.064414   \n",
       "$\\mu=0.2$      -0.006339      -0.014306      -0.025330      -0.038919   \n",
       "$\\mu=0.3$      -0.000761      -0.006703      -0.012069      -0.023053   \n",
       "$\\mu=0.4$      -0.002279      -0.004620      -0.010429      -0.016995   \n",
       "$\\mu=0.5$       0.000029      -0.002163      -0.006567      -0.009910   \n",
       "$\\mu=0.6$      -0.000738      -0.001217      -0.002906      -0.004713   \n",
       "$\\mu=0.7$      -0.000540      -0.000062      -0.000819      -0.001700   \n",
       "$\\mu=0.8$       0.000217       0.000691       0.000636       0.000656   \n",
       "$\\mu=0.9$      -0.000448      -0.000409      -0.000024       0.000017   \n",
       "\n",
       "           $\\lambda=0.8$  $\\lambda=0.9$  \n",
       "$\\mu=0.1$      -0.092164      -0.118783  \n",
       "$\\mu=0.2$      -0.053644      -0.071788  \n",
       "$\\mu=0.3$      -0.033479      -0.046584  \n",
       "$\\mu=0.4$      -0.024071      -0.031709  \n",
       "$\\mu=0.5$      -0.014280      -0.021110  \n",
       "$\\mu=0.6$      -0.008421      -0.011707  \n",
       "$\\mu=0.7$      -0.003462      -0.003704  \n",
       "$\\mu=0.8$       0.000095      -0.000699  \n",
       "$\\mu=0.9$      -0.000331      -0.000160  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regret_DDR_vs_OLS_para_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2h_DDR_vs_OLS_para_avg_df = pd.DataFrame(h2h_ddr_vs_ols_avg * 100)\n",
    "h2h_DDR_vs_OLS_para_avg_df.index = [\"$\\mu=\"+str(mu)+\"$\" for mu in mu_all]\n",
    "h2h_DDR_vs_OLS_para_avg_df.columns = [\"$\\lambda=\"+str(lamb)+\"$\" for lamb in lamb_all]\n",
    "h2h_DDR_vs_OLS_para_avg_df.to_csv(DataPath+\"h2h_ddr_vs_ols_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\lambda=0.0$</th>\n",
       "      <th>$\\lambda=0.1$</th>\n",
       "      <th>$\\lambda=0.2$</th>\n",
       "      <th>$\\lambda=0.3$</th>\n",
       "      <th>$\\lambda=0.4$</th>\n",
       "      <th>$\\lambda=0.5$</th>\n",
       "      <th>$\\lambda=0.6$</th>\n",
       "      <th>$\\lambda=0.7$</th>\n",
       "      <th>$\\lambda=0.8$</th>\n",
       "      <th>$\\lambda=0.9$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.1$</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.543852</td>\n",
       "      <td>50.190222</td>\n",
       "      <td>49.391055</td>\n",
       "      <td>48.554208</td>\n",
       "      <td>47.422403</td>\n",
       "      <td>46.539300</td>\n",
       "      <td>45.202844</td>\n",
       "      <td>43.860044</td>\n",
       "      <td>42.803609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.2$</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.419736</td>\n",
       "      <td>50.272393</td>\n",
       "      <td>49.348802</td>\n",
       "      <td>48.933186</td>\n",
       "      <td>48.369444</td>\n",
       "      <td>47.520337</td>\n",
       "      <td>46.806229</td>\n",
       "      <td>46.035184</td>\n",
       "      <td>45.273431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.3$</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.913978</td>\n",
       "      <td>50.942576</td>\n",
       "      <td>50.798585</td>\n",
       "      <td>50.129227</td>\n",
       "      <td>49.127494</td>\n",
       "      <td>48.841545</td>\n",
       "      <td>48.039523</td>\n",
       "      <td>47.226476</td>\n",
       "      <td>46.364369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.4$</th>\n",
       "      <td>50.0</td>\n",
       "      <td>52.171327</td>\n",
       "      <td>51.002916</td>\n",
       "      <td>50.867792</td>\n",
       "      <td>49.859536</td>\n",
       "      <td>49.532259</td>\n",
       "      <td>48.762078</td>\n",
       "      <td>48.192180</td>\n",
       "      <td>47.527694</td>\n",
       "      <td>47.076940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.5$</th>\n",
       "      <td>50.0</td>\n",
       "      <td>51.258936</td>\n",
       "      <td>51.460817</td>\n",
       "      <td>51.180108</td>\n",
       "      <td>50.675516</td>\n",
       "      <td>50.057719</td>\n",
       "      <td>49.199146</td>\n",
       "      <td>49.222032</td>\n",
       "      <td>48.597400</td>\n",
       "      <td>47.750001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.6$</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.787486</td>\n",
       "      <td>50.975030</td>\n",
       "      <td>50.959475</td>\n",
       "      <td>50.645630</td>\n",
       "      <td>50.317932</td>\n",
       "      <td>49.793824</td>\n",
       "      <td>49.508387</td>\n",
       "      <td>48.800142</td>\n",
       "      <td>48.395647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.7$</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.301229</td>\n",
       "      <td>52.130152</td>\n",
       "      <td>50.813531</td>\n",
       "      <td>50.570216</td>\n",
       "      <td>51.081295</td>\n",
       "      <td>50.697381</td>\n",
       "      <td>50.144722</td>\n",
       "      <td>49.802546</td>\n",
       "      <td>49.710205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.8$</th>\n",
       "      <td>50.0</td>\n",
       "      <td>51.827201</td>\n",
       "      <td>51.356050</td>\n",
       "      <td>52.255970</td>\n",
       "      <td>52.302122</td>\n",
       "      <td>51.731718</td>\n",
       "      <td>51.559921</td>\n",
       "      <td>51.616919</td>\n",
       "      <td>51.424037</td>\n",
       "      <td>50.938521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\mu=0.9$</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.461905</td>\n",
       "      <td>50.190873</td>\n",
       "      <td>52.126825</td>\n",
       "      <td>50.181132</td>\n",
       "      <td>50.407028</td>\n",
       "      <td>50.548354</td>\n",
       "      <td>51.262953</td>\n",
       "      <td>50.799692</td>\n",
       "      <td>50.592271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           $\\lambda=0.0$  $\\lambda=0.1$  $\\lambda=0.2$  $\\lambda=0.3$  \\\n",
       "$\\mu=0.1$           50.0      50.543852      50.190222      49.391055   \n",
       "$\\mu=0.2$           50.0      50.419736      50.272393      49.348802   \n",
       "$\\mu=0.3$           50.0      50.913978      50.942576      50.798585   \n",
       "$\\mu=0.4$           50.0      52.171327      51.002916      50.867792   \n",
       "$\\mu=0.5$           50.0      51.258936      51.460817      51.180108   \n",
       "$\\mu=0.6$           50.0      50.787486      50.975030      50.959475   \n",
       "$\\mu=0.7$           50.0      50.301229      52.130152      50.813531   \n",
       "$\\mu=0.8$           50.0      51.827201      51.356050      52.255970   \n",
       "$\\mu=0.9$           50.0      50.461905      50.190873      52.126825   \n",
       "\n",
       "           $\\lambda=0.4$  $\\lambda=0.5$  $\\lambda=0.6$  $\\lambda=0.7$  \\\n",
       "$\\mu=0.1$      48.554208      47.422403      46.539300      45.202844   \n",
       "$\\mu=0.2$      48.933186      48.369444      47.520337      46.806229   \n",
       "$\\mu=0.3$      50.129227      49.127494      48.841545      48.039523   \n",
       "$\\mu=0.4$      49.859536      49.532259      48.762078      48.192180   \n",
       "$\\mu=0.5$      50.675516      50.057719      49.199146      49.222032   \n",
       "$\\mu=0.6$      50.645630      50.317932      49.793824      49.508387   \n",
       "$\\mu=0.7$      50.570216      51.081295      50.697381      50.144722   \n",
       "$\\mu=0.8$      52.302122      51.731718      51.559921      51.616919   \n",
       "$\\mu=0.9$      50.181132      50.407028      50.548354      51.262953   \n",
       "\n",
       "           $\\lambda=0.8$  $\\lambda=0.9$  \n",
       "$\\mu=0.1$      43.860044      42.803609  \n",
       "$\\mu=0.2$      46.035184      45.273431  \n",
       "$\\mu=0.3$      47.226476      46.364369  \n",
       "$\\mu=0.4$      47.527694      47.076940  \n",
       "$\\mu=0.5$      48.597400      47.750001  \n",
       "$\\mu=0.6$      48.800142      48.395647  \n",
       "$\\mu=0.7$      49.802546      49.710205  \n",
       "$\\mu=0.8$      51.424037      50.938521  \n",
       "$\\mu=0.9$      50.799692      50.592271  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2h_DDR_vs_OLS_para_avg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2H_regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Figures import regret_and_h2h_figure\n",
    "rhf = regret_and_h2h_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu = 0.7\n",
    "# lamb = 0.1\n",
    "# all_x = h2h_ddr_vs_ols_all[mu,lamb] * 100\n",
    "# all_y = regret_reduction_ddr_vs_ols_all[mu,lamb] * 100\n",
    "# figure_name = DataPath + \"h2h_regret_mu\"+str(mu)+\"_lamb=\"+str(lamb)+\"_\"\n",
    "# rhf.figure_plot_upright(all_x,all_y,figure_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPO(SPO+,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Implement_EPO(DataPath,iteration_all,batch_size,num_epochs,method_names,W_star_all,bump,x_train_all,c_train_all,x_test_all,noise_test_all,\\\n",
    "                  arcs,grid,epo_runner,perfs):\n",
    "    W_EPO_all = {}; w0_EPO_all = {}\n",
    "    cost_EPO_all = {}\n",
    "    for iter in iteration_all:\n",
    "        DataPath_seed = DataPath +\"iter=\"+str(iter)+\"/\"\n",
    "        pathlib.Path(DataPath_seed).mkdir(parents=True, exist_ok=True)\n",
    "        # print(\"*** seed = \",seed,\": Run EPO ******\")\n",
    "        W_EPO_all[iter],w0_EPO_all[iter] = epo_runner.run(method_names,DataPath_seed,batch_size,num_feat,grid,num_epochs,\\\n",
    "                                        x_train_all[iter],c_train_all[iter],arcs)\n",
    "        \n",
    "        cost_dem = (W_EPO_all[iter] @ x_test_all[iter].T).T + w0_EPO_all[iter]\n",
    "        if data_generation_process == \"SPO_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T)/np.sqrt(num_feat) + 3\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis + 1).T\n",
    "            cost_EPO_all[iter] = perfs.compute_SPO_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "\n",
    "        if data_generation_process == \"DDR_Data_Generation\":\n",
    "            cost_oracle_ori = (W_star_all[iter] @ x_test_all[iter].T) + bump\n",
    "            cost_oracle_pred = (cost_oracle_ori ** mis).T\n",
    "            cost_EPO_all[iter] = perfs.compute_DDR_out_of_sample_Cost(arcs, grid,cost_dem,cost_oracle_pred,noise_test_all[iter])\n",
    "        print(method_names[0],\": iter=\",iter,\",cost=\",np.nanmean(cost_EPO_all[iter]))\n",
    "\n",
    "    return W_EPO_all,w0_EPO_all,cost_EPO_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_generation_process = \"SPO_Data_Generation\"\n",
    "# # data_generation_process = \"DDR_Data_Generation\"\n",
    "\n",
    "# grid_all = [(2,2),(3,3),(4,4),(5,5)] # grid size\n",
    "# max_regret_arr = []\n",
    "# for grid in grid_all:\n",
    "#     d = (grid[0] - 1) * (grid[0] - 1) * 2 + 2 * (grid[0] - 1) # num of arcs\n",
    "\n",
    "#     current_directory = os.getcwd()\n",
    "#     parent_directory = os.path.dirname(current_directory)\n",
    "#     grandparent_directory = os.path.dirname(parent_directory)\n",
    "#     DataPath_parents = os.path.dirname(grandparent_directory) + '/Data/Shortest_Path_Reproduce/'+str(grid[0])+'by'+str(grid[1])+'_grid_' + data_generation_process + \"/\"\n",
    "#     print(\"DataPath_parents:\", DataPath_parents)\n",
    "#     DataPath_current = DataPath_parents + \"data_size=\"+str(num_train)+\"_deg=\"+str(deg)+\"_e=\"+str(e)+\"_d=\"+str(d)+\"_x_dist=\"+x_dist+\"_num_test=\"+str(num_test)+\"_diff_W/\"\n",
    "#     print(\"DataPath_current:\", DataPath_current)\n",
    "#     regret_ddr_vs_ols_avg = pd.read_csv(DataPath_current +'regret_ddr_vs_ols_avg.csv',index_col=0)\n",
    "#     regret_np = pd.DataFrame(regret_ddr_vs_ols_avg.values).applymap(lambda x: float(x.strip('%')) / 100).values\n",
    "#     print(\"max regert = \",np.max(regret_np)*100)\n",
    "#     max_regret_arr.append(np.max(regret_np)*100)\n",
    "# max_regret_arr = np.asarray(max_regret_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
